goland面试题源码分析：
https://www.kancloud.cn/aceld/golang/1858955

1、简单介绍sync.mutex

	1、先介绍
		Go语言以并发作为其特性之一，并发必然会带来对于资源的竞争。这个时候通常使用Go语言 提供的sync.Mutex 互斥锁
	来保证临界资源的访问互斥。
	简单来说就是，当一个goroutine获得了这个锁的拥有权后，其他请求锁的goroutine就会阻塞在lock方法的调用上，直到锁被释放。

	2、讲看过的源码 Mutex
	源码中的注释是这样介绍的。
		1、sync.Mutex的互斥锁有两种状态。正常状态和饥饿状态。
			1、在正常状态下，所有等待锁的goroutine按照 FIFO(队列先进先出) 的顺序等待。唤醒的goroutine不会直接拥有锁
		，而是会和新请求锁的goroutine竞争锁的拥有。新请求锁的goroutine具有优势：它正在CPU上执行。而且可能好几个，所以刚刚唤醒的goroutine有很大可能在锁的竞争中失败。在这种情况下，这个被唤醒的goroutine会加入到等待队列的前面。如果一个等待的goroutine超过1ms没有获取锁，那么它将会把锁转变为饥饿模式。
			2、在饥饿模式下，锁的所有权将从unlock的goroutine直接交给等待队列中的第一个。新来的goroutine将不会尝试去获得锁。即使锁看起来是unlock状态，也不会尝试自旋操作，而是放在等待队列的尾部。
			如果一个等待的goroutine获取了锁，并且满足以下任何一个条件。（1）他是等待队列的第一个。（2）他等待的时间小于1ms，它将会把锁的状态由饥饿模式转换为正常状态。

		2、正常状态有很好的性能表现。饥饿模式也是很重要的，他能阻止尾部延迟的现象。


	3、讲具体的源码
	在sync.Mutex源码中对 Mutex结构体的定义 只包含两个字段
	type Mutex struct {
		state int32
		sema uint32	用来唤醒 goroutine 所用的信号量。
	}

	1、state
		state是一个共用的字段， 第0个 bit 标记这个mutex是否已被某个goroutine所拥有，下面为了描述方便称之为state已加锁，
		或者mutex已加锁。 如果第0个 bit为0, 下文称之为state未被锁, 此mutex目前没有被某个goroutine所拥有。
		第1个 bit 标记这个mutex是否已唤醒, 也就是有某个唤醒的goroutine要尝试获取锁。
		第2个 bit 标记这个mutex状态， 值为1表明此锁已处于饥饿状态。

		eg:
			``[1][1][1]`` :  第一个[1] 表示锁状态，第二个[1]表示是否有唤醒，第三个[1]表示是否是饥饿模式
	·``001`普通模式 ，无唤醒， 锁  ，`010` 普通模式， 有唤醒  ，无锁状态，,`101``  饥饿模式 ，无唤醒  ，锁


1、Mutex分析


	1、CAS 指令
		CAS全称 Compare-And-Swap 它是CPU并发语。它的功能是判断内存中某个位置的值是否为预期值。
	如果是则更改为新的值，这个过程是原子的。

	golang中 在sync/atomic包种，这类原子操作由名称以‘CompareAndSwap’为前缀的若干个函数代表。

	声明如下：
		func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool)

	解释：
	1、调用函数后，会先判断参数addr指向的被操作值与参数old的值是否相等
	2、仅当此判断（1）得到肯定的结果后，才会用参数new代表的新值替换掉原来的旧值，否则操作会被忽略。
	3, so 需要用for循环不断进行尝试,直到成功为止
	4、使用锁的做法趋于悲观
		1、我们总假设会有并发的操作要修改被操作的值，并使用锁将相关操作放入临界区中加以保护
	5、使用CAS操作的做法趋于乐观
		总是假设被操作值未曾被改变（即与旧值相等），并一旦确认这个假设的真实性就立即进行值替换。


	2、自旋 和 信号量
		当一个 Goroutine 获取到锁后, 其他的 Goroutine 开始进入自旋转(为了持有CPU) 或者进入沉睡阻塞状态(等待信号量唤醒).
		正常情况下, 当一个 Goroutine 获取到锁后, 其他的 Goroutine 开始进入自旋转(为了持有CPU) 或者进入沉睡阻塞状态(等待信号量唤醒). 但是这里存在一个问题, 新请求的 Goroutine 进入自旋时是仍然拥有 CPU 的, 所以比等待信号量唤醒的 Goroutine 更容易获取锁. 用官方话说就是，新请求锁的 Goroutine具有优势，它正在CPU上执行，而且可能有好几个，所以刚刚唤醒的 Goroutine 有很大可能在锁竞争中失败.

	于是如果一个 Goroutine 被唤醒过后, 仍然没有拿到锁, 那么该 Goroutine 会放在等待队列的最前面. 并且那些等待超过 1 ms 的 Goroutine 还没有获取到锁，该 Goroutine 就会进入饥饿状态。该 Goroutine 是饥饿状态并且 Mutex 是 Locked 状态时，才有可能给 Mutex 设置成饥饿状态.

	获取到锁的 Goroutine Unlock, 将 Mutex 的 Locked 状态解除, 发出来解锁信号, 等待的 Goroutine 开始竞争该信号. 如果发现当前 Mutex 是饥饿状态, 直接将唤醒信号发给第一个等待的 Goroutine

	这就是所谓的 Goroutine 排队

	举例子分析加锁和解锁流程。

	1、如果



2、当 Go struct 遇上 Mutex。不能复制原因。
	  我们使用 Mutex 是为了不同 goroutine 之间共享某个变量, 所以需要让这个变量做到能够互斥, 不然该变量就会被互相被覆盖.
	  Mutex 底层是由 state sema 控制的, 当 Mutex 变量被复制时, Mutex 的 state, sema 当时的状态也被复制走了, 但是由于不同 goroutine 之间的 Mutex 已经不是同一个变量了, 这样就会造成要么某个 goroutine 死锁或者不同 goroutine 共享的变量达不到互斥

3、struct 如何与 不可复制 的类型一块使用 ?
type URL struct {
	Ip       string
	mux   	 *sync.RWMutex
}

将嵌套的不可复制变量改成指针类型变量，就可避免，但是要注意空指针问题。


二、
二、sync.Map源码分析
	go中 map 并不是并发安全的，go基于mutex排它锁，实现了并发安全的sync.Map

    在Go 1.6之前， 内置的map类型是部分goroutine安全的，并发的读没有问题，并发的写可能有问题。
    自go 1.6之后， 并发地读写map会报错，这在一些知名的开源库中都存在这个问题，所以go 1.9之前的解决方案是额外绑定一个锁，
    封装成一个新的struct或者单独使用锁都可以。

    在1.9以后提出了一个sync.Map 实现并发安全
  sync.Map是协程安全的，并通过读写分离的机制，降低锁的粒度，提高并发性能。

   1、 看看 sync.map 优点：

        1、空间换时间：通过冗余的两个数据结构(read、dirty)，实现加锁对性能的影响。
        2、使用只读数据(read)，避免读写冲突。
        3、动态调整，miss次数多了之后，将dirty数据迁移到read中。
        4、double-checking。
        5、延迟删除。 删除一个键值只是打标记，只有在迁移dirty数据的时候才清理删除的数据。
        6、优先从read读取、更新、删除，因为对read的读取不需要锁。


	1、sync.Map的数据结构
	sync.Map的数据结构很简单，包含 ,mutex，read，dirty，misses 四个字断。

	type Map struct {

		mu Mutex 	// 互斥锁，当涉及到dirty数据的操作的时候，需要使用这个锁

		read atomic.Value // readOnly 。 是一个只读的数据结构，因为只读，并不会有读写冲突，从这个数据中读取总是安全的。

		dirty map[interface{}]*entry	// dirty数据 包含当前的map数据中的entries , 对于dirty的操作需要加锁，因为对它的操作可能会有读写竞争

		misses int // 当从Map中读取到entry的时候，如果read中不包含这个entry，会尝试从dirty中读取，这个时候会将misses加一，只有当misses累积到dirty的长度的时候，就会将dirty提升为read，避免从dirty中miss太多次，因为dirty需要加锁。
}


2、需要介绍下read的数据结构

	read的数据结构是：
		type readOnly struct {
			m       map[interface{}]*entry
			amended bool // 如果Map.dirty有些数据不在中read的时候，这个值为true
		}

	amended指明Map.dirty中有readOnly.m未包含的数据，所以如果从Map.read找不到数据的话，还要进一步到Map.dirty中查找


3、介绍下entry数据结构
	type entry struct {
		p unsafe.Pointer // *interface{}
	}
	readOnly.m和Map.dirty存储的值类型是*entry,它包含一个指针p, 指向用户存储的value值。
	read和dirty有冗余数据，但这些数据是通过指针指向同一个数据，所以尽管Map的value会很大，但是冗余的空间占用还是有限的


4、分别介绍load和store，delet，range

	4.1 Load
		加载方法，也就是提供一个键key,查找对应的值value。

		流程：
		1、首先从m.read中得到只读readOnly,从它的map中查找，不需要加锁。如果找到直接返回。如果没找到，并且m.dirty中有新数据，需要从m.dirty查找，这个时候需要加锁，并且 不管m.dirty中存不存在，都将misses计数加一。并且当misses值 和dirty中数据个数一样的时候。把dirty提升为read。接下来还是从read中直接读取。

		有两个需要关注的地方：
			1、一个是首先从m.read中加载，不存在的情况下，并且m.dirty中有新数据，加锁，然后从m.dirty中加载。
			2、二是这里使用了双检查的处理。
				if !ok && read.amended {
					m.mu.Lock()

				因为在加锁之前，m.dirty可能被提升为m.read,所以加锁后还得再检查m.read，后续的方法中都使用了这个方法。


	4.2 Store (更新或者新增一个entry)
		流程：
		1、如果m.read存在这个键，并且这个entry【没有被标记删除】，尝试直接存储。（因为m.dirty也指向这个entry,所以m.dirty也保持最新的entry）
		2、如果 m.read不存在这个值， 并且m.dirty中存在，则直接更新m.dirty的值
		3、如果m.read和 m.dirty中都不存在，那么是是一个新键值，插入到m.dirty中。（存在一个判断m.dirty是否有新更新数据操作。并且复制m.read数据到m.dirty中）

	4.3 delete （删除一个键值。）
		流程
		1、删除操作还是从m.read中开始， 如果这个entry不存在于m.read中，并且m.dirty中有新数据，则加锁尝试从m.dirty中删除。
		2、如果存在于m.read中。则从m.read中删除（注意：不是直接删除而是，打上已删除标记）

	4.4 Range(遍历操作)
		1、流程：（会根据read.amend值，先判断 m.dirty中是否有新数据，则提升m.dirty,然后在遍历）

三、waitGroup源码分析
	WaitGroup是多个goroutine之间协作的一种实现方式，主要功能就是阻塞等待一组goroutine执行完成。
	常用的使用场景：主goroutine调用Add函数设置需要等待的goroutine的数量,当每个goroutine执行完成后调用Done函数(将counter减1)，Wait函数用于阻塞等待直到该组中的所有goroutine都执行完成

	1、waitGroup方法及数据结构概念。

  	type WaitGroup struct {
		noCopy noCopy  / 该WaitGroup对象不允许拷贝使用,只能用指针传递
		state1 [12]byte // 用户存储计数器(counter)和waiter的值。只需要64位，其中高32位是counter值，低32位值是waiter值，不直接使用unit64位，是因为uint64的原子操作需要64位操作系统，而32位系统下，可能会出现崩溃。所以使用btye数组来实现。32位系统下4字节对齐，64位系统下8字节对齐，所以申请12个字节。其中必定有8个字节是符合8字节对齐的。在state（）函数中有进行判断。
	}

    state[0],   state[1],   state[2]
   64位   waiter,     counter,    sema
   32位    sema ,      waiter,   counter,
    从结构体中我们看到 waitgroup结构体中state1的格式很重要。共占12个字节,用于存储counter和waiter的值 sema就是传说中的信号量。

        1、waiter 是等待者计数，
        2、counter 是任务计数，
        3、sema 是信号量


	2、state函数
		state是一个内部函数，用于获取counter和 waiter的值

	//获取counter  、 waiter的值  (counter是uint64的高32位，waiter是uint64的低32位)
	func (wg *WaitGroup) state() *uint64 {
		// 根据state1的起始地址分析,若是8字节对齐的,则直接用前8个字节作为*uint64类型
		// 若不是,说明是4字节对齐,则后移4个字节后,这样必为8字节对齐,然后取后面8个字节作为*uint64类型
		if uintptr(unsafe.Pointer(&wg.state1))%8 == 0 {
			return (*uint64)(unsafe.Pointer(&wg.state1))
		} else {
			return (*uint64)(unsafe.Pointer(&wg.state1[4]))
		}
	}

	3、Add 函数
		用于增加或减少计数器(counter)的，如果计数器为0，则释放调用Wait方法时的阻塞，如果计数器为负，则panic
		参考流程图：
			https://mmbiz.qpic.cn/mmbiz_png/picLDrXZzlobmEsicxu1Bic6jmxjTu44hiaLlgNGupxmib49p514r4aqtyciaDWibcPOfdEzaY44S6rqYsNln0icVFk75w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1

			关键判断：
			//1.counter > 0,说明还不需要释放信号量，可以直接返回
		//2. waiter  = 0 ,说明没有等待的goroutine，也不需要释放信号量，可以直接返回
		if v > 0 || w == 0 {
			return
		}

	4、done 函数
		//将计数器(counter)的值减1
		相当于Add(-1)

	5、wait 函数
		调用Wait方法会阻塞当前调用的goroutine直到 counter的值为0。会一直阻塞，一直等待，直到无需等待或信号量触发，才返回
		参考流程图：
		https://mmbiz.qpic.cn/mmbiz_png/picLDrXZzlobmEsicxu1Bic6jmxjTu44hiaLyuze241iaqn1nGjTcHf360keZkQxwPFXic23dW6SHiaPkvNia0ZYHiaqZtA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1

	6、注意点
	1.Add()必须在Wait()前调用

	2.Add()设置的值必须与实际等待的goroutine个数一致，如果设置的值大于实际的goroutine数量，可能会一直阻塞。如果小于会触发panic

	3. WaitGroup不可拷贝，可以通过指针传递，否则很容易造成BUG

四、goland GC 过程。
	垃圾回收是编程语言中提供的自动的内存管理机制，目的是自动释放不需要的对象，让出存储器资源，这一过程无需由开发人员手动执行。

	1、golang GC 算法演变过程
		版本	GC 算法
			v1.1	Mark 、Sweep、STW （STW(stop the word)）
			v1.3	Mark STW,Sweep (标记清除)
			v1.5	三色标记
			v1.8	hybrid write barrier (三色标记基础上加入写屏障)

	2、Go V1.3之前的标记-清除(mark and sweep)算法
		此算法主要由两个步骤
			1、标记(Mark phase)
			2、清除(Sweep phase)

		1、第一步 暂停程序业务逻辑，程序找出它所有可达的对象，然后做上标记。
			操作非常简单，但是有一点需要额外注意：mark and sweep算法在执行的时候，需要程序暂停！即 STW(stop the world)。也就是说，这段时间程序会卡在哪儿
			参考图片：https://img.kancloud.cn/01/60/0160c38ec63623f3108550ff648f0959_1494x1248.png
		2、	标记完了之后，然后开始清除未标记的对象
			参考图：https://img.kancloud.cn/3e/a9/3ea9ec35364a573c669f5f32c03c8b50_1344x1326.png

		3、第四步, 停止暂停，让程序继续跑。然后循环重复这个过程，直到process程序生命周期结束。

		分析、标记-清扫(mark and sweep)的缺点
			1、STW，stop the world；让程序暂停，程序出现卡顿 (重要问题)。
			2、标记需要扫描整个heap，会产生heap碎片

	3、Go V1.3之前 和 v1.3版本的标记-清除(mark and sweep)算法	对比
		1、Go V1.3版本之前就是以上来实施的, 流程是：
			启动STW  => Mark标记 =》 Sweep清除 =〉 停止STW
			参考：https://img.kancloud.cn/c7/da/c7da67305d321015d28af3f505ccc748_2426x578.png
		2、Go V1.3 做了简单的优化,将STW提前, 减少STW暂停的时间范围.
			启动STW  => Mark标记 =》 停止STW =〉 Sweep清除
			参考 https://img.kancloud.cn/7f/c9/7fc93a9ae9387d34e9843eb1edec31fe_2410x520.png

		Go V1.3 及之前版本的 mark and Sweep 算法 最大的问题是 STW会造成程序卡顿。go V1.5提出了三色标记法，来优化这个问题。

	4、Go v1.5 三色标记法
		为了解决原始标记清除算法带来的长时间 STW。垃圾收集器都会实现三色标记算法的变种以缩短 STW 的时间。三色标记算法将程序中的对象分成白色、黑色和灰色三类：

		白色对象 — 潜在的垃圾，其内存可能会被垃圾收集器回收；
        黑色对象 — 活跃的对象，包括不存在任何引用外部指针的对象以及从根对象可达的对象；
        灰色对象 — 活跃的对象，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象；


        在垃圾收集器开始工作时，程序中不存在任何的黑色对象，垃圾收集的根对象会被标记成灰色，
        垃圾收集器只会从灰色对象集合中取出对象开始扫描，当灰色集合中不存在任何对象时，标记阶段就会结束。
            1、将根节点标记为灰色，其他节点标记为白色
            2、在灰色对象中选择一个标记为黑色
            3、将黑色对象指向的所有对象都标记为灰色
            4、重复前两个步骤直到所有对象中没有灰色对象
            5、清除所有白色对象

            如图：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/三色标记01.png

        标记阶段完成时，应用程序的堆中不存在任何灰色对象，只有黑色的活跃对象和白色的垃圾对象，垃圾收集器就会回收这些白色对象，下图中的白色对象 2 就是即将被回收的垃圾：
       如图： https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/三色标记02.png

        因为用户程序可能在标记执行的过程中修改对对象的引用，所以三色标记法本身是不可以并发或者增量执行的，仍需要 STW。

    在下图所示的标记过程中，如果将对象 1 标记为黑色后，根对象 𝑅1 引用了对象 2 。由于对象 2 是被黑色对象引用而不是被灰色对象引用，所以对象 2 虽然被引用了，标记点却已走到了对象 1 ，对象 2 也就不可能被标记为灰色，直到标记完成时，对象 2 仍是白色，就会被垃圾收集器错误回收。
   如图：  https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/错误垃圾回收.jpeg


    一个正常引用的对象被回收是一个非常严重的错误，这个错误被挑不悬挂指针或野指针，即指针指向了非法的内存地址。

    为了解决这个问题，需要并发或增量标记对象，手段就是使用屏障技术。

    1、为什么要有屏障保护
    如果在三色标记法中 一个白色对象被黑色对象引用，是注定无法通过这个黑色对象来保证自身存活的。
    为了防止这种现象发生，最简单的方式就是STW，直接禁止掉其他用户程序对对象饮用关系的干扰。但是STW过程明显的浪费资源。

    因此需要屏障技术来保证对象不丢失的情况下尽可能的提高GC效率，减少STW时间。


1、三色变式
  1、 想要在并发或者增量的标记算法中保证正确性，我们需要达成以下两种三色不变性（Tri-color invariant）中的一种：

    回收器满足以下情况之一时，即可保证不会出现对象丢失问题。
        强三色不变性 — 黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象；
        弱三色不变性 — 黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径

        屏障技术就是在并发或增量标记过程中保证三色不变式的重要技术

          1、插入写屏障
            1、插入写屏弹是一种相对保守的屏障技术，它会将有存活可能的对象都标记为灰色以满足强三色不变式。

            2、在Golang中，对栈上指针的写入添加写屏障的成本很高，所以Go选择仅对堆上的指针插入增加写屏障，
            这样就会出现在扫描结束后，栈上仍存在引用白色对象的情况，这时的栈是灰色的，不满足三色不变式，
            所以需要对栈进行重新扫描使其变黑，完成剩余对象的标记，这个过程需要STW。
            这期间会将所有goroutine挂起，当有大量应用程序时，时间可能会达到10～100ms。

            在对象 𝐴 引用对象 𝐶 的时候，如果对象 𝐶 是白色，就将对象 𝐶 标记为灰色，其他情况则保持不变

            如图：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/插入写屏障.png


            在上图所示的垃圾回收过程中，实际上不再存活的的对象 𝐵 也保留到了最后，没有被回收。
            如果在第二步时再指 𝐴 到 𝐶 的指针指向 𝐵 ，虽然 𝐶 没有被任何对象引用，但其依然是灰色，
            不会被回收，只有在下次 GC 时才会被回收。

         2、删除写屏障
            1、删除写屏障也叫基于快照的写屏障方案，必须在起始时，STW 扫描整个栈（注意了，是所有的 goroutine 栈），
                保证所有堆上在用的对象都处于灰色保护下，保证的是弱三色不变式；

            2、由于起始快照的原因，起始也是执行 STW，删除写屏障不适用于栈特别大的场景，栈越大，STW 扫描时间越长，
                对于现代服务器上的程序来说，栈地址空间都很大，所以删除写屏障都不适用，
                一般适用于很小的栈内存，比如嵌入式，物联网的一些程序；
            3、删除写屏障 存在精度问题，一个对象即使被删除后依旧可以活过这一轮 。

          当白色或灰色的对象的引用被删除时，将白色对象变为灰色。
              如图：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/删除写屏障.png

         删除写屏障通过对对象 𝐶 的着色，保证了对象 𝐶 和下游的对象 𝐷 能够在这一次垃圾收集的循环中存活，避免发生野指针以保证用户程序的正确性。

        这样删除写屏障就可以保证弱三色不变式，能够保证白色对象的上游链路中一定存在灰色对象


        3、混合写屏障
           1、 插入写屏障和删除写屏障的短板：
                1、插入写屏障：结束时需要STW来重新扫描栈，标记栈上引用的白色对象的存活；
                2、删除写屏障：回收精度低，GC开始时STW扫描堆栈来记录初始快照，这个过程会保护开始时刻的所有存活对象。
             Go V1.8版本引入了混合写屏障机制（hybrid write barrier），避免了对栈re-scan的过程，极大的减少了STW的时间。结合了两者的优点。

           2、在 v1.8 版本中，由插入写屏障和删除写屏障构成了如下所示的混合写屏障，其流程如下：
                 1、GC 开始，将栈上的全部可达对象标记为黑色，之后便不再需要进行重新扫描
                 2、GC 期间，任何在栈上新创建的对象都标记为黑色
                 3、写屏障将被删除的对象标记为灰色（堆）
                 4、写屏障将新添加的对象标记为灰色（堆）

            注意：     混合写屏障扫描栈虽然没有 STW，但是扫描某一个具体的栈的时候，还是要停止这个 goroutine
                       赋值器的工作的哈（针对一个 goroutine 栈来说，是暂停扫的，要么全灰，要么全黑哈，原子状态切换）；

            场景一 对象被一个堆对象删除引用，被一个栈对象引用。
              1、第一步，将栈上可达对象全部标记为黑色：
                    如图：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/混合屏障01.png

              2、第二步，对象 6 被对象 1 引用：
                 如图：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/混合屏障02.png

              3、 第三步，断开与对象 5 的引用关系：
                 如图：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/混合屏障03.png

              对象 5 删除与对象 6 的引用关系，触发写屏障，将对象 6 标记为灰色


五、goroutine 和 GMP 调度
	1、先介绍协程和调度器的由来，引出goroutine
		1、单进程时代
			1、所有软件都跑在操作系统上，真正用来干活的是操作系统。早期的操作系统每个程序就是一个进程，知道一个程序运行完，才能进行下一个进程，就是“单进程时代”。
			一切的程序只能串行发生。例如： A-》B => c
			期的单进程操作系统，面临2个问题：
			1、单一的执行流程，计算机只能一个任务一个任务的处理。
			2、进程阻塞所带来的CPU时间浪费。
			后来 操作系统具有了最早的并发能力：多进程并发。当一个进程阻塞的时候，切换到另外等待执行的进程。这样就能把CPU 利用起来。

		2、多进程/线程时代有了调度器需求
			多进程/线程时代 解决了 阻塞带来的CPU浪费问题。但是又导致了新的问题：
			1、因为 进程拥有太多的资源，进程的创建、切换、销毁，都会占用很长的时间。CPU虽然利用了起来，但是如果进程过多，就会导致
			大部分CPU用来进行进程调度了。
		3、使用协程来提高效率。
			1、多进程、多线程已经提高了系统的并发能力。但是在当今互联网高并发场景下，为每个任务都创建一个线程是不现实的，因为会消耗大量的内存(进程虚拟内存会占用4GB[32位操作系统], 而线程也要大约4MB)。
			大量的进程/线程出现了新的问题
				1）高内存占用
				2）调度的高消耗CPU
			2、后来。就把线程 分为 ： 用户态线程 和 内核态 线程。CPU 并不知道 “用户态”线程的存在，只关心内核态线程的存在。这个用户态的线程就是 “协程”
			3、早期的协程和线程的绑定关系，有三种情况，。
				1、N：1 （N个协程绑定1个线程）
					优点：就是协程在用户态线程即完成切换，不会陷入到内核态，这种切换非常的轻量快速。但也有很大的缺点，1个进程的所有协程都绑定在1个线程上
					缺点：某个程序用不了硬件的多核加速能力一旦某协程阻塞，造成线程阻塞，本进程的其他协程都无法执行了，根本就没有并发的能力了。
				2、1：1  （1个协程绑定1个线程）
					优点：不存在N：1的问题。但是也有以下缺点。
					缺点：CPU的创建，删除，切换也都有CPU管理，代价略高
				3、M：N （M个协程绑定1个线程）
					是N:1和1:1类型的结合，克服了以上2种模型的缺点，但实现起来最为复杂。

					​	需要注意的是：协程跟线程是有区别的，线程由CPU调度是抢占式的，协程由用户态调度是协作式的，一个协程让出CPU后，才执行下一个协程


	2、goroutine及其调度器的演变历程
		goroutine 就是来自上述 协程的概念。
			Go中，协程被称为goroutine，它非常轻量，一个goroutine只占几KB，并且这几KB就足够goroutine运行完，这就能在有限的内存空间内支持大量goroutine，支持了更多的并发
		但是它具有两个优点：
		1、goroutine 内存占用更小
		2、调度更灵活(runtime调度)

	  1、goroutine 早期的调度器。（2012）
	  1、早期Go的调度器 主要有 G(协程)，M（内核线程），及 G的全局队列。
	  	M 要执行 和 放回 G 都需要访问G 的全局队列。并且M有多个，即多线程访问同一个资源，需要加锁保持 同步和互斥。所以全局队列是有互斥锁保护的。
	  	缺点：
	  		1、创建、销毁，调度G都需要每个M获取锁 ，这就形成了激烈的锁竞争。
	  		2、M转移G会造成延迟和额外的系统负载。比如 当G中包含创建新协程的时候。M创建了G‘ ，为了继续执行G，需要把G‘交给M‘执行。也造成了很差的局部性，因为G‘和G是相关的，最好放在M上执行，而不是其他M‘。
	  		3、系统调用(CPU在M之间的切换)导致频繁的线程阻塞和取消阻塞操作增加了系统开销

	 2、Goroutine调度器的GMP模型的设计思想 （新的调度器）
	 	在新调度器中，出列M(thread)和G(goroutine)，又引进了P(Processor)
	 1、	概念：
	 	1、G  goroutine 协程
	 	2、M  内核态线程
	 	3、P  processor处理器。它包含了运行goroutine的资源，如果线程想运行goroutine，必须先获取P,P中还包含了可运行的G队列。


	 2、GMP 模型
	 	在GMP模型中，线程是运行goroutine的实体。调度器的功能是把可运行的goroutine分配到工作线程上。

	 	CMP流程图 参考链接：https://img.kancloud.cn/eb/fe/ebfe3e28315f12a08fbb4ffaee32e046_1024x768.png

	 	1、全局队列（Global Queue）：存放等待运行的G。
		2、P的本地队列：同全局队列类似，存放的也是等待运行的G，存的数量有限，不超过256个。新建G'时，G'优先加入到P的本地队列，如果队列满了，则会把本地队列中一半的G移动到全局队列。
		3、P列表：所有的P都在程序启动时创建，并保存在数组中，最多有GOMAXPROCS(可配置)个。
		4、M：线程想运行任务就得获取P，从P的本地队列获取G，P队列为空时，M也会尝试从全局队列拿一批G放到P的本地队列，或从其他P的本地队列偷一半放到自己P的本地队列。M运行G，G执行之后，M会从P获取下一个G，不断重复下去。

		说明： Gorotine调度器的作用是 将 goroutine和 M 结合绑定。OS系统调度器的作用是，将线程分配在CPU上运行。


		2、有关P和M的个数问题
			1、P的数量：
			由启动时环境变量$GOMAXPROCS或者是由runtime的方法GOMAXPROCS()决定。这意味着在程序执行的任意时刻都只有$GOMAXPROCS个goroutine在同时运行。

			2、M的数量
				go语言本身的限制：go程序启动时，会设置M的最大数量，默认10000.但是内核很难支持这么多的线程数，所以这个限制可以忽略。

		3、调度器的设计策略
		1）work stealing机制
​			 当本线程无可运行的G时，尝试从其他线程绑定的P偷取G，而不是销毁线程。
		2）hand off机制
			当本线程因为G进行系统调用阻塞时，线程释放绑定的P，把P转移给其他空闲的线程执行

			1、利用并行：GOMAXPROCS设置P的数量，最多有GOMAXPROCS个线程分布在多个CPU上同时运行。GOMAXPROCS也限制了并发的程度，比如GOMAXPROCS = 核数/2，则最多利用了一半的CPU核进行并行。
			2、抢占：在coroutine中要等待一个协程主动让出CPU才执行下一个协程，在Go中，一个goroutine最多占用CPU 10ms，防止其他goroutine被饿死，这就是goroutine不同于coroutine的一个地方。
			3、全局G队列：在新的调度器中依然有全局G队列，但功能已经被弱化了，当M执行work stealing从其他P偷不到G时，它可以从全局G队列获取G。


		4、go func() 调度流程
		参考流程图：https://img.kancloud.cn/76/4f/764f7be119026cc16314e87628e4013f_1920x1080.jpeg

		从上图我们可以分析出几个结论：
​			1、我们通过 go func()来创建一个goroutine；
​			2、有两个存储G的队列，一个是局部调度器P的本地队列、一个是全局G队列。新创建的G会先保存在P的本地队列中，如果P的本地队列已经满了就会保存在全局的队列中；
​			3、G只能运行在M中，一个M必须持有一个P，M与P是1：1的关系。M会从P的本地队列弹出一个可执行状态的G来执行，如果P的本地队列为空，就会想其他的MP组合偷取一个可执行的G来执行；
​			4、一个M调度G执行的过程是一个循环机制；
			5、当M执行某一个G时候如果发生了syscall或则其余阻塞操作，M会阻塞，如果当前有一些G在执行，runtime会把这个线程M从P中摘除(detach)，然后再创建一个新的操作系统的线程(如果有空闲的线程可用就复用空闲线程)来服务于这个P；

			6、当M系统调用结束时候，这个G会尝试获取一个空闲的P执行，并放入到这个P的本地队列。如果获取不到P，那么这个线程M变成休眠状态， 加入到空闲线程中，然后这个G会被放入全局队列中。

		5、场景分析 1
			(1)场景1
				P拥有G1，M1获取P后开始运行G1，G1使用go func()创建了G2，为了局部性G2优先加入到P1的本地队列
				参考图：
					https://img.kancloud.cn/2d/eb/2debce43683adca1acb5ca5210057232_1074x900.png
			 （2）
			 G1运行完成后(函数：goexit)，M上运行的goroutine切换为G0，G0负责调度时协程的切换（函数：schedule）。从P的本地队列取G2，从G0切换到G2，并开始运行G2(函数：execute)。实现了线程M1的复用
			参考图： https://img.kancloud.cn/93/65/93658da22081d52ed1caf32f42145e5a_1624x984.png


六、 channel实现原理
    六、channel 及其 源码 分析
    	channel 是goroutine 之间通信的一种方式。（go 是这样定义的： GO语言不要用共享内存来通信，要用通信来共享内存）

    	1、先介绍 channel类型 （有缓存和无缓存，及阻塞特征）
    	    无缓存通道和有缓存通道
            	1、无缓存通道创建 （读写同步）
            		channel1 := make(chan int ,0) //第二个参数为0，或者不写第二个参数
            	无缓冲通道的特点是，发送的数据需要被读取后，发送才会完成

            	2、有缓存通道创建 （读写不同步）
            		ch := make(chan int, 3)  //容量是3

        2、    阻塞场景：阻塞场景共4个，有缓存和无缓冲各2个。

            	1、无缓存通道阻塞
            		1、通道中无数据，但是执行读通道
            		2、通道无数据，向通道中写数据，但是无协程读取

            	2、有缓存通道阻塞
            		1、通道的缓存无数据，但是执行读通道
            		2、通道的缓存已经占满，向通道中写数据，但是无协程读。

            	3、解决阻塞的方案
            		1、使用select的default语句，在channel不可读写时，即可返回
            		2、使用select+定时器，在超时时间内，channel不可读写，则返回
        3、 收发操作何时会引起panic
           1、通道关闭，在进行发送操作会引发panic

           2、 关闭一个已经关闭的通道也会引发panic

    	2、源码分析
    		1、channel 通过make创建， 返回*hchan 指针类型。hchan 则是 channel 在 golang 中的内部实现
    		hchan 类型如下参考图片链接：https://ask.qcloudimg.com/http-save/yehe-6019987/bk5bw2rxaz.png?imageView2/2/w/1620
    		hchan 结构类型如下：
    			type hchan struct {
    					qcount   uint           // buffer 中已放入的元素个数
    					dataqsiz uint           // 用户构造 channel 时指定的 buf 大小
    					buf      unsafe.Pointer // buffer
    					elemsize uint16         // buffer 中每个元素的大小
    					closed   uint32         // channel 是否关闭，== 0 代表未 closed
    					elemtype *_type         // channel 元素的类型信息
    					sendx    uint           // buffer 中已发送的索引位置 send index
    					recvx    uint           // buffer 中已接收的索引位置 receive index
    					recvq    waitq          // 等待接收的 goroutine  list of recv waiters
    					sendq    waitq          // 等待发送的 goroutine list of send waiters
    					lock mutex
    			}


    			hchan 中的所有属性大致可以分为三类：

    		1、buffer 相关的属性。例如 buf、dataqsiz、qcount 等。 当 channel 的缓冲区大小不为 0 时，buffer 中存放了待接收的数据。使用 ring buffer 实现。（是个循环链表）
    		2、waitq 相关的属性，可以理解为是一个 FIFO 的标准队列。其中 recvq 中是正在等待接收数据的 goroutine，sendq 中是等待发送数据的 goroutine。waitq 使用双向链表实现。
    		3、其他属性，例如 lock、elemtype、closed 等。 （互斥锁）

    		当使用send (ch <- xx)或者recv ( <-ch)的时候，首先要锁住hchan这个结构体。


    	3、什么channel会使用循环链表作为缓存结构
    		个人认为是在缓存列表在动态的send和recv过程中，定位当前send或者recvx的位置、选择send的和recvx的位置比较方便吧，只要顺着链表顺序一直旋转操作就好。
    		缓存中按链表顺序存放，取数据的时候按链表顺序读取，符合FIFO的原则。

    	4、send/recv的细化操作
    		每一步的操作的细节可以细化为：
    		1、加锁
    		2、把数据从goroutine中copy到“队列”中(或者从队列中copy到goroutine中）。
    		3、释放锁

    	5、当channel缓存满了之后会发生什么？这其中的原理是怎样的？

    	1、先 send  在 recv
    		goroutine的阻塞操作，实际上是调用send (ch <- xx)或者recv ( <-ch)的时候主动触发的
    		eg:  goroutine G1 中
    			ch = make(chan int 3);
    		 ch<-1 ;
    		 ch<-1 ;
    		 ch<-1 ;

    		 当chan 已满的时候。G1正在正常运行,当再次进行send操作(ch<-1)的时候，会主动调用Go的调度器,让G1等待，并从让出M，让其他G去使用。G1也会被抽象成含有G1指针和send元素的sudog结构体保存到hchan的sendq中等待被唤醒。

    		 G2执行了recv操作p := <-ch，于是会发生以下的操作：

    		 G2从缓存队列中取出数据，channel会将等待队列中的G1推出，将G1当时send的数据推到缓存中，然后调用Go的scheduler，唤醒G1，并把G1放到可运行的Goroutine队列中。


        2、先进行执行recv操作的G2会怎么样？

      		 这个时候G2会主动调用Go的调度器,让G2等待，并从让出M，让其他G去使用。
    		G2还会被抽象成含有G2指针和recv空元素的sudog结构体保存到hchan的recvq中等待被唤醒
    			此时恰好有个goroutine G1开始向channel中推送数据 ch <- 1。
    		这个时候 G1并没有锁住channel，然后将数据放到缓存中，而是直接把数据从G1直接copy到了G2的栈中。
    这种方式非常的赞！在唤醒过程中，G2无需再获得channel的锁，然后从缓存中取数据。减少了内存的copy，提高了效率。

    		参考链接：https://cloud.tencent.com/developer/article/1750350

七、Map实现原理分析
	1、golang中map是一个kv对集合。底层使用hash table，用链表来解决冲突 ，出现冲突时，不是每一个key都申请一个结构通过链表串起来，而是以bmap为最小粒度挂载，一个bmap可以放8个kv。
	而是以bmap为最小粒度挂载，一个bmap可以放8个kv。在哈希函数的选择上，会在程序启动时，检测 cpu 是否支持 aes，如果支持，则使用 aes hash，否则使用 memhash。
	每个map的底层结构是hmap，是有若干个结构为bmap的bucket组成的数组。每个bucket底层都采用链表结构。
	在这个散列表中，主要出现的结构体有两个，一个叫hmap(a header for a go map)，一个叫bmap(a bucket for a Go map，通常叫其bucket)。这两种结构的样子分别如下所示：
        // A header for a Go map.
        type hmap struct {
            count     int                  // 元素个数
            flags     uint8
            B         uint8                // 扩容常量相关字段B是buckets数组的长度的对数 2^B
            noverflow uint16               // 溢出的bucket个数
            hash0     uint32               // hash seed
            buckets    unsafe.Pointer      // buckets 数组指针
            oldbuckets unsafe.Pointer      // 结构扩容的时候用于赋值的buckets数组
            nevacuate  uintptr             // 搬迁进度
            extra *mapextra                // 用于扩容的指针
        }

        type mapextra struct {
            overflow    *[]*bmap
            oldoverflow *[]*bmap
            nextOverflow *bmap
        }

        // A bucket for a Go map.
        type bmap struct {
            tophash [bucketCnt]uint8        // len为8的数组
        }
        //底层定义的常量
        const (
            // Maximum number of key/value pairs a bucket can hold.
            bucketCntBits = 3
            bucketCnt     = 1 << bucketCntBits
        ）

        但这只是表面(src/runtime/hashmap.go)的结构，编译期间会给它加料，动态地创建一个新的结构：
        type bmap struct {
          topbits  [8]uint8
          keys     [8]keytype
          values   [8]valuetype
          pad      uintptr
          overflow uintptr
        }


	hmap结构图：
	    https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/hmap.png

	bmap结构图
	https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/bmap.png

	整体结构图：
	https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/hmap_bmap.jpeg

	简单的说： Golang的map中用于存储的结构是bucket数组。每个bucket就是 bmap .
	bmap : 由 以下三部分组成。
		高八位hash值。 =》 存储key/value 的字节数组 =〉 一个指向扩容后的bucket的指针

		注意： data区存放的是key-value数据，存放顺序是key/key/key/...value/value/value，如此存放是为了节省字节对齐带来的空间浪费

		每个 bucket 设计成最多只能放 8 个 key-value 对，如果有第 9 个 key-value 落入当前的 bucket，那就需要再构建一个 bucket ，通过 overflow 指针连接起来。

	2、哈希函数会将传入的key值进行hash运算。得到一个唯一的值。go语言把生成的哈希值  “一分为二”

	    例如，现在有一个 key 经过哈希函数计算后，得到的哈希结果是：
            10010111 | 000011110110110010001111001010100010010110010101010 │ 01010


		比如经过一个key 的 hash运算。生成哈希值 88888887777 .go 语言会对hash值拆分。分成 ：  前半部分为高位hash值， 后半部分低位hash值

		高位hash值： 高位用于寻找bucket中的哪个key，便于搜索查找

		低位hash值: 低位用于寻找当前key属于hmap中的哪个bucket

	通俗的说： 低位hash值，用来确定当前key 存在于hmap中的哪个bucket。而地位hash值，用来确定当前key在 在bmap桶 中数组的key，以便获取值。
	3. 哈希冲突
		当有两个或以上数量的键被哈希到了同一个bucket时，我们称这些键发生了冲突。Go使用链地址法来解决键冲突。
由于每个bucket可以存放8个键值对，所以同一个bucket存放超过8个键值对时就会再创建一个键值对，用类似链表的方式将bucket连接起来。
	参考图：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/bmp_bucket.jpeg

	4、如何进行扩容
	    使用哈希表的目的就是要快速查找到目标 key，然而，随着向 map 中添加的 key 越来越多，key 发生碰撞的概率也越来越大。
	    bucket 中的 8 个 cell 会被逐渐塞满，查找、插入、删除 key 的效率也会越来越低。最理想的情况是一个 bucket
	    只装一个 key，这样，就能达到 O(1) 的效率，但这样空间消耗太大，用空间换时间的代价太高。

        Go 语言采用一个 bucket 里装载 8 个 key，定位到某个 bucket 后，还需要再定位到具体的 key，这实际上又用了时间换空间。
        当然，这样做，要有一个度，不然所有的 key 都落在了同一个 bucket 里，直接退化成了链表，各种操作的效率直接降为 O(n)，是不行的。
        因此，需要有一个指标来衡量前面描述的情况，这就是装载因子。Go 源码里这样定义 装载因子：
        loadFactor := count / (2^B)
         count 就是 map 的元素个数，2^B 表示 bucket 数量。

         再来说触发 map 扩容的时机：在向 map 插入新 key 的时候，会进行条件检测，符合下面这 2 个条件，就会触发扩容：
         1、装载因子超过阈值，源码里定义的阈值是 6.5。
         2、overflow 的 bucket 数量过多：当 B 小于 15，也就是 bucket 总数 2^B 小于 2^15 时，如果 overflow 的 bucket 数量超过 2^B；当 B >= 15，也就是 bucket 总数 2^B 大于等于 2^15，如果 overflow 的 bucket 数量超过 2^15。

         // 触发扩容时机
         if !h.growing() && (overLoadFactor(int64(h.count), h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) {
                 hashGrow(t, h)
             }

         // 装载因子超过 6.5
         func overLoadFactor(count int64, B uint8) bool {
             return count >= bucketCnt && float32(count) >= loadFactor*float32((uint64(1)<<B))
         }

         // overflow buckets 太多
         func tooManyOverflowBuckets(noverflow uint16, B uint8) bool {
             if B < 16 {
                 return noverflow >= uint16(1)<<B
             }
             return noverflow >= 1<<15
         }
        解释：
            第 1 点：我们知道，每个 bucket 有 8 个空位，在没有溢出，且所有的桶都装满了的情况下，装载因子算出来的结果是 8。
            因此当装载因子超过 6.5 时，表明很多 bucket 都快要装满了，查找效率和插入效率都变低了。在这个时候进行扩容是有必要的。

            第 2 点：是对第 1 点的补充。就是说在装载因子比较小的情况下，这时候 map 的查找和插入效率也很低，而第 1 点识别不出来这种情况。
            表面现象就是计算装载因子的分子比较小，即 map 里元素总数少，但是 bucket 数量多（真实分配的 bucket 数量多，包括大量的 overflow bucket）

            对于命中条件 1，2 的限制，都会发生扩容。但是扩容的策略并不相同，毕竟两种条件应对的场景不同。

            3、对于条件 1，元素太多，而 bucket 数量太少，很简单：将 B 加 1，bucket 最大数量（2^B）直接变成原来 bucket 数量的 2 倍。
            于是，就有新老 bucket 了。注意，这时候元素都在老 bucket 里，还没迁移到新的 bucket 来。
            而且，新 bucket 只是最大数量变为原来最大数量（2^B）的 2 倍（2^B * 2）。

            4、对于条件 2，其实元素没那么多，但是 overflow bucket 数特别多，说明很多 bucket 都没装满。
            解决办法就是开辟一个新 bucket 空间，将老 bucket 中的元素移动到新 bucket，使得同一个 bucket 中的 key 排列地更紧密。
            这样，原来，在 overflow bucket 中的 key 可以移动到 bucket 中来。结果是节省空间，提高 bucket 利用率，map 的查找和插入效率自然就会提升。




八、slice 及数组 区别和源码

	1、slice和数组的区别和源码
		数组：数组是类型相同的元素的集合。Go不允许在数组中混合使用不同类型的元素
		切片：在Go中，切片是长度可变，容量固定的相同元素序列。Go的本质其实是一个动态数组。

		1、切片的创建
			1、make （[]type,length,capacity)  和 []Type{} ，以及从数组中创建。

	2、slice源码

		type slice struct{
			array unsafe.Pointer	 // Pointer 是一个指向数组的指针
			len int   // len 代表当前切片的长度
			cap int   // cap 是当前切片的容量
		}

	3、空切片和nil切片
		1、nil 切片  var slice []int
		2、空切片 （ slice := make([]int,0) 和 slice := []int{} ）

		nil切片用来表述一个不存在的切片。 空切片用来表示一个空的集合。
		空切片指向的地址不是nil,指向的一个内存地址。它没有分配任何空间，即底层元素包含0个元素。
		nil切片底层指向的是一个 nil .


	4、切片扩容及策略

		1、扩容策略
			1、首先先判，如果新申请容量（cap）大于2倍的旧容量（old.cap）,最终容量（newCap）就是新申请的容量（cap）
			2、否则判断，如果旧切片的长度小于1024，则最终容量（newcap），就是旧容量（old.cap）的两倍。即newcap = 			doublecap
			3、否者判断，如果旧切片的长度大于等于1024，则最终容量（newcap）从旧容量	old.cap）的两倍。即newcap开始循环增加原来的1/4 即 （参考slice源码）newcap = old.cap for {newcap += newcap/4},直到最终容量（newcap) 大于等于新申请的容量cao .即 newcap 》= cap .

	5、切片扩容后是新数组or 旧数组
		扩容之后的数组一定是新的嘛？这个不一定分两种情况。
		1、情况1
			如果原数组还有容量可以扩容，则在执行append（）操作后，会在原数组上直接操作，所以这时候，切片扩容后的数组还是指向的原来数组，并且原来数组会跟随改变。
			demo:

		array := [6]int{1,2,3,4,5,6}
		fmt.Printf("1、array: %+v\n",array)

		slice1 := array[1:4]
		fmt.Printf("2、slice1: %+v,cap:%d ",slice1,cap(slice1))
		fmt.Printf("3、array: %+v\n",array)

		slice1 = append(slice1, 9,10,11,12,23,45,67,78)
		fmt.Printf("4、slice1: %+v\n",slice1)
		fmt.Printf("5、array: %+v\n",array)


	这种情况 及容易出现在使用字面量创建切片的时候。要谨慎。


	   2、情况二

	   	 如果原来的数组的容量已经将达到了最大值，则在扩容时会根据扩容策略，开辟一片新的内存区域，把原来数组的值拷贝过来，然后执行append操作，这个时候不会影响原数组。




九、切片作为函数参数是传值还是传引用

1、切片作为函数参数是传值还是传引用？


	eg:

func changeSlice(s []int){
	s[1] = 111
}

func testSlice() {
	slice := []int{0, 1, 2, 3,}
	fmt.Printf("slice:%+v,\n", slice)

	changeSlice(slice)
	fmt.Printf("new slice:%+v\n", slice)
}

输出结果：
slice:[0 1 2 3],
new slice:[0 111 2 3]


上述 代码虽然slice 的值变了。但不是引用传递。

 1、理清三个重要的 概念。
 	1、值传递
 		值传递是指在调用函数时将实际参数拷贝一份传递到函数中，这样在函数中对参数进行修改不会影响到实际参数。

 	2、传指针
 		传指针是指 形参是指向实际参数的指针，当对形参的指向进行操作时，相当于对实参本身进行操作。

 	demo :
 	func main (){
 		a := 10
 		pa :=&a
 		modify(pa)
 		fmt.printf("a=",a)
 	}

 	func modifty(p *int){
 		*p = 1
 	}

 	上述代码，
 	pa 和p 虽然值相同 都是指向 a的内存地址，但是存放pa 和p 的内存地址是不同的，因此是两个不同的指针，但是 修改时指向的值时，a也会改变。

 	3、引用传递
 		引用传递是指调用函数时将实际参数的地址传递到函数中，在函数中对参数进行修改，影响实际参数。


 2、Go 官方文档明确指出： Go里面函数传参只有值传递一种方式。


Go语言中所有的传参都是值传递(传值)，都是一个副本，一个拷贝。
因为拷贝的内容有时候是非引用类型(int、string、struct等这些)，这样就在函数中就无法修改原内容数据；
有的是引用类型(指针、map、slice、chan等这些)，这样就可以修改原内容数据。

这里要注意的是：引用类型和传引用是两个概念。


 3、切片参数，修改形参一定影响实参吗？
 	当 “切片扩容” 的时候是不会影响实参的。
 	原因：
 	demo :
 func main() {
    slice := make([]int, 2, 3)
    for i := 0; i < len(slice); i++ {
        slice[i] = i
    }

    fmt.Printf("slice: %v, addr: %p \n", slice, slice)

    changeSlice(slice)
    fmt.Printf("slice: %v, addr: %p \n", slice, slice)
}

func changeSlice(s []int){
    s = append(s, 3)
    s = append(s, 4)
    s[1] = 111
    fmt.Printf("func s: %v, addr: %p \n", s, s)
}

原因：切片扩容是不会影响 底层数组的。 （参考slice源码）

	扩容详情：
		1、无论数组还是切片，都有长度限制。也就是追加切片的时候，如果元素正好在切片的容量范围内，直接在尾部追加一个元素即可。如果超出了最大容量，再追加元素就需要针对底层的数组进行复制和扩容操作了。
也就是说：

	2、使用append方法给slice追加元素的时候，由于slice的容量还未满，因此等同于扩展了slice指向数组的内容，可以理解为重新切了一个数组内容附给slice，同时修改了数组的内容。
	3、使用append方法给slice追加元素的时候，如果此时slice的容量已满，再进行追加时，超出了切片的容量，数组就会越界了，于是就会出现扩容操作
	4、当需要扩容时，append会做哪些操作呢？
	创建一个新的临时切片t，t的长度和slice切片的长度一样，但是t的容量是slice切片的2倍，新建切片的时候，底层也创建了一个匿名的数组，数组的长度和切片容量一样。（实际上不一定是两倍扩容，详情可参考文章 Golang 中关于slice扩容策略）
	2、复制slice里面的元素到t里，即填入匿名数组中。然后把t赋值给slice，现在slice的指向了底层的匿名数组。3
	3、转变成小于容量的append方法。
	详情参见slice源码八、

十、反射

十一、逃逸分析

一、逃逸分析

   1、缘起
   前段时间跟项目组leader聊到golang编码规范时，我提到一个问题。
   我：“golang函数传参是不是应该跟c一样，尽量不要直接传结构体，而要传结构体指针？“
   leader：“不对，咱们项目很多都是直接传结构体的。“
   我：“那样不会造成不必要的内存copy开销吗？”
   leader：“确实会有，但这样可以减小gc压力，因为传值会在栈上分配，而一旦传指针，结构体就会逃逸到堆上。“
   我：“有道理。。。“
   由于之前是搞java的，关于逃逸分析在golang的上规则还不是很熟，因此，后来在心里一直记得：
   “一旦将某个局部变量以指针的方式传出，该变量就会逃逸到堆”。
   但是我内心还是对这种说法一直存在疑惑，所以一直想找个机会好好学习一下

   2、什么是逃逸分析
      在计算机语言编译器优化原理中，逃逸分析是指分析指针动态范围的方法，它同编译器优化原理的指针分析和外形分析相关联。当变量（或者对象）在方法中
      分配后，其指针有可能被返回或者被全局引用，这样就会被其他过程或者线程所引用，这种现象称作指针（或者引用）的逃逸。

    说白了就是：逃逸分析是编译器用于决定变量分配到栈还是堆上的一种行为。
      go在一定程度上消除了堆和栈的区别，因为go在编译的时候进行了逃逸分析，来决定一个对象放到栈上还是堆上，不逃逸的对象放栈上，可能逃逸的放到堆上

   3、逃逸分析场景
   准备知识：
    goland的逃逸分析是在编译期完成的，并且Goland 的逃逸分析只针对指针。一个值引用如果没有被取地址，那么它永远不可能逃逸。

    go run -gcflags "-m -l"
    情景1：典型的逃逸case，函数返回局部变量的指针。
    demo1:
        func test() *User{
            a := User{}
            return &a
        }

        func test1()*int{
            var a =10
            return &a
        }

    情景2：被指针类型的slice，map 和 chan 引用的指针一定发生逃逸。
       备注：在stack overflow有人提问为什么使用指针的chan比使用值的chan慢30%，就是因为使用指针的chan发生了逃逸，gc拖慢了速度。
       a := make([]*int,1)
       b := 12
       a[0] = &b

    情景3：逃逸指针引用逃逸
        被已经逃逸的变量引用的指针，一定发生逃逸。这里是fmt.Printf里，func newPrinter() *pp {…} pp指针逃逸了，所以传入的word被一个逃逸的指针引用了，必然逃逸。
    情景4：栈空间不足逃逸,变量对象发生逃逸被分配到堆上
            func test {
                t := make([]int ,1000,1000)
                s :=make([]itn,10000,10000)
                for i:=0;i<len(s);i++{
                    s[i[]= i
                }
            }

         当s的容量足够大时，s逃逸到堆上。t容量较小分配到栈上


    情景5:动态类型逃逸
          当对象不确定大小或者被作为不确定大小的参数时发生逃逸。

    必然不会逃逸
    • 指针被未发生逃逸的变量引用；
    • 仅仅在函数内对变量做取址操作，而未将指针传出


    4、逃逸分析的好处
        1、减少gc压力，不逃逸的对象分配到栈上，当函数返回时就回收了资源，不需要gc标记清除
        2、逃逸分析后可以确定那变量可以分配到栈上，栈的分配比堆快，因此性能更好。


十三、进程、线程、协程，goroutine 区别
    1、进程是系统资源分配的最小单位。
    进程有三个状态:
        1、等待态：等待某个事件的完成；
        2、就绪态：等待系统分配处理器以便运行；
        3、运行态：占有处理器正在运行。

    进程是抢占式的争夺CPU运行自身,而CPU单核的情况下同一时间只能执行一个进程的代码,
    但是多进程的实现则是通过CPU飞快的切换不同进程,因此使得看上去就像是多个进程在同时进行.

    进程间通信（IPC，InterProcess Communication）是指在不同进程之间传播或交换信息。
    由于每个进程的用户空间都是独立的，不能相互访问，
    这时就需要借助内核空间来实现进程间通信，原因很简单，每个进程都是共享一个内核空间。

    IPC的方式通常有
    管道:通信的数据是无格式的流并且大小受限，通信的方式是单向的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道
    消息队列:消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。
    共享内存:mmp
    信号量
    信号:信号是进程间通信机制中唯一的异步通信机制，
    Socket：
        要与不同主机的进程间通信，那么就需要 Socket 通信了。Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。

    管道（包括无名管道和命名管道）、消息队列、信号量、共享存储、Socket、Streams等。其中 Socket和Streams支持不同主机上的两个进程IPC。

    2、线程是CPU 独立运行的基本单位

    线程间通信：
    1、锁机制 （互斥锁（Mutual Exclusion，Mutex）是一种用于多线程编程中，防止两条线程同时对同一公共资源（比如全局变量）进行读写的机制。）
    2、信号和信号量

    一是单个线程消耗的内存过多，比如 64 位的 Linux 为每个线程的栈分配了 8MB 的内存

    进程和线程区别：
    1、同一个进程中可以包括多个线程；进程结束后它拥有的所有线程都将销毁，而线程的结束不会影响同个进程中的其他线程的结束；
    2、线程共享进程的地址空间，而进程有自己独立的地址空间。


    3、协程 （协程就是用户态的线程。）
       1、 通常创建协程时，会从进程的堆中分配一段内存作为协程的栈。线程的栈有 8MB，而协程栈的大小通常只有几十 KB
       2、 协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。
        协程调度切换时，将寄存器上下文和栈保存到其他地方，
        在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，
        可以不加锁的访问全局变量，所以上下文的切换非常快。

    协程与线程的区别:
        1) 一个线程可以多个协程，一个进程也可以单独拥有多个协程。


十四、虚拟内存和物理内存区别，操作系统如何控制，如何使用；
    物理内存地址是主存真实的地址，而虚拟内存则是作为一个抽象层，成为了进程和物理内存的桥梁。
    虚拟内存和物理内存是通过 MMU(Memory Management Unit，内存管理单元) 来进行转换和映射的，
    内存管理单元中最重要的数据结构就是页表，在页表中，虚拟地址有三种状态：未被使用、未被缓存、已缓存：
    1、如果是未被使用，则该虚拟地址并不存在于磁盘或者主存中；
    2、如果是未被缓存的状态，说明虚拟地址此时对应的真实地址为磁盘地址，如果此时进程去访问未被缓存的虚拟地址，会触发缺页中断，操作系统会将磁盘上未被缓存的虚拟页加载到主存中，然后更新页表；
    3、如果是已缓存的状态，说明虚拟地址此时对应的地址就是物理内存，也就是我们的主存。