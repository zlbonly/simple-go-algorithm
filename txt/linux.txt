
Linux 基础 知识 准备

Linux 基础知识

	1、Linux架构层级
		Application -》 Shell 和 公共函数库 -〉系统调用 -》 内核

		Apllication: 在操作系统上安装并运行的用户态层序
		Shell : 支持编程的命令解析器
		Libs: 操作系统表标准库函数
		System Calls：暴露给用户的内核态系统调用接口
		Kernel: 操作系统的核心，真正对接硬件平台的软件程序

	操作系统将虚拟内存划分为两部分，一部分是内核空间（Kernel-space）,一部分是用户空间（User-space）。在Linux系统中
	内核模块运行在内核空间，对应的进程处于内核态，而用户程序运行在用户空间，对应的进程处于用户态。


Linux I/O多路复用技术
Linux 五种I/O模型

1、基本概念
linux I/O主要分为: 阻塞IO(Blocking IO)，非阻塞IO(Non-blocking IO)，同步IO(Sync IO)和异步IO(Async IO)

同步：调用端会一直等待服务端响应，直到返回结果。
异步：调用端发起调用之后不会立刻返回，不会等待服务端响应。服务端通过通知机制或者回调函数来通知客户端。

阻塞：服务端返回结果之前，客户端线程会被挂起，此时线程不可被CPU调度，线程暂停运行。
非阻塞：在服务端返回前，函数不会阻塞调用端线程，而会立刻返回。


2、Linux 五种I/O模型
2.1 阻塞I/O（blocking IO）
	进程会一直阻塞，直到数据拷贝完成应用程序调用一个IO函数，导致应用程序阻塞，等待数据准备好。数据准备好后，从内核拷贝到用户空间，IO函数返回成功指示。
	阻塞IO模型图如下所示：
	https://user-gold-cdn.xitu.io/2019/2/24/1691ebff3e4ebf27?imageView2/0/w/1280/h/960/format/webp/ignore-error/1

2.2 非阻塞IO模型
	通过进程反复调用IO函数，在数据拷贝过程中，进程是阻塞的。
	模型图：	https://user-gold-cdn.xitu.io/2019/2/24/1691ebf25c789918?imageView2/0/w/1280/h/960/format/webp/ignore-error/1

2.3 IO复用模型
	主要是select和epoll。一个线程可以对多个IO端口进行监听，当socket有读写事件时分发到具体的线程进行处理.
	模型如图：
		https://user-gold-cdn.xitu.io/2019/2/24/1691ebf25c7146fa?imageView2/0/w/1280/h/960/format/webp/ignore-error/1

2.4 信号驱动IO模型
	信号驱动式I/O：首先我们允许Socket进行信号驱动IO,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。
	过程图：
		https://user-gold-cdn.xitu.io/2019/2/24/1691ec1919c6fa00?imageView2/0/w/1280/h/960/format/webp/ignore-error/1

2.5 异步IO模型
	相对于同步IO，异步IO不是顺序执行。用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。IO两个阶段，进程都是非阻塞的

	过程图：https://user-gold-cdn.xitu.io/2019/2/24/1691ec1919b4b16b?imageView2/0/w/1280/h/960/format/webp/ignore-error/1

3、IO复用之select、poll、epoll简介 (用少量的线程来处理网络上大量的TCP连接中的I/O。)

3.1 select

	Select会将全量fd_set从用户空间拷贝到内核空间，并注册回调函数， 在内核态空间来判断每个请求是否准备好数据 。select在没有查询到有文件描述符就绪的情况下，将一直阻塞（I/O多路服用中提过：select是一个阻塞函数）。如果有一个或者多个描述符就绪，那么select将就绪的文件描述符置位，然后select返回。返回后，由程序遍历查看哪个fd请求有数据。

	缺点：
	1、每次调用select，都需要把fd集合从用户态拷贝到内核态，fd越多开销则越大；
	2、每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大
	3、select支持的文件描述符数量有限，默认是1024。参见/usr/include/linux/posix_types.h中的定义：

	#define __FD_SETSIZE         1024 (内核中有个参数__FD_SETSIZE定义了每个FD_SET的句柄个数)

3.2 poll
int poll ( struct pollfd * fds, unsigned int nfds, int timeout);

pollfd结构体：
struct pollfd {
    int fd;               /* 文件描述符 */
    short events;         /* 等待的事件 */
    short revents;        /* 实际发生了的事件 */
} ;

	poll本质和select相同，将用户传入的数据拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或主动超时，被唤醒后又要再次遍历fd。它没有最大连接数的限制，原因是它是基于链表来存储的


	缺点：
		1、poll函数和select相同都是将大量文件描述符信息从用户空间拷贝到内核空间。
		2、poll函数没有解决select轮训所有文件描述符的问题。

3.3 epoll

	1、epoll的相关函数
	#include <sys/epoll.h>
	int epoll_create(int size);

	int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);

	int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);


	1、epoll_create
		当某个进程调用epoll_create时 内核会创建一个eventpoll对象（也就是程序中epfd所代表的对象）

	2、epoll_ctl
		向epoll中注册事件，该函数如果调用成功返回0，否则返回-1。
		该函数主要是对内核事件表的操作，涉及插入（添加监听描述符）、删除（删除被监听的描述符）、修改（修改被监听的描述符）。

		示例：
			如果通过epoll_ctl添加sock1、sock2和sock3的监视 内核会将eventpoll添加到这三个socket的等待队列中。
			当socket收到数据后，中断程序会操作eventpoll对象，而不是直接操作进程。（当socket收到数据后，中断程序会给eventpoll的“就绪列表”添加socket引用）

	3、epoll_wait
		epoll_wait的功能就是不断查看就绪队列中有没有描述符，如果没有就一直检查、直到超时。如果有就绪描述符，就将就绪描述符通知给用户

	epoll过程：
		epoll不会让每个 socket的等待队列都添加进程A引用，而是在等待队列，添加 eventPoll对象的引用。当socket就绪时，中断程序会操作eventPoll，在eventPoll中的就绪列表(rdlist)，添加scoket引用。这样的话，进程A只需要不断循环遍历rdlist，从而获取就绪的socket。从代码来看每次执行到epoll_wait，其实都是去遍历rdlist。如果rdlist为空，那么就阻塞进程。当有socket处于就绪状态，也是发中断信号，再调用对应的中断程序。此时中断程序，会把socket加到rdlist，然后唤醒进程。进程再去遍历rdlist，获取到就绪socket。
		总之：poll轮询的是所有的socket。而epoll只轮询就绪的socket。

epoll将“维护监视队列”和“进程阻塞”分离，也意味着需要有个数据结构来保存监视的socket。
补充知识：eventpoll内核事件表的底层数据结构是红黑树，rdlist就绪描述符的底层数据结构是双向链表

	epoll的优点：
	1、没有最大并发连接的限制。
	2、效率提升，只有活跃可用的FD才会调用callback函数。
	3、内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递。

	epoll的水平触发（LT）和 边缘触发（ET）

	1、LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错误可能性要小一点。传统的select/poll都是这种模型的代表．

	优点：当进行socket通信的时候，保证了数据的完整输出，进行IO操作的时候，如果还有数据，就会一直的通知你。

	缺点：由于只要还有数据，内核就会不停的从内核空间转到用户空间，所有占用了大量内核资源，试想一下当有大量数据到来的时候，每次读取一个字节，这样就会不停的进行切换。内核资源的浪费严重。效率来讲也是很低的。

	2、ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知。请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once).

	优点：每次内核只会通知一次，大大减少了内核资源的浪费，提高效率。

	缺点：不能保证数据的完整。不能及时的取出所有的数据。

	应用场景： 处理大数据。使用non-block模式的socket。


	参考链接：https://zhuanlan.zhihu.com/p/64746509


Linux零拷贝技术

   1、为什么需要零拷贝。
          传统的 Linux 系统的标准 I/O 接口（read、write）是基于数据拷贝的，也就是数据都是 copy_to_user 或者 copy_from_user，
          这样做的好处是， 通过中间缓存的机制，减少磁盘 I/O 的操作，但是坏处也很明显，大量数据的拷贝，用户态和内核态的频繁切换，
          会消耗大量的 CPU 资源，严重影响数据传输的性能，有数据表明，在Linux内核协议栈中，
          这个拷贝的耗时甚至占到了数据包整个处理流程的57.1%。

          linux 原始数据拷贝。例如：某个应用程序需要从磁盘读取某个内容，然后通过网络发送出去，

          while((n = read(diskfd, buf, BUF_SIZE)) > 0)
              write(sockfd, buf , n);

              大致经过的流程：
              1、read()将数据从磁盘文件，通过DMA（Direct Memory Access 直接内存读取）等方式拷贝到内核开辟的缓冲区。
              2、数据从内核缓冲区复制到 用户缓冲区
              3、write() 将数据从用户态缓冲区复制到内核协议栈开辟的socket缓冲区
              4、数据从socket缓冲通过DMA拷贝到网卡发送出去。


   2、 什么是零拷贝
            零拷贝是解决1问题的一种解决方案，通过尽量避免拷贝操作来缓解CPU压力。
            Linux 下常见的零拷贝技术可以分为两大类：一是针对特定场景，去掉不必要的拷贝；二是去优化整个拷贝的过程。
            由此看来，零拷贝并没有真正做到“0”拷贝，它更多是一种思想，很多的零拷贝技术都是基于这个思想去做的优化。


        2.1 特定场景的零拷贝

            2.1.1 用户态直接I/O
                使应用程序或者运行在用户态下的库函数直接访问硬件设备，数据直接跨过内核进行传输，内核在整个数据传输过程中除了会进行必要的虚拟
                存储配置工作外，不参与其他任何工作，这种方式直接绕过内核，极大提高性能
                （参考图片）https://pic3.zhimg.com/80/v2-2863a48a73b6438cf96996b7ed992d72_1440w.jpg

                缺陷：
                1、这种方法只能适用于那些不需要内核缓冲区处理的应用程序，这些应用程序通常在进程
                这些应用程序通常在进程地址空间有自己的数据缓存机制，称为自缓存应用程序，如数据库系统就是一个代表
                2、这些方法直接操作磁盘I/O，由于CPU和磁盘I/O 之间的执行时间差距，会造成资源的浪费，解决这个问题需要和异步I/O结合使用

            2.1.2 mmap (内存映射)
                使用mmap 内存映射来代替 read,可以减少一次拷贝操作，流程如下：
                buf = mmap(diskfd,len);write(sockfd,buf,len)；
                应用程序调用mmap,磁盘文件的数据通过DMA拷贝到内核缓冲区，
                接着操作系统会将这个缓冲区与应用程序共享，这样就不用往用户空间拷贝。应用程序调用write，操作系统直接将数据从内核缓冲区拷贝到socket缓冲区，
                最后在通过DMA拷贝到网卡发送出去。相当于只进行了3次拷贝。
                流程参考图：https://pic1.zhimg.com/80/v2-682495ea64eda8eaea168fc125539d14_1440w.jpg

                缺陷：
               1）mmap 隐藏着一个陷阱，当 mmap 一个文件时，如果这个文件被另一个进程所截获，
                    那么 write 系统调用会因为访问非法地址被 SIGBUS 信号终止，SIGBUS 默认会杀死进程并产生一个 coredump，
                    如果服务器被这样终止了，那损失就可能不小了。

                解决这个问题通常使用文件的租借锁：首先为文件申请一个租借锁，当其他进程想要截断这个文件时，内核会发送一个实时的 RT_SIGNAL_LEASE 信号，告诉当前进程有进程在试图破坏文件，
                这样 write 在被 SIGBUS 杀死之前，会被中断，返回已经写入的字节数，并设置 errno 为 success。
                通常的做法是在 mmap 之前加锁，操作完之后解锁：

            2.1.3 sendfile
                从Linux 2.1版内核开始，Linux引入了sendfile，也能减少一次拷贝。
                eg: #include<sys/sendfile.h>ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);

                sendfile系统调用在两个文件描述符之间直接传递数据(完全在内核中操作)，
               从而避免了数据在内核缓冲区和用户缓冲区之间的拷贝，操作效率很高，被称之为零拷贝。

               流程；
               1、sendfile() 系统调用利用 DMA 引擎将文件中的数据拷贝到操作系统内核缓冲区中，
               2、 然后数据被拷贝到与 socket 相关的内核缓冲区中去。
               3、DMA 引擎将数据从内核 socket 缓冲区中拷贝到协议引擎中去

              缺陷：
                    sendfile() 系统调用不需要将数据拷贝或者映射到应用程序地址空间中去，
                    所以 sendfile() 只是适用于应用程序地址空间不需要对所访问数据进行处理的情况。

               优点： sendfile 传输的数据没有越过用户应用程序 / 操作系统内核的边界线，所以 sendfile () 也极大地减少了存储管理的开销


            2.1.4 DMA 辅助的sendfile
                常规 sendfile 还有一次内核态的拷贝操作。可以使用DMA辅助的sendfile 去掉内核态内的拷贝，流程如下：
                1、首先，sendfile() 系统调用利用 DMA 引擎将文件内容拷贝到内核缓冲区去；
                2、将带有文件位置和长度信息的缓冲区描述符添加到 socket 缓冲区中去，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，
                3、DMA 引擎会将数据直接从内核缓冲区拷贝到协议引擎中去，这样就避免了最后一次数据拷贝。

                流程参考图如下：
                    https://pic4.zhimg.com/v2-63a6315bcda173d1a89f649ee0939f17_r.jpg

                    缺陷：只适用于将数据从文件拷贝到套接字上 及2.1.3中的缺陷

            2.1.5 splice
                splice 去掉 sendfile 的使用范围限制，可以用于任意两个文件描述符中传输数据。
                #define _GNU_SOURCE /* See feature_test_macros(7) */#include <fcntl.h>ssize_t splice(int fd_in, loff_t *off_in, int fd_out, loff_t *off_out, size_t len, unsigned int flags);
                但是 splice 也有局限，它使用了 Linux 的管道缓冲机制，所以，它的两个文件描述符参数中至少有一个必须是管道设备。
                缺陷：

                1）同样只适用于不需要用户态处理的程序

                2）传输描述符至少有一个是管道设备。

        2.2 优化零拷贝

            2.2.1  写时复制
                   在某些情况下，内核缓冲区可能被多个进程所共享，如果某个进程想要这个共享区进行 write 操作，
                   由于 write 不提供任何的锁操作，那么就会对共享区中的数据造成破坏，写时复制就是 Linux 引入来保护数据的。

                   写时复制，就是当多个进程共享同一块数据时，如果其中一个进程需要对这份数据进行修改，那么就需要将其拷贝到自己的进程地址空间中，
                   这样做并不影响其他进程对这块数据的操作，每个进程要修改的时候才会进行拷贝，所以叫写时拷贝。这种方法在某种程度上能够降低系统开销，如果某个进程永远不会对所访问的数据进行更改，那么也就永远不需要拷贝。

            2.2.2   缓存区共享

                这种方法完全改写 I/O 操作，因为传统 I/O 接口都是基于数据拷贝的，要避免拷贝，就去掉原先的那套接口，重新改写，所以这种方法是比较全面的零拷贝技术，目前比较成熟的一个方案是最先在 Solaris 上实现的 fbuf （Fast Buffer，快速缓冲区）。

                Fbuf 的思想是每个进程都维护着一个缓冲区池，这个缓冲区池能被同时映射到程序地址空间和内核地址空间，内核和用户共享这个缓冲区池，这样就避免了拷贝。

   参考链接： https://zhuanlan.zhihu.com/p/78388827


二、socket 编程
Socket(套接字)是网络编程的一个抽象概念，是在应用层和传输层的一个抽象层，它把TCP/IP层复杂的操作抽象为简单的API接口，
	供应用层调用，实现进程在网络中的通信。

	扩展： Socket起源于UNIX，在Unix一切皆文件的思想下，进程间通信就被冠名为文件描述符（file desciptor），Socket是一种“打开—读/写—关闭”模式的实现，服务器和客户端各自维护一个“文件”，在建立连接打开后，可以向文件写入内容供对方读取或者读取对方内容，通讯结束时关闭文件。


	socket 位置图：https://pic2.zhimg.com/80/v2-07267d9c6efe0e7f290eaacedb37ebc9_720w.jpg


socket 函数说明：

1、socket():  用于创建一个socket描述符（sockfd）

int socket(int domain, int type, int protocol);

domain: 协议域。 AF_INET,AF_INET6等
type ： socket 类型。常用的socket类型有：sock_stream,sock_dgram，sock_nonblock等
protocol: 协议类型（常用的协议类型，IPPROTO_TCP,IPPTOTO_UDP等）


调用socket()函数创建一个socket时，返回的socket描述符，存在于协议族（address family AF_XXX）空间中
，但没有一个具体的地址。如果想要分配赋值一个地址，就必须调用用bind() 函数，否则当调用connect()和listen()时
系统会自动随机分配一个端口。

说明： 如果socket函数type没有指定sock_nonblock时，，socket函数返回的“套接字文件描述符”默认就是阻塞的，所以使用
accept函数来监听客户连接时，如果没有客户请求连接，accept函数就会组赛，直到有客户连接为止


2、connect():
	connect函数主要为了客户端主动连接服务器，建立连接是通过三次握手，而这个连接建立的过程是由内核完成的，并不是通过connect函数
完成。connect函数仅仅是为了通知Linux内核，让内核自动完成TCP三次握手，最后在把连接的结果返回给这个函数的返回值（连接成功0，失败为-1）。通常情况下，客户端的connect()函数默认会一只阻塞，直到三次握手成功或者超时失败才返回。


3、listen()函数：
 	#include<sys/socket.h>
 	int listen(int sockfd, int backlog);
	listen()函数的主要作用就是将套接字（sockfd 套接字文件描述符fd）变成被动的连接监听套接字（被动的等待客户端连接），
	至于参数backlog的作用是设置内核连接队列的长度，TCP三次握手也不是由这个函数完成，listen（）函数的作用仅仅是告诉内核一些信息

  ！！！ listen() 函数不会阻塞，它主要做的事情为，将该套接字描述符（sockfd）和套接字对应的连接队列长度告诉linux内核，然后listen()函数 完成结束。

4、accept()

accept函数的linux头文件以及函数定义：
#include<sys/socket.h>
int accept ( int sockfd,  struct sockaddr * addr, socklen_t * len )

 说明：
 	sockfd 上述listen函数指定的监听socket
 	sockaddr 请求连接方（客户端）地址
 	socklen_t 客户端长度
 	@return  函数执行成功返回一个新的连接socket，失败返回 -1

 	accept函数返回值：一个新的连接socket（因此也称为已连接套接字），该socket唯一标示了接受的新连接。后续双方可以利用已连接套接字进行通信。




6、read/write 和 recv/send
	从套接字接收和发送数据。
	recv()所做的工作，就是把内核缓冲区中的数据拷贝到应用层用户的buffer里面，并返回，仅此而已。进程调用send()发送的数据的时候，最简单情况（也是一般情况），将数据拷贝进入socket的内核发送缓冲区之中，然后send便会在上层返回

7、recvfrom/sendto
	recvfrom 与 recv功能基本相同，sendto和send功能基本相同 只不过sendto函数和revcfrom 函数参数中都带有对方地址
	信息。 针对UDP无连接协议 必须使用sendto函数发送数据，必须使用recvfrom函数接收数据，发送时需要指明目的地址。

8、socket通信三次握手 (参考TCP三次握手)
    1、三次握手
        流程图参考： http://images.cnblogs.com/cnblogs_com/skynet/201012/201012122157467258.png
   1、 当客户端调用connect时，触发了连接请求，向服务器发送了SYN J包，这时connect进入阻塞状态；
   2、服务器监听到连接请求，即收到SYN J包，调用accept函数接收请求向客户端发送SYN K ，ACK J+1，这时accept进入阻塞状态；
   3、客户端收到服务器的SYN K ，ACK J+1之后，这时connect返回，并对SYN K进行确认；服务器收到ACK K+1时，accept返回，至此三次握手完毕，连接建立。

   总结；客户端的connect在三次握手的第二个次返回，而服务器端的accept在三次握手的第三次返回。

9、socket中TCP的四次握手释放连接详解（参考TCP四次挥手）

    流程图参考：http://images.cnblogs.com/cnblogs_com/skynet/201012/201012122157487616.png

    1、某个应用进程首先调用close主动关闭连接，这时TCP发送一个FIN M；
    2、另一端接收到FIN M之后，执行被动关闭，对这个FIN进行确认。它的接收也作为文件结束符传递给应用进程，因为FIN的接收意味着应用进程在相应的连接上再也接收不到额外数据；
    3、一段时间之后，接收到文件结束符的应用进程调用close关闭它的socket。这导致它的TCP也发送一个FIN N；
    4、接收到这个FIN的源发送端TCP对它进行确认。

参考连接：
1、https://zhuanlan.zhihu.com/p/109826876
2、https://www.cnblogs.com/niwotaxuexiba/p/9700764.html


二、TCP连接（三次握手/四次挥手）
报文中字段解释：
 1） 序号：seq序号，占32位，用来标识从TCP源端向目地端发送的字节流
 2） 确认号 ack号，占32位，期待收到对方下一个报文段的第一个数据字节的序号。
 3）标识位 （flags）共6哥，即URG,ACK,PSH,RST,SYN,FIN等。具体含义如下
 	（A）URG：紧急指针（urgent pointer）有效，值为1时表示某一位需要优先处理。
	（B）ACK：确认序号有效，一般为1。
	（C）PSH：接收方应该尽快将这个报文交给应用层。
	（D）RST：重置连接。
	（E）SYN：请求建立连接，并在其序列号的字段进行序列号的初始值设定。建立连接，设置为1。
	（F）FIN：发送断开连接请求。

1、三次握手

	三次握手 其实就是指建立一个TCP连接时，需要客户端和服务器总共发送3个包。进行三次握手的主要作用就是为了确认双方的
	接收能力和发送能力是否正常，指定自己的初始化序列号为后面的可靠性传送做准备。

	三次握手过程：

	1、第一次握手：
		客户端给服务端发一个SYN报文，并指明客户端的初始化序列号ISN，此时客户端处于SYN_SEND状态 （
	首部的同步位SYN=1 ，初始化序号seq=x，SYN=1的报文段不能携带数据，但是要消耗掉一个序号）
	2、第二次握手
		服务器收到客户端的SYN报文之后，会以自己的SYN报文作为应答，并且也是指定了自己的初始化序列号ISN。同时把客户端的ISN+1
		作为ACK的值，表示自己已经收到了客户端的SYN，此时服务器处于SYN_REVD状态。
		在确认报文段中，SYN=1，ACK=1，确认号ack=x+1,初始化序号 seq=y
	3、第三次握手
		客户端收到SYN报文之后，会发送一个ACK报文，把服务器的ISN+1作为ACK的值，表示已经收到了服务端的SYN报文，此时
		客户端处于ESTABLISHED 状态。服务器收到ACK报文之后也处于ESTABLISHED状态，此时双方已建立起了连接。

		确认报文段：ACK=1，确认号ack=y+1,序号seq=x+1 (初始为seq=x,第二个报文段所以要+1),ack报文段可以携带数据，
		不携带数据则不消耗序号。

		在socket编程中，客户端执行connect()时，将触发三次握手，并在accept()函数中完成握手连接

		流程图参考：
			https://pic3.zhimg.com/80/v2-2a54823bd63e16674874aa46a67c6c72_1440w.jpg


	1.1、 为什么需要三次握手，两次不行吗？
	第一次握手：客户端发送网络包，服务端收到了。
	这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。
	第二次握手：服务端发包，客户端收到了。
	这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认客户端的接收能力
	是否正常。
	第三次握手：客户端发包，服务端收到了。
	这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。
	因此，需要三次握手才能确认双方的接收与发送能力是否正常

	1.2 什么是半连接队列？
		服务器第一次收到客户端的 SYN 之后，就会处于 SYN_RCVD 状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个队列里，我们把这种队列称之为半连接队列。
		当然还有一个全连接队列，就是已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象。
	 补充：关于SYN-ACK 重传次数的问题：
		服务器发送完SYN-ACK包，如果未收到客户确认包，服务器进行首次重传，等待一段时间仍未收到客户确认包，进行第二次重传。如果重传次数超过系统规定的最大重传次数，系统将该连接信息从半连接队列中删除。注意，每次重传等待的时间不一定相同，一般会是指数增长，例如间隔时间为 1s，2s，4s，8s…

	1.3 三次握手过程中可以携带数据吗？
		其实第三次握手的时候，是可以携带数据的。但是，第一次、第二次握手不可以携带数据
		为什么这样呢?大家可以想一个问题，假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器，那他每次都在第一次握手中的 SYN 报文中放入大量的数据。因为攻击者根本就不理服务器的接收、发送能力是否正常，然后疯狂着重复发 SYN 报文的话，这会让服务器花费很多时间、内存空间来接收这些报文。
		也就是说，第一次握手不可以放数据，其中一个简单的原因就是会让服务器更加容易受到攻击了。而对于第三次的话，此时客户端已经处于 ESTABLISHED
		状态。对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据也没啥毛病。

2、四次挥手

		建立一个连接需要三次握手，而终止一个连接需要经过四次挥手，这是由于TCP的半关闭（half-close）造成的。所谓的半关闭，其实就是TCP提供了连接的一端在结束它的发送后还能接收来自另外一端数据的能力。
		TCP 的连接的拆除需要发送四个包，因此称为四次挥手(Four-way handshake)，客户端或服务器均可主动发起挥手动作。
		刚开始双方都处于 ESTABLISHED 状态，假如是客户端先发起关闭请求。

		四次挥手的过程如下：

		第一次挥手：
			客户端发送一个FIN报文，报文中会指定一个序列号。此时客户端处于FIN_WAIT1 状态。
		即发出连接释放报文段（FIN=1，序号seq=u）,并停止在发送数据，主动关闭TCP连接，进入FIN_WAIT1（终止等待1）状态，等待
		服务端的确认。

		第二次挥手：
			服务端收到FIN之后，会发送ACK报文，且把客户端的序列号值+1 作为ACK报文的序列号值，表明已经收到了客户端的报文了，
			此时服务端处于CLOSE_WAIT状态。

			即服务端收到连接释放报文段后即发出确认报文段（ACK=1，确认号ack=u+1，序号seq=v），服务端进入CLOSE_WAIT（关闭等待）状态，此时的TCP处于半关闭状态，客户端到服务端的连接释放。客户端收到服务端的确认后，进入FIN_WAIT2（终止等待2）状态，等待服务端发出的连接释放报文段。

		第三次挥手：
			如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 LAST_ACK 的状态。
			即服务端没有要向客户端发出的数据，服务端发出连接释放报文段（FIN=1，ACK=1，序号seq=w，确认号ack=u+1），服务端进入LAST_ACK（最后确认）状态，等待客户端的确认。

		第四次挥手
			客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 +1 作为自己 ACK 报文的序列号值，此时客户端处于 TIME_WAIT 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态，服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态。

			即客户端收到服务端的连接释放报文段后，对此发出确认报文段（ACK=1，seq=u+1，ack=w+1），客户端进入TIME_WAIT（时间等待）状态。此时TCP未释放掉，需要经过时间等待计时器设置的时间2MSL后，客户端才进入CLOSED状态。

			说明：
				收到一个FIN只意味着在这一方向上没有数据流动。客户端执行主动关闭并进入TIME_WAIT是正常的，服务端通常执行被动关闭，不会进入TIME_WAIT状态。

				在socket编程中，任何一方执行close()操作即可产生挥手操作。
			流程图参考：https://pic2.zhimg.com/80/v2-c7d4b5aca66560365593f57385ce9fa9_720w.jpg

	2.1 挥手为什么四次
		因为当服务端收到客户端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当服务端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉客户端，“你发的FIN报文我收到了”。
		只有等到我服务端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四次挥手。

	2.2 四次挥手释放连接时，等待2MSL的意义? 和 为什么TIME_WAIT状态需要经过2MSL才能返回到CLOSE状态？
		说明：MSL可译为“最长报文段寿命”，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。

		理论上，四个报文都发送完毕，就可以直接进入CLOSE状态了，但是可能网络是不可靠的，有可能最后一个ACK丢失。
		所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。

		等待2MSL的主要目的总结：
			1、保证客户端发送的最后一个ACK报文段能够到达服务端。
				为了保证客户端发送的最后一个ACK报文段能够到达服务器。因为这个ACK有可能丢失，从而导致处在LAST-ACK状态的服务器收不到对FIN-ACK的确认报文。服务器会超时重传这个FIN-ACK，
				接着客户端再重传一次确认，重新启动时间等待计时器。最后客户端和服务器都能正常的关闭。假设客户端不等待2MSL，而是在发送完ACK之后直接释放关闭，一但这个ACK丢失的话，服务器就无法正常的进入关闭连接状态。

			2、防止“已失效的连接请求报文段”出现在本连接中。
				客户端在发送完最后一个ACK报文段后，再经过2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文段。

补充知识：
    OSI七层模型：
        应用层 -》 表示层 =》 会话层 -》传输层 -》网络层 -》数据链路层 -》wulic

     TCP/IP 概念层模型
        应用层 -》 传输层（TCP/UDP协议）-》网络层 -》 链路层


TCP/IP 和 HTTP/HTTPS 区别

1、TCP/IP协议是传输层协议，主要解决数据如何在网络中传输，而HTTP是应用层协议，主要解决如何包装数据。
    eg: 比如你需要访问一个网页，浏览器会先生成HTTP的数据包，然后交给传输层去建立连接。

HTTP 和 HTTPS

1、什么是HTTPS
	HTTPS是在HTTP上建立SSL/TLS加密层，并对传输数据进行加密，是HTTP协议的安全版。

2、HTTP存在的问题

	1、HTTP通信使用明文（不加密），内容可能被窃听。

	2、HTTP 无法验证报文的完整性，可能遭篡改

		所谓报文的完整性也是指报文信息的准确度。由于HTTP协议无法证明你通信的报文完整性，因此，在请求或响应送出之后直到对方
		接收之前的这段时间内，即使请求或响应的内容遭到篡改，也没有办法获悉。换句话说，没有任何办法确认，发出的请求/响应和接收到的请求/响应是前后相同的。

	3、HTTP无法验证通信双方的身份，因此可能遭遇伪装。
		HTTP协议中的请求和响应不会对通信方进行确认。在HTTP协议通信时，由于不存在确认通信方的处理步骤，任何人都可以发起请求。
		另外，服务器只要接收到请求，不管对方是谁都会返回一个响应。因此，HTTP协议无法验证通信双方身份，任何人都可以伪造虚假服务器欺骗用户，实现“钓鱼欺诈”，而用户无法擦觉。


3、HTTPS解决了上述问题
	1、数据隐私性。（内容经过对成加密，每个连接生成一个唯一的加密密钥）
	2、数据完整性。（内容传输经过完整性校验）
	3、身份认证。（第三方无法伪造服务端（客户端）身份）



4、HTTP和HTTPS 层次

	HTTP(传输层协议)					HTTPS（传输层协议）
	TCP                             SSL/TLS
	IP                              TCP
									IP


   HTTPS协议的主要功能基本都依赖于TLS/SSL协议，TLS/SSL协议的功能实现主要依赖于三类基本算法。散列函数，对称机密和非对称加密。
   1、利用非对称加密实现身份认证和密钥协商
   2、利用对称加密算法采用协商的密钥对数据进行加密
   3、基于散列函数验证信息的完整性。

   参考结构图：
   https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/TLS:SSL%E6%B5%81%E7%A8%8B%E5%9B%BE.png



5、HTTPS解决内容可能被窃听的问题 - 加密
	HTTPS 使用对称加密+ 非对称加密 两者并用的混合加密机制
	具体做法： 发送密文的一方使用对方的公钥进行加密处理 ”对称的密钥“，然后对方用自己的私钥解密拿到”对称的密钥“，这样可以确保
	交换的密钥是安全的前提下，使用对称加密方式进行通信。



6、解决报文可能遭篡改问题 - 数字签名
	HTTPS使用 数字签名，解决报文可能被篡改。
	具体流程：
		1、发送者将一段报文先用HASH 函数生成消息摘要，然后用发送着的私钥加密生成数字签名。并且将数字签名与原报文一起发送给接收者。
		2、接送着用发送者的公钥解密被加密的摘要信息，然后用HASH函数对接收到的原文生成一个摘要信息，并与上一步接收到的摘要信息进行对比。如果相同，则说明收到的信息是完整的，在传输过程中没有被修改，否则说明信息被修改过，因此数字签名能够验证信息的完整性。


7、解决通信方身份可能被伪装的问题 —— 数字证书
	HTTPS使用 数字证书 解决通信方身份可能被伪装的问题
	数字证书认证机构处于客户端与服务器双方都可信赖的第三方机构的立场上

	我们来介绍一下数字证书认证机构的业务流程：

	1、服务器的运营人员向第三方机构CA提交公钥、组织信息、个人信息(域名)等信息并申请认证;

	2、CA通过线上、线下等多种手段验证申请者提供信息的真实性，如组织是否存在、企业是否合法，是否拥有域名的所有权等;

	3、如信息审核通过，CA会向申请者签发认证文件-证书。证书包含以下信息：申请者公钥、申请者的组织信息和个人信息、签发机构 CA的信息、有效时间、证书序列号等信息的明文，同时包含一个签名。其中签名的产生算法：首先，使用散列函数计算公开的明文信息的信息摘要，然后，采用 CA的私钥对信息摘要进行加密，密文即签名;

	4、客户端 Client 向服务器 Server 发出请求时，Server 返回证书文件;

	5、客户端 Client 读取证书中的相关的明文信息，采用相同的散列函数计算得到信息摘要，然后，利用对应 CA的公钥解密签名数据，对比证书的信息摘要，如果一致，则可以确认证书的合法性，即服务器的公开密钥是值得信赖的。

	6、客户端还会验证证书相关的域名信息、有效时间等信息; 客户端会内置信任CA的证书信息(包含公钥)，如果CA不被信任，则找不到对应 CA的证书，证书也会被判定非法


8、HTTPS工作流程

	参考流程图：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/https%E6%B5%81%E7%A8%8B%E5%9B%BE.jpeg
	1.Client发起一个HTTPS（比如 https://juejin.im/user）的请求，根据RFC2818的规定，Client知道需要连接Server的443（默认）端口。

	2.Server把事先配置好的公钥证书（public key certificate）返回给客户端。

	3.Client验证公钥证书：比如是否在有效期内，证书的用途是不是匹配Client请求的站点，是不是在CRL吊销列表里面，它的上一级证书是否有效，这是一个递归的过程，直到验证到根证书（操作系统内置的Root证书或者Client内置的Root证书）。如果验证通过则继续，不通过则显示警告信息。

	4.Client使用伪随机数生成器生成加密所使用的对称密钥，然后用证书的公钥加密这个对称密钥，发给Server。

	5.Server使用自己的私钥（private key）解密这个消息，得到对称密钥。至此，Client和Server双方都持有了相同的对称密钥。

	6.Server使用对称密钥加密“明文内容A”，发送给Client。

	7.Client使用对称密钥解密响应的密文，得到“明文内容A”。

	8.Client再次发起HTTPS的请求，使用对称密钥加密请求的“明文内容B”，然后Server使用对称密钥解密密文，得到“明文内容B”。



 9、补充知识 对称加密和非对称加密
 	非对称加密的特点是信息传输一对多，服务器只需要维持一个私钥就能够和多个客户端进行加密通信。
 	非对称加密效率低。
