项目总结整理：

1、连麦pk

2、充值
    1、充值设置（充值金额，优惠券，返利券配置，及使用规则）
    2、PHP  整理打通对接多种支付方式 （微信&公众号&支付宝&QQ钱包&华为&魅族），下单
    3、鹅肝&鹅蛋微服务 给用户下发 充值鹅肝奖励，并记录充值流水，房间热度增长等

3、个人中心
	1、登录模块（账号密码&三方登录&二维码扫码登录&手机号登录）
	    1、token 生成规则参考 JWT.txt总结
	    2、集成三方登录（ios & huawei & weixin & QQ &斗鱼）
	        1、union_loin (uid => unionId)映射
	    3、二维码扫码逻辑
	        1、参考二维码扫码逻辑 技术方案

	2、用户基础信息及基础功能
		1、用户基础信息及修改，修改手机号&绑定（解绑）手机号，修改昵称&头像，绑定三方账号，视频投稿
		2、实名认证 & 验证码（邮箱&短信）风控逻辑 优化 及 站内信相关服务。
		    1、风控逻辑
		       1、ip 每个ip每天收发验证码次数限制，收发频率限制（每分钟内）
		       2、用户层面 单个用户每天收发频率限制
		       3、验证码错误风控 ，多次错误，验证码失效
		       4、验证码异步发送



1、“房间服务”
	“房间服务”主要负责平台，主播直播间的申请，流地址管理，开播，关播；房间信息设置和获取，以及房管权限，房间监控，房间审核等一系列功能，

2、“用户服务”
	“用户服务”主要包括以下模块。1、用户登录模块。多种三方登录，一键登录，二维码登录，短信验证码登录 等	登录方式的集成。
	2、“用户信息”模块。例如 用户基础信息的设置和获取，用户基本信息修改，主播实名认证，手机号及三方账号的绑定和解绑 ，主播工会 等所有一系列用户端和主播端功能。

4、房间
	1、房间基础信息
	    1、房间基础信息
	    2、房管权限及操作
	    3、房间审核
	    4、房间监控及置顶&隐藏
	2、房间开播&关播&流地址管理
	    1、房间开播设置
	    2、开播、关播、流地址

5、运营活动
    1、周星榜
    2、用户回归礼活动
    3、首充活动，七夕&春节活动等

6、社区&资讯
	社区：UGC 用户生成内容

    1、社区 可以配置 帖子所属虚的圈子 类似主题的东西。  包括圈子的封面，介绍。
    2、帖子，用户可以进行发帖
    	帖子审核方式，可以通过后台配置。
    	比如先发后审， 发布后用户可以直接在圈子对应的列表中查看，
    	先审后发 ，发布后 进入到后台的审核列表，用户在前端只能在自己的个人中心看到，其他用户没法看到，审核通过后，其他用户才可以在
    	圈子中看到

    	publish
    	review 两个字段来控制

    3、帖子的类型包括文字 ，图片， 视频
    4、然后是评论，回复 和引用回复。我们支持到三级评论
    	id post_id ,quote_id ,reply_quote_id

    	 php提供网关接口 =》 go 提供rpc服务

    5、管理员
    	管理员可以对用户进行禁言，删除用户帖子

    6、后台
    	禁言列表
    	审核列表
    	发布列表举报列表
    	热门池列表
    	白名单
    	审核方式开关



1、周星榜总结
 1、周星榜
 	属于平台榜单玩法的一种。具体规则是：
 	1、CMS 后台 可以分频道 配置周星礼物，最多四个周星礼物，除首次外配置修改后下周生效。
 	2、前台包括 本周实时榜单 和 上周榜单
 		1、本周实时榜单，统计各个频道下，每个周星礼物的送礼排行，
 		2、上周榜单。周日晚上24:00 结算各个频道下，各个礼物的排行榜，并统计最强助力用户
 	需求：难度 3型，复杂度 4星
 	需求需要注意的地方：

 		1、配置比较麻烦
 			1、榜单开关；可针对频道分别配置，移动端&Web端可分别控制开启&关闭；用户控制端上是否展示周星榜常驻入口&移动端未选中礼物时展示的周星横幅
 				单端关闭(WeborAPP)；服务正常，只是关闭端不展示入口，数据正常统计
 				全端关闭（Web&APP）；服务关闭，不展示入口的同时，数据不再统计/礼物标签不再展示，如本周结算时，服务处于关闭状态，则下周不会发放榜单奖励
 				榜单开关实时生效
 			2、如果一条配置 有礼物新增 则需要在下周配置生效，
 			3、如果新增一条配置 本周需要立即生效。并且还要展示本周和下周的礼物配置。
 				因此 每个频道 每个礼物 都会根据是否同步配置到底层 维护两条数据，本周的和下周的 ，当有开关关闭的时候，及时通知底层rpc服务更新配置。

 		2、某个周星礼物 相同分数时，需要根据时间排序，最先达到分值的排在最前面 (难点)

 			实现，使用redis zset 在进行有序排列时，需要维护一个时间戳 浮点数 的变量。比如（Max - now timestamp）/10000000 	，时间戳越大浮点数越小。 从而进行区别相同分值的情况。
 			同时为了保证数据的精度。
 			1、使用float64来保证数据的精度。
            2、采用shopspring库。
                shopspring的Decimal实现比较简单, 思路是使用十进制定点数表示法,
                 有多少位小数就小数点后移多少位, value保存移之后的整数, exp保存小数点后的数位个数,
                  number=value*10^exp, 因为移小数点后的整数可能很大,
                  所以这里借用标准包里的math/big表示这个大整数. exp使用了int32,
                  所以这个包最多能表示小数点后有32个十进制数位的情况


            方案：利用zset实现多维度排序
              构造一个特殊的有效值score： 整数部分就是打赏值，小数部分就是最后的更新时间戳。
              （socre:它是一个双精度64位的浮点型数字字符串。+inf和-inf都是有效值，能包括的整数范围是-(2^53) 到 +(2^53)，或者说是-9007199254740992 到 9007199254740992。）

              例如：1000.0000000001

              注意问题：需要处理精度的时候，使用shopspring 的decimal来处理


            方案2:  自实现一个得分权重 计算公式
                类似：count*10000000+timestamp （基准时间 - 减去当前时间） 时间戳构成。（需要注意不要让score溢出）



            方案3：利用key来实现
              1、zset 在分数值相同的时候，默认根据key来进行排序的。因此我们可以根据 时间来构造出一个特殊的key.


            方案4:利用二进制分段存储。
              1、如二进制64位long分段存储分值和时间。高32位存储分值，低32位存储时间。


 		3、需要根据频道id和礼物giftId 维护各个频道下，各个礼物的排行榜

 		4、各个礼物上周的排行榜 缓存维护，需要考虑跨年
 			rpc服务 和 PHP client 端都有 考虑 根据 年份，当前年份所属的周（第几周 ） 作为参数

 				上周榜单缓存key:WeekStarRankingPrefix      = "Rank:WeekStar:Ranking:%d:%d"     //Rank:WeekStar:Realtime:$week:$channel,周星榜
 				实时榜单缓存key:WeekStarRealtimePrefix     = "Rank:WeekStar:Realtime:%d:%d:%d" //Rank:WeekStar:Realtime:$week:$channel:$gift

 				并且把 上周的数据保存到mogodb中

 		5、统计上周榜单频道下某个礼物的 最佳助力（送礼最多的用户）时 ，需要从clickhouse中查询，clickhouse作为列式数据库，比较陌生，在实现时，花费了一定的时间。
 			因为送礼数据都存在了clickhouse中，为了方便用户热度计算时的查询。 （难点）

 			思路：
 			1、先从clickhouse 中 根据start,end,roomId(主播房间ID)，giftId ,统计出 满足条件的送礼数量 并且只取 前两个
 			2、判断 判断这两个 送礼的总数量是否相同，如果第一个比第二个大 直接返回 第一个就行。
 			3、如果两个相同，在分别查询这两个用户 最后一次送礼的时间，如果 第一个比第二个大，则返回第二个用户，否则返回第一个。

 		5、实时榜单：
 			 go底层 使用协程 实时消费kafka中的送礼数据，根据频道id,礼物id，礼物数量，时间 维护一个有序列表

2、首充奖励
	 充值活动奖励：根据充值的档位 判断 是否历史首次充值，每月首次充值，然后用户充值以后 调用 道具，贵族 勋章，站内信等rpc服务，给用户下发响应的奖励，并发送通知。
	 注意点：
	 1、用户权限的校验，是否有首充奖励权限，查询db后，缓存充值权限
	 2、麻烦规则， 每个月第1和第3个星期六00:00-周日23:59，历史未充值用户或未完成月首充的用户进入直播间30秒后，弹出首充活动页面，提醒用户完成首充和月充活动，每日仅触发1。
	 	1、需要先判断 当前月第一天是否是 周六和周天
	 		1、如果不是，则可以获取当前月第一天，然后根据 当前天距离 第一周 周六 周天，和第三周 周六周天的天数 推算出  第一周 周六和周天，第三周 周六和周天的 起始时间范围。
	 		2、如果是 ，需要判断 第一天是否是 周六，或者是否是周天，然后同样推算 第一周 周六和周天，第三周 周六和周天的 起始时间范围。
	 		注意： 12; // 第一周周日和第三周周五 中间间隔天数

	修复难度：2*


三、连麦pk 和普通pk

        1、普通连麦	平台主播可以邀请其他主播连麦pk,连麦方式为双人同屏视频，语音互通

        2、Pk连麦 。基于普通连麦，在一定的连麦时间内，对比连麦双方分值决出胜负，失败方在惩罚阶段接受约定好的惩罚

            1、PK阶段：双方主播进入PK状态后，要经历两个阶段，第一个阶段是比分阶段，双方通过收礼或其它行为获得分值，如果在比分阶段通过比分分出胜负，将进入下一阶段：惩罚阶段，若未分出胜负将直接结束比赛；惩罚阶段，分值不再变化，失败方要在惩罚阶段完成约定的惩罚方式
            2、PK时长：两个阶段都拥有固定的时长，暂定比分阶段时长为6分钟，惩罚阶段时长为2分钟；两个时长在PK开始前，从服务端获取（根据线上效果或场景变化，会适当调整时长）
            3、PK分数：比分阶段，每赠送主播0.1鹅肝礼物，记为1分；

        3、
            1、后台维护主播白名单，白名单內的主播可以进行连麦
            2、连麦发起方 发起连麦邀请，接收方可以 【接受】，【拒绝】，【不处理】（也就是邀请过期）（15s邀请时间）

                一条连麦数据拥有以下几个状态
            未开始;1进行中;2惩罚阶段;3已结束;4后台关闭， 5空闲；// 3，4，5都是可以进行pk的状态

            连麦时间结束后，：双方如果分数值相同，则平局 连麦结束
                          分数不一样，	进入惩罚阶段。然后连麦结束


            3、严格的维护连麦过程中的状态机，pk的状态和分数值 通过socket下发给连麦双方
                分数值，通过携程消费kafka中的送礼数据，计算出真实的分数，分别下发给 不同的用户。

            项目比较复杂，难度不大，

            难点：
                1、周星榜频道开关配置和 连麦主播的信息，都是存在本地
                go-cache中，会导致数据不一致的情况
                       原因：网络不稳定或节点故障导致 ,每个post
                解决思路：
                    1、使用redis发布订阅的模式，当修改发生时 通知副本及时更新信息

                    go-cache是一款类似于memached 的key/value 缓存软件。它比较适用于单机执行的应用程序。
                    go-cache实质上就是拥有过期时间并且线程安全的map，可以被多个goroutine安全访问。


四、充值流程
    支付流程 即时下单接口（老版本）

    1、用户请求服务器调用充值接口下单，
    2、服务器生成订单，并且调用支付宝的即时下单接口生成支付宝订单。
    3、支付宝 收到请求，生成订单
    4、用户扫码或者输入密码支付成功，
    5、支付宝根据传入的return_url和 notify_url跳转页面，并通过回调的方式通知订单的状态
    6、在回调中处理订单的状态，并给用户下发充值鹅肝。
    7、补单定时，已防止回调失败后，可以刚更新订单状态。

    ios充值碰到的问题 重复下发鹅肝,解决方案： 解决数据库的唯一索引防止重复补单。

五、基于redis实现延迟消息队列

1、基于有赞实现的延迟队列
	1、job是需要异步处理的任务。延迟队列的基本单元，与具体的topic关联再一起。
	2、topic 一组相同类型job的集合（队列），供消费者订阅。

2、job属性
	1、Topic job类型。可以理解成具体业务的名称。
	2、id job的唯一标示。由业务方保证。
	3、Delay 延迟的时间，单位秒，（服务方会根据这个时间戳，转换成具体的执行时间点）
	4、TTR ：job 执行超时时间。
	5、Body ： job的内容，以json格式存储。
3、每个job的状态
	1、delay 不可执行状态，扽带时钟周期。
	2、ready :可执行轧状态，等待消费
	3、reserved  已被消费者读取
	4、delete： 已被消费者完成或者已被删除

4、消息存储
	1、Job 存放任务的具体内容
	2、Delay Bucket 一个有序列表
		bucket的数据结构就是redis的zset，将其分为多个bucket是为了提高扫描速度，降低消息延迟。
		1、根据配置启用 3个bucket也就是3个 zset提高扫码的速度，并且生成对应3个计时器
		2、业务方设置延迟任务的时候，先把任务 通过redis.set缓存，然后在随机加入一个zset中。
		3、通过计时器轮询遍历每个zset，将任务时间小于/等于当前时间的 加入到 ready queue 中


	3、Ready Queue 	普通的list 队列

	大体实现思想是：
		1、每一个topic 对应一个ready Queue 队列。 业务方轮询获取延迟任务时，直接根据topic获取即可。


5、	需要注意的是
	1、业务方调用push 添加延迟队列
	2、服务方 通过pop接口轮询获取延迟任务，服务端会一直阻塞，直到队列中有延迟任务 或者 设置的ttr超时后返回。
		任务执行完成后需调用finish接口删除任务, 否则任务会重复投递, 消费端需能处理同一任务的多次投递



举例说明一个Job的生命周期
	1、用户对某个商品下单，系统创建订单成功，同时往延迟队列里put一个job。job结构为：{‘topic':'orderclose’, ‘id':'ordercloseorderNoXXX’, ‘delay’:1800 ,’TTR':60 , ‘body':’XXXXXXX’}
	2、延迟队列收到该job后，先往job pool中存入job信息，然后根据delay计算出绝对执行时间，并以轮询(round-robbin)的方式将job id放入某个bucket。
	3、timer每时每刻都在轮询各个bucket，当1800秒（30分钟）过后，检查到上面的job的执行时间到了，取得job id从job pool中获取元信息。如果这时该job处于deleted状态，则pass，继续做轮询；如果job处于非deleted状态，首先再次确认元信息中delay是否大于等于当前时间，如果满足则根据topic将job id放入对应的ready queue，然后从bucket中移除；如果不满足则重新计算delay时间，再次放入bucket，并将之前的job id从bucket中移除。
	4、消费端轮询对应的topic的ready queue（这里仍然要判断该job的合理性），获取job后做自己的业务逻辑。与此同时，服务端将已经被消费端获取的job按照其设定的TTR，重新计算执行时间，并将其放入bucket。
	5、消费端处理完业务后向服务端响应finish，服务端根据job id删除对应的元信息。


缺点是：如果业务方没有调用finish和delete 以及，ttr时间超时了。那么 业务方的任务仍然存在在服务方的 redis中。缺少一定的清理机制。可以考虑在给 任务设置一定的超时时间，或者脚本定期清理。
