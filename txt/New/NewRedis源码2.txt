1、String 类型
	1、SDS 动态字符串
		Redis没有直接使用 C 语言的字符串，而是自己创建了名为 SDS (simple dynamic string, SDS) 的字符串。
		struct sdshdr {
	        int len; //存长度
	        int free; //存字符串内容的柔性数组的剩余空间
	        char buf[]; //柔性数组，真正存放字符串值
	    };

	    1、len 字符串长度
	    2、free 记录buff数组中未使用字节的数量
	    3、buf 字节数组，保存字符串

	2、SDS优点
		1、二进制安全
			C 语言中，用 “\0” 表示字符串的结束，如果字符串本身就有 “\0” 字符，字符串就会报截断，是非二进制安全的。
			SDS 使用len 字段记录字符串长度，读写字符串时不依赖“\0”终止符，保证了二进制安全.
		2、获取字符串长度时，只需要获取len属性的值，复杂度为O(1)
		3、减少修改字符串时带来的内存重分配次数。
			 1、常规C字符串，再执行拼接操作或者截断操作时，通常会对数组进行内存重分配。 Redis作为数据库，会对数据进行频繁的修改，并且对速度要求极为严苛，所以每次修改字符串长度都需要进行内存重分配会对性能造成极大的影响。
			  因此，SDS实现了空间预分配和惰性空间释放两种优化策略

			 2、空间预分配
			 	1、SDS 进行空间扩展的时候， 程序不仅会为 SDS 分配修改所必须要的空间， 还会为 SDS 分配额外的未使用空间
			 	2、如果对 SDS 进行修改之后， SDS 的长度（也即是 len 属性的值）将小于 1 MB ， 那么程序分配和 len 属性同样大小的未使用空间， 这时 SDS len 属性的值将和 free 属性的值相同。 举个例子， 如果进行修改之后， SDS 的 len 将变成 13 字节， 那么程序也会分配 13 字节的未使用空间， SDS 的 buf 数组的实际长度将变成 13 + 13 + 1 = 27 字节（额外的一字节用于保存空字符）。

				3、如果对 SDS 进行修改之后， SDS 的长度将大于等于 1 MB ， 那么程序会分配 1 MB 的未使用空间。 举个例子， 如果进行修改之后， SDS 的 len 将变成 30 MB ， 那么程序会分配 1 MB 的未使用空间， SDS 的 buf 数组的实际长度将为 30 MB + 1 MB + 1 byte 。

			 3、惰性空间释放
			 	当 SDS 的 API 需要缩短 SDS 保存的字符串时， 程序并不立即使用内存重分配来回收缩短后多出来的字节， 而是使用 free 属性将这些字节的数量记录起来， 并等待将来使用。

	3、SDS缺点
		1、不同的 SDS字符串占用了相同大小的头部空间（buf和len长度），浪费额外的空间。
		2、Redis 5.0改进了SDS，将根据字符串的长度，分成了5种类型sdshdr5、sdshdr8、sdshdr16、sdshdr32、sdshdr64。
			（1）五种类型都多了一个flags字段，但sdsdr5没有了头部（len和free ）
			（2）sdshdr5结构中，flags占1个字符，其低3位表示结构体类型，高5位表示长度，能表示的长度区间为0~31，flags后面就是字符串的内容。而长度大于31的字符串，1个字节存不下，那么就要将len和free单独存放，因此redis存放数据时会先检查字符串长度，再根据字符串长度计算好不同类型的头部和初始长度，然后动态分配内存

	4、为什么要用柔性数组？
       	 柔性数组的地址和结构体是连续的，这样查找内存更快（因为不需要额外通过指针找到字符串的位置）；
   		 可以更快的通过柔性数组的首地址偏移得到结构体首地址，进而能很方便的获取其余变量。

2、List
	1、Redis 列表list使用两种数据结构作为底层实现
		1、压缩列表ziplist
		2、双向链表linkedlist

			因为双向链表占用的内存比压缩列表要多， 所以当创建新的列表键时， 列表会优先考虑使用压缩列表， 并且在有需要的时候， 才从压缩列表实现转换到双向链表实现
		3、当列表对象可以同时满足下列两个条件时，列表对象采用压缩链表编码：
		（1）列表对象保存的所有字符串元素的长度都小于64字节；
		（2）列表元素保存的元素数量小于512个；
	3、ziplist
		1、压缩列表由一系列经Redis特殊编码的连续内存块组成，每一个内存块称为一个节点（entry），而一个压缩列表可以包含很多个节点。每个节点存储的数据格式可以是字节数组（中文字符串等都会转换为字节数组）或者整数值。
		2、结构：
			1、ziplist
				  字节数组（Redis使用字节数组表示一个压缩列表，字节数组逻辑划分为多个字段）
	            zlbytes | zltail | zllen | entry1 | entry2 | ......zlend

	            1、zlbytes：表示整个压缩链表所占用内存的长度（以字节为单位），占4个字节，因此压缩列表最长(2^32)-1字节；
	            2、zltail：该字段固定是一个四字节的无符号整数，用于表示在链表中最后一个节点的偏移字节量，借助这个字段，我们不 需要遍历整个链表便可以在链表尾部执行Pop操作。；
	            3、zllen：压缩列表的元素数目，占两个字节；那么当压缩列表的元素数目超过(2^16)-1怎么处理呢？此时通过zllen字段无法获得压缩列表的元素数目，必须遍历整个压缩列表才能获取到元素数目；
	            4、entryX：压缩列表存储的若干个元素，可以为字节数组或者整数；entry的编码结构后面详述；
	            5、zlend：压缩列表的结尾，占一个字节，恒为0xFF。

	        2、压缩列表节点
	           每个压缩列表节点都是由 previous_entry_length ,encoding,content三个部分组成。
	            i) previous_entry_length 属性以字节为单位，记录了压缩列表中前一个节点的长度。
	                主要用于压缩列表遍历（使用指向当前节点起始节点指针C，减去当前节点previous_entry_length属性的值，就可以得出一个指向前一个
	                节点起始地址的指针p）。
	            ii） encoding： 这个字段用于表示该节点使用的编码方式，具体是按照整形数进行编码还是按照字符串进行编码， 当节点使用的是字符串编码时，该字段还会指明字符串数据的字节长度。
	            iii) content : 节点保存的值 （可以是字节数组/整数），具体类型和长度 由节点encoding属性决定。

		3、优缺点：
			1、优点
				1、节省内存
				2、可以在O(1) 时间内进行push和pop操作
			2、缺点
				1、插入、删除、更新时存在内重新分配
				2、存在连锁更新问题
					因为每个节点都保存了前一个节点的长度，如果发生了更新或者删除节点。则这个节点之后的数据也需要修改，有一种最坏的情况就是如果每个节点都处于需要扩容的零界点，就会造成这个节点之后的节点都要修改 size 这个参数，引发连锁反应。这个时候就是 压缩链表最坏的时间复杂度 O(n^2)。不过所有节点都处于临界值

3、hash
	redis的哈希对象的底层存储可以使用ziplist（压缩列表）和hashtable
	1、ziplist
		1、哈希对象保存的所有键值对的键和值的字符串长度都小于64字节
		2、哈希对象保存的键值对数量小于512个
		总结见上ziplist
	2、hashTable
		  Redis的字典使用哈希表作为底层实现，一个哈希表里面可以有多个哈希表节点，而每个哈希表节点就保存了字典的一个键值对。
		1、字典结构
			/* 字典结构定义 */
			typedef struct dict {
			    dictType *type;  // 字典类型
			    void *privdata;  // 私有数据
			    dictht ht[2];    // 哈希表数组[两个]
			    long rehashidx;   // 记录rehash 进度的标志，值为-1表示rehash未进行
			    int iterators;   //  当前正在迭代的迭代器数
			} dict

      		1、dictht 。正常情况只用到ht[0]；ht[1] 在Rehash时使用

      		2、hash 冲突。
		       	 1、当有两个或者以上数量的键被分配到了哈希表数组的同一个索引上面时，我们称为这些键冲突
		         2、解决方案： 哈希表使用链地址法 来解决键冲突，每个哈希表节点都有一个next指针，多个哈希表节点可以用next指针构成一个单向链表，被分配到同一个索引上
		        的多个节点可以用这个单向链表连接起来。（redis总是将新节点添加到链表的表头位置（复杂度为O(1))）,排在其他节点的前面
		    3、Rehash
		    	1、Rehash 条件。
		    		1、 负载因子计算
		    			#哈希表的负载因子计算：负载因子 = 哈希表已保存节点数量 / 哈希表大小
		    			（load_factor = ht[0].used / ht[0].size）

		    		2、触发扩容操作条件
		    			1、服务器目前没有在执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且哈希表的负载因子大于等于 1
		    			2、服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且哈希表的负载因子大于等于 5
		    		3、触发收缩操作条件
		    			当哈希表的负载因子小于0.1时，程序自动开始对哈希表执行收缩操作
		    			（(ht[0].used / ht[0].siz) < 0.1，也就是填充率必须<10%。）

		    	2、渐进式 rehash
		    		1、为了避免 rehash 对服务器性能造成影响， 服务器不是一次性将 ht[0]里面的所有键值对全部 rehash 到 ht[1]， 而是分多次、渐进式地将 ht[0]里面的键值对慢慢地 rehash 到 ht[1]
		    		2、哈希表渐进式rehash的详细步骤：
		    			1、为ht[1]分配空间，让dict字典同时持有 ht[0] 和 ht[1] 两个哈希表。
		    			2、在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始。
		    			3、在rehash执行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成后，程序将rehashidx属性的值增1
		    			4、随着字典操作的不断执行，最终在某个时间点上，ht[0]的所有桶对应的键值对都会被rehash至ht[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成
                        5、把ht[1]替换ht[0]
		    		3、渐进式 rehash 执行期间的哈希表操作
						1、删除和查找：在进行渐进式rehash的过程中，字典会同时使用ht[0]和ht[1]两个哈希表，所以在渐进式rehash进行期间，字典的删除、查找、更新等操作会在两个哈希表上进行。比如说，要在字典里面查找一个键的话，程序会先在ht[0]里面进行查找，如果没找到的话，就会继续到ht[1]里面进行查找，诸如此类。
						2、新增数据：在渐进式 rehash 执行期间，新添加到字典的键值对一律会被保存到ht[1]里面，而ht[0]则不再进行任何添加操作。这一措施保证了ht[0]包含的键值对数量会只减不增，并随着rehash操作的执行而最终变成空表。

4、Zset
	1、ziplist：满足以下两个条件的时候
		1、元素数量少于128
		2、每个元素的长度小于64字节
	2、skiplist：不满足上述两个条件就会使用跳表，具体来说是组合了map和skiplist
		1、map用来存储member到score的映射，这样就可以在O(1)时间内找到member对应的分数
		2、skiplist按从小到大的顺序存储分数skiplist每个元素的值都是[score,value]对，实现快速的按分数范围查找元素

	3、skiplist原理
		1、skiplist原理
    		1、skiplist特点
    			(1) 由很多层结构组成
    			(2) 每一层都是一个有序的链表
    			(3) 最底层(Level 1)的链表包含所有元素
    			(4) 如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现。
    			(5) 每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。
    		2、跳跃表主要作用是：对有序的链表查询进行加速。
    		   查找、插入和删除流程如下
    		   1、查找
    		   	  基本原理就是从最高层的链接节点开始，查询最高成链表中是否存在要查找的元素，如果存在则返回。
    		   	  否则，查找到第一个比查询元素大的节点A，以及前一个比他小的节点B，借助B进入下层查找
    		   	  以次类推，直到找到第0层 如果期间找到则返回，反之返回空。
    		   2、插入
    		   		1、随机生成一个最高层M，根据上述查找流程，找到要插入的未知，把插入的节点插入到 1～ M 的每一层。
    		   		需要注意 生成的层M，1、如果小于skiplist现有的层，则直接查找插入，如果生成的层大于现有的层
    		   		需要调整skiplist的层。
    		   3、删除
    		   		1、先查找当前要删除的元素A，比如当前元素在M层，把1-M层内的所有A都删除。让每一层中A的前一个节点 直接指向A的后一个节点。

    		   O(logn)的平均时间复杂度，其空间复杂度为O(n)。
    		 3、redis 排名是怎么算出来的

    		    typedef struct zskiplistNode {  // 跳跃表节点
                    robj *obj;  // redis对象
                    double score;   // 分值
                    struct zskiplistNode *backward; // 后退指针
                    struct zskiplistLevel {
                        struct zskiplistNode *forward;  // 前进指针
                        unsigned int span;  // 跨度
                    } level[];
                } zskiplistNode;

                typedef struct zskiplist {
                    struct zskiplistNode *header, *tail;
                    unsigned long length;   // 跳跃表长度
                    int level;  // 目前跳跃表的最大层数节点
                } zskiplist

	            zrank [zset name] [value]的实现依赖与一些附加在跳表上的属性：
	            1、level[]存放指向各层链表后一个节点的指针（后向指针）。每层对应1个后向指针，用forward字段表示。另外，每个后向指针还对应了一个span值，它表示当前的指针跨越了多少个节点。
	               redis在插入和删除元素的时候，都会更新这个值
	            2、然后在搜索的过程中按经过的路径将路径中的span值相加得到rank
                3、zrevrange的查询，是根据排名查数据，由扩展后的skiplist来提供。
                  zrevrank是先在dict中由数据查到分数，再拿分数到skiplist中去查找，查到后也同时获得了排名。

	         4、为什么采用跳表，而不使用哈希表或平衡树实现呢
		        1、skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。
		            因此，在哈希表上只能做单个key的查找，不适宜做范围查找。
	       		2、在做范围查找的时候，平衡树比skiplist操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。
       		    3、平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速
       			 4、从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），		 而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，
       			 取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。
5、set
	 Set 是String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据
	1、inset
		结合对象保存的所有元素都是整数值
		集合对象保存的元素数量不超过512个

		1、intset的数据结构
			intset内部其实是一个数组（int8_t coentents[]数组），而且存储数据的时候是有序的，因为在查找数据的时候是通过二分查找来实现的

			typedef struct intset {
	    		uint32_t encoding;    // 编码方式
	   			uint32_t length; // 集合包含的元素数量
	    		int8_t contents[];// 保存元素的数组
			} intset;

	2、	hashtable

6、redis 持久化  RDB 和 AOF
	1、RDB
	   1、RDB是一种快照存储持久化方式，具体就是将Redis某一时刻的内存数据保存到硬盘的文件当中。
	   2、触发机制
	   	 1、save命令：阻塞当前Redis服务器，直到RDB过程完成为止，对于内存 比较大的实例会造成长时间阻塞，线上环境不建议使用
		 2、bgsave命令：Redis进程执行fork操作创建子进程，RDB持久化过程由子 进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。

	   3、优缺点
	   	  1、优点
	   	  	1、RDB在大量数据，比如几个G的数据，恢复的速度比AOF快
	   	  	2、RDB是一个快照文件，数据很紧凑，它保存了 Redis 在某个时间点上的数据集，体积比较小。适合做容灾备份，主从复制。
	   	  2、缺点
	   	  	1、不能实时保存数据，可能会丢失自上一次执行rdb备份到当前的内存数据
	   	  	2、当数据量非常大的时候，从父进程fork子进程进行保存至rdb文件时需要一点时间，可能时毫秒或者秒，取决于磁盘IO性能

    2、AOF持久化
    	1、AOF持久化方式会记录客户端对服务器的每一次写操作命令，并将这些写操作以追加的方式保存到以后缀为aof文件中
    	2、触发机制
    		1、手动触发： bgrewriteaof
    		2、自动触发 就是根据配置规则来触发，当然自动触发的整体时间还跟Redis的定时任务频率有关系
    	3、AOF的工作流程操作：命令写入 （append）、文件同步（sync）、文件重写
    		1、所有的写入命令会追加到aof_buf（缓冲区）中
    		2、AOF缓冲区根据对应的策略向硬盘做同步操作
    			AOF为什么把命令追加到aof_buf中？Redis使用单线程响应命令，如 果每次写AOF文件命令都直接追加到硬盘，那么性能完全取决于当前硬盘负 载。先写入缓冲区aof_buf中，还有另一个好处，Redis可以提供多种缓冲区同步硬盘的策略，在性能和安全性方面做出平衡
    		3、AOF重写
    			1、为什要重写
    				1、随着运行时间的增长，执行的命令越来越多，会导致AOF文件越来越大，
                 	当AOF文件过大时，redis会执行重写机制来压缩AOF文件。
                 	2、重写机制主要是将文件中无效的命令去除。
		                 1、同一个key的值，只保留最后一次写入
		                 2、已删除或者已过期数据相关命令会被去除
		                 3、这样就避免了，aof文件过大而实际内存
		        2、重写过程
		           1、从主进程中fork出子进程，并把fork时的AOF文件数据，写到一个临时AOF文件中。
                   2、在重写过程中，redis主进程收到的命令会同时写到AOF缓冲区和重写缓冲区中，这样保证重写不丢失重写过程中的命令
                   3、重写完成后通知主进程，主进程会将AOF重写缓冲区中的数据追加到新的aof文件上。
                   4、redis会原子的将旧的aof文件替换为新的aof文件，并开始将数据写入到新的aof文件上

      	4、AOF优缺点
      		1、对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB
      		2、aof在恢复大数据集时的速度比rdb的恢复速度要慢

    3、一般线上建议同时开启rdb和aof

7、Redis的内存回收机制
    Redis的内存回收主要分为过期删除策略和内存淘汰策略两部分。
    1、过期删除策略；
    	1、redis采用惰性删除、定期删除两种策略来删除过期的键
	    	1、惰性删除
	    		1、放任过期键不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话就删除该键，如果没有过期，就返回该键
	            2、优点：对cpu执行时间优化，但是对内存不友好，如果一个键过期，如果不是删除，内存会一直被占用
	        2、 定期删除
	        	1、 每隔一段时间，扫描Redis中过期key字典，并清除部分过期的key。
	        	2、优点：通过调整定时扫描的时间间隔和每次扫描的限定耗时，在不同情况下使得CPU和内存资源达到最优的平衡效果
	    2、Redis清理过期key的时机
	    	1、Redis在启动的时候，会注册两种事件，一种是时间事件，另一种是文件事件。时间事件主要是Redis处理后台操作的一类事件：比如客户端超时、删除过期key；文件事件是处理请求。
            在时间事件中，redis注册的回调函数是serverCron，在定时任务回调函数中，通过调用databasesCron清理部分过期key。（这是定期删除的实现。）
        	2、每次访问key的时候，都会调用expireIfNeeded函数判断key是否过期，如果是，清理key。（这是惰性删除的实现。）

    2、内存淘汰策略
    	1、为什么要有内存回收策略
    		Redis结合了定期删除和惰性删除，基本上能很好的处理过期数据的清理，但是实际上还是有点问题的，如果过期key较多，定期删除漏掉了一部分，而且也没有及时去查，即没有走惰性删除，那么就会有大量的过期key堆积在内存中，导致redis内存耗尽，因此需要内存淘汰策略。清理掉老数据，以保证新数据的存入。
    	2、Redis的内存淘汰机制
    		1、noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错。
	        2、allkeys-lru：当内存不足以容纳新写入数据时，在键空间（server.db[i].dict）中，移除最近最少使用的 key（这个是最常用的）。
	        3、allkeys-random：当内存不足以容纳新写入数据时，在键空间（server.db[i].dict）中，随机移除某个 key。
	        4、volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间（server.db[i].expires）中，移除最近最少使用的 key。
	        5、volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间（server.db[i].expires）中，随机移除某个 key。
	        6、volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间（server.db[i].expires）中，有更早过期时间的 key 优先移除。
        3、什么时候会进行淘汰？
                Redis会在每一次处理命令的时候（processCommand函数调用freeMemoryIfNeeded）判断当前redis是否达到了内存的最大限制，
                如果达到限制，则使用对应的算法去处理需要删除的key。伪代码如下：

                int processCommand(client *c)
                {
                    ...
                    if (server.maxmemory) {
                        int retval = freeMemoryIfNeeded();
                    }
                    ...
                }

8、Redis有三种集群模式。
   	1、主从模式
   		1、为了避免单点故障，通常的做法是将数据库复制多个副本以部署在不同的服务器上，这样即使有一台服务器出现故障，其他服务器依。Redis 提供了复制（replication）功能，可以实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上

   		2、 主从复制原理
            1、从库启动成功后，连接主库，发送 SYNC 命令；
            2、主库接收到 SYNC 命令后，开始执行 BGSAVE 命令生成 RDB 文件并使用缓冲区记录此后执行的所有写命令；
            3、主库 BGSAVE 执行完后，向所有从数据库发送快照文件，并在发送期间继续记录被执行的写命令；
            4、从库收到快照文件后丢弃所有旧数据，载入收到的快照；
            5、主库快照发送完毕后开始向从库发送缓冲区中的写命令；
            6、从库完成对快照的载入，开始接收命令请求，并执行来自主数据库缓冲区的写命令；（从数据库初始化完成）
            7、主库每执行一个写命令就会向从库发送相同的写命令，从库接收并执行收到的写命令（从库初始化完成后的操作）

         3、主从复制的类型
         	  1、全量复制 （通过sync 命令复制）
         	  	1、一般用于用于初次复制，将主节点中的所有数据都发送给从节点。当数据量过大的时候，会造成很大的网络开销

         	  2、缺点
  				1、master服务器执行BGSAVE命令生成RDB文件，这个生成过程会大量消耗主服务器资源（CPU、内存和磁盘I/O资源）。
  				2、最大的问题是重连接后回全量同步数据

  		  3、增量复制 （PSYNC-增量同步）
  		  	 1、用于处理在主从复制中因网络闪退等原因造成数据丢失场景，当从节点再次连上主节点，如果条件允许，主节点会补发丢失数据给从节点，因为补发的数据远远小于全量数据，可以有效避免全量复制的过高开销

  		  	 2、、psync流程：
  				 PSYNC执行过程和SYNC的区别在于：
  					1、salve连接时，判断是否需要全量同步，全量同步的逻辑过程和SYNC相同
  						.客户端向服务器发送的命令，并且slave根据自己是否保存Master runid来判断是否是第一次连接。
  					2、如果是第一次同步则向Master发送 PSYNC = -1 命令来进行全量同步；否则 会向Master发送PSYNC runid  offset命令(runid是master的身份ID，offset（复制偏移量)。

  					3、Master接收到PSYNC 命令后，首先判断runid是否和本机的id一致，如果一致则会再次判断offset偏移量和本机的偏移量相差有没有超过复制积压缓冲区大小，如果没有，就根据按照复制偏移量，将复制积压缓冲区的
  					 命令同步到从服务器。如果runid和本机id不一致或者offset差距超过了复制积压缓冲区大小，那么就会返回FULLRESYNC runid offset，Slave将runid保存起来，并进行全量同步

  		4、主从复制优缺点
  			1、优点
  				1、一个是读写分离，分担 "master" 的读写压力
              	2、一个是方便做容灾恢复
  			2、缺点
  				1、Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复（也就是要人工介入）；

   	2、哨兵模式
   		1、哨兵机制简介
          	1）Sentinel(哨兵) 进程是用于监控 Redis 集群中 Master 主服务器工作的状态
         		2）在 Master 主服务器发生故障的时候，可以实现 Master 和 Slave 服务器的切换，保证系统的高可用（High Availability）
         	2、哨兵进程的工作方式
         		1、主观下线和客观下线：
                  1）每个 Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的 Master 主服务器，Slave 从服务器以及其他 Sentinel（哨兵）进程发送一个 PING 命令。（此处我们还没有讲到集群，下一章节就会讲到，这一点并不影响我们模拟哨兵机制）
                  2. 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）。
                  3. 如果一个 Master 主服务器被标记为主观下线（SDOWN），则正在监视这个 Master 主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认 Master 主服务器的确进入了主观下线状态。
                  4. 当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认 Master 主服务器进入了主观下线状态（SDOWN）， 则 Master 主服务器会被标记为客观下线（ODOWN）。

  	        2、Sentinel集群选举Leader：
  	            a、每个在线的哨兵节点都可以成为领导者，当它确认（比如哨兵3）主节点下线时，会向其它哨兵发is-master-down-by-addr命令，征求判断并要求将自己设置为领导者，由领导者处理故障转移；
  	            b、当其它哨兵收到此命令时，可以同意或者拒绝它成为领导者；
  	            c、如果哨兵3发现自己在选举的票数大于等于num(sentinels)/2+1时，将成为领导者，如果没有超过，继续选举…………

  	        3、故障转移机制，Sentinel Leader决定新主节点
  	               当Sentinel集群选举出Sentinel Leader后，由Sentinel Leader从redis从节点中选择一个redis节点作为主节点：
  	              1、 过滤故障的节点
  	              2、 选择优先级slave-priority最大的从节点作为主节点，如不存在则继续
  	              3、 选择复制偏移量（数据写入量的字节，记录写了多少数据。主服务器会把偏移量同步给从服务器，当主从的偏移量一致，则数据是完全同步）最大的从节点作为主节点，如不存在则继续
  	              4、 选择runid（redis每次启动的时候生成随机的runid作为redis的标识）最小的从节点作为主节点
  	    3、哨兵模式脑裂问题
  	    	1、什么是集群脑裂。
  	    		redis的集群脑裂是指因为网络问题，导致redis master节点跟redis slave节点和sentinel集群处于不同的网络分区，此时因为sentinel集群无法感知到master的存在，所以将slave节点提升为master节点。此时存在两个不同的master节点，就像一个大脑分裂成了两个

  	    	2、脑裂导致的问题。
  	    		1、集群脑裂问题中，如果客户端还在基于原来的master节点继续写入数据，那么新的master节点将无法同步这些数据，当网络问题解决之后，sentinel集群将原先的master节点降为slave节点，此时再从新的master中同步数据，将会造成大量的数据丢失。
  	    	3、	解决方案
  	    		1、redis的配置文件中，存在两个参数
  	    			1、min-slaves-to-write 3
  					2、min-slaves-max-lag 10
  					第一个参数表示连接到master的最少slave数量
  					第二个参数表示slave连接到master的最大延迟时间
  				按照上面的配置，要求至少3个slave节点，且数据复制和同步的延迟不能超过10秒，否则的话master就会拒绝写请求，配置了这两个参数之后，如果发生集群脑裂，原先的master节点接收到客户端的写入请求会拒绝，就可以减少数据同步之后的数据丢失
  	3、Redis Cluster模式
  		1、Redis Cluster是一种服务器 Sharding 技术，3.0版本开始正式提供。
              Redis 的哨兵模式基本已经可以实现高可用，读写分离 ，但是在这种模式下每台 Redis 服务器都存储相同的数据，很浪费内存，所以在 redis3.0上加入了 Cluster 集群模式，实现了 Redis 的分布式存储，也就是说每台 Redis 节点上存储不同的内容。
          2、原理：
          	 1、Redis集群没有使用一致性hash,而是引入了哈希槽的概念。一个 redis 集群包含 16384 个哈希槽，集群中的每个 redis 节点，分配到一部分槽。而集群使用公式 CRC16(key) % 16384 来计算每次请求的键 key 属于哪个槽，通过查询集群配置，便可知道 key 对应的槽属于哪个 redis 节点，然后再将请求打到该节点
          3、为什么要16384个槽位
          	1.如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大。
                  如上所述，在消息头中，最占空间的是 myslots[CLUSTER_SLOTS/8]（节点负责的槽信息）
                  当槽位为65536时，这块的大小是: 65536÷8÷1024=8kb因为每秒钟，
                  redis节点需要发送一定数量的ping消息作为心跳包，如果槽位为65536，
                  这个ping消息的消息头太大了，浪费带宽。
                   而16384÷8÷1024=2kb。
              2.redis的集群主节点数量基本不可能超过1000个。
                  如上所述，集群节点越多，心跳包的消息体内携带的数据越多。
                  如果节点过1000个，也会导致网络拥堵。因此redis作者，不建议redis cluster节点数量超过1000个。
                   那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了。没有必要拓展到65536个。
              3.槽位越小，节点少的情况下，压缩率高
                      Redis主节点的配置信息中，它所负责的哈希槽是通过一张bitmap的形式来保存的，
                      在传输过程中，会对bitmap进行压缩，但是如果bitmap的填充率slots / N很高的话(N表示节点数)，
                      bitmap的压缩率就很低。 如果节点数很少，而哈希槽数量很多的话，bitmap的压缩率就很低。
                  综上所述，作者决定取16384个槽，不多不少，刚刚好！

          4、Redis Cluster 的故障发现和转移
              Redis 集群内节点通过ping/pong消息实现节点通信，消息不但可以传播节点槽的信息，还可以传播其他状态信息。
                 	如：主从状态，节点故障。因此故障发现也是通过消息传播机制实现的。
                 		1、故障发现。
                 			1、主观下线。
                 				1、集群中每个节点都会定期向其他节点发送ping消息，并接收节点回复的pong消息作为响应。如果在一定时间内
                 				没有接收到消息，则发送节点会认为接收节点故障，把接收节点标记为主观线状态。
                 			2、客观下线。
                 				1、当某个发送节点把接收节点标记为主观下线后，节点的状态会在集群中进行广播。当半数以上持有槽的节点
                 				都标记某个节点主观下线时，该节点状态就被标记为客观下线，就会向集群中广播一条消息，通知所有节点将该节点标记为客观下线 。
                 		2、故障转移
                 			1、	故障节点变为客观下线后，他的每个从节点，都要检查最后与主节点断线的时间，判断是否有资格替换故障节点。
                 			如果从节点与主节点断线时间超过设置时间，当前从节点就不具备故障转移资格。
                 			2、从节点符合故障转移资格后，更新触发故障的选举时间，发起选举流程。当某个从节点获得n/2+1的节点个数后，
                 			就会触发替换主节点的操作。向集群广播自己的pong消息，通知集群内的所有的节点，当前从节点变为主节点 并接管了故障主节点的槽信息。

9、redis事务
     1、Redis事务
  		1、Redis中的事务是可以视为一个队列，即我们可以通过MULTI开始一个事务，这相当于我们声明了一个命令队列
     			接下来，我们向Redis中提交的每条命令，都会进入这个命令队列。
     	2、当执行EXEC命令时，将触发当前事务，从命令队列中取出命令执行。

     	2、Redis事务相关命令：
     		1、MULTI ：开启事务，redis会将后续的命令逐个放入队列中，然后使用EXEC命令来原子化执行这个命令系列。
     		2、EXEC：执行事务中的所有操作命令。
     		3、DISCARD：取消事务，放弃执行事务块中的所有命令。
     		4、WATCH：监视一个或多个key,如果事务在执行前，这个key(或多个key)被其他命令修改，则事务被中断，不会执行事务中的任何命令。
     		5、UNWATCH：取消WATCH对所有key的监视。

     	3、事务执行失败的错误场景
     		1、语法错误（编译器错误），在开启事务后，修改key1 => 11,修改key2 => 222 但是k2的语法错误，
     		最终导致事务提交失败，k1和 k2保留原值
     		2、Redis 类型错误（运行时错误），在开启事务后，修改k1 => 11,修改key => 2222,但是将k2的类型
     		作为list， 在运行时检测类型错误，最终导致事务提交失败，此时事务并没有回滚，而是跳过错误命令继续执行，
     		key1 的值改变，key2保留原值。

     	4、WATCH监视key
     		Redis事务是非原子性的，要让Redis事务完全具有事务回滚的能力，需要借助于命令WATCH来实现。

     		当使用EXEC执行事务命令时，首先会比对WATCH所监控的键值对，如果没有改变，他会执行事务队列中的命令，提交事务；
     		如果发生改变，将不会执行事务中的任何命令，同时事务回滚。
     	5、Redis事务为什么不支持回滚？
     		1、Redis认为，Redis 命令只会因为错误的语法而失败（并且这些语法不能在入队时发现），或是命令用在了错误的类型键上面
     		，也就是说，从实用性角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发过程被发现，而不是出现在生产环境中
     		2、因为不需要对回滚进行支持，所以Redis的内部可以保持简单且快速。

10、Redis 是单线程的？为什么还那么快。
  1、redis是单线程介绍
  	1、我们所说的redis单线程，指的是“其网络IO和键值对读写是由一个线程完成的”，也就是说，Redis中
  	只有网络请求模块和数据操作模块是单线程的。而其他的如持久化模块其实是支持多线程的。
  	2、Redis为什么这么快。
  		1、Redis 操作基于内存，绝大多数操作的性能瓶颈不在 CPU
  		2、单线程模型，避免了线程间切换带来的性能开销
  		3、redis为每一个数据结构，都设计了一种极多种底层实现 。例如string => SDS ,以便提供更好的性能。
  		4、Redis 采用了 IO 多路复用机制，就是为了让单线程(进程)的服务端应用同时处理多个客户端的事件。
  			Redis 的 I/O 多路复用模型进行一下描述说明：
  			1、一个 socket 客户端与服务端连接时，会生成对应一个套接字描述符(套接字描述符是文件描述符的一种)，每一个 socket 网络连接其实都对应一个文件描述符。
  			2、多个客户端与服务端连接时，Redis 使用 「I/O 多路复用程序」 将客户端 socket 对应的 FD 注册到监听列表(一个队列)中。当客服端执行 read、write 等操作命令时，I/O 多路复用程序会将命令封装成一个事件，并绑定到对应的 FD 上。
  			3、文件事件处理器」使用 I/O 多路复用模块同时监控多个文件描述符（fd）的读写情况，当 accept、read、write 和 close 文件事件产生时，文件事件处理器就会回调 FD 绑定的事件处理器进行处理相关命令操作。
  			4、整个文件事件处理器是在单线程上运行的，但是通过 I/O 多路复用模块的引入，实现了同时对多个 FD 读写的监控，当其中一个 client 端达到写或读的状态，文件事件处理器就马上执行，从而就不会出现 I/O 堵塞的问题，提高了网络通信的性能。

11、redis卡顿的原因：
   	1、使用复杂度高的命令
   		业务经常使用O(n)以上复杂度的命令，例如sort、sunion、zunionstore，或者在执行O(n)命令时操作的数据量比较大，这些情况下Redis处理数据时就会很耗时。
   		解决方案就是，不使用这些复杂度较高的命令，并且一次不要获取太多的数据，每次尽量操作少量的数据，让Redis可以及时处理返回。
   	2、存储大key
   		Redis在写入数据时，需要为新的数据分配内存，当从Redis中删除数据时，它会释放对应的内存空间。
   		如果一个key写入的数据非常大，Redis在分配内存时也会比较耗时。同样的，当删除这个key的数据时，释放内存也会耗时比较久
   	3、集中过期
   		如果有大量的key在某个固定时间点集中过期，在这个时间点访问Redis时，就有可能导致延迟增加。
   		Redis的主动过期的定时任务，也是在Redis主线程中执行的，也就是说如果在执行主动过期的过程中，出现了需要大量删除过期key的情况，
   		那么在业务访问时，必须等这个过期任务执行结束，才可以处理业务请求。此时就会出现，业务访问延时增大的问题，最大延迟为25毫秒。
   	4、实例内存达到上限
   		导致变慢的原因是，当Redis内存达到maxmemory后，每次写入新的数据之前，必须先踢出一部分数据，
   		让内存维持在maxmemory之下。这个踢出旧数据的逻辑也是需要消耗时间的，而具体耗时的长短，要取决于配置的淘汰策略：
   	5、Redis进行持久化时，通过save 和 bgsave  以及berewriteaof 时会fork出一个子进程。造成延迟。

12、redis Hot key 和 Big key 。
    在分布式缓存中，面对高并发要求有两个问题非常重要：热key问题（hot key）和大value（big key）问题。
    1、热key问题：是指缓存集群中的某个key在瞬间被数万甚至十万的并发请求打爆。
    2、大value问题：是指某个key对应的value可能有gb级别的大小，导致查询value的时候会引发网络相关的故障问题。

    1、热key问题
        要解决缓存中的热key问题也简单，主要分两步：监控热key和处理热key
        1、监控热key
            1、按业务场景，预估热点key（常用）
                这步是必做的，没啥技术难度，主要是对业务的预估和理解。比如秒杀商品业务中，秒杀的商品都是热点key。缺点是预估往往有偏差，总会有想不到的地方成为热点，或者突发的状况。
            2、客户端收集（常用）
                在访问redis客户端之前加入一行代码进行数据统计，统计方式多种多样，有本地计数、发消息单独处理统计等。优点：实现简单方便；缺点：代码侵入大。
            3、redis监控命令（常用）
                hotkeys命令：redis 4.0.3提供了redis-cli的热点key发现功能，执行redis-cli时加上–hotkeys选项即可，操作方便缺点：该参数在执行的时候，如果key比较多，执行起来比较慢。
        2、处理热key
            1、使用本地缓存（二级缓存）。
                发现热key以后，把热key加载到本地缓存中，比如go-cache.
                假设此时有十万个针对同一个key的请求过来,如果没有本地缓存，这十万个请求就直接怼到同一台redis上了。
                现在假设，你的应用层有50台机器，OK，你也有jvm缓存了。这十万个请求平均分散开来，
                每个机器有2000个请求，会从JVM中取到value值，然后返回数据。避免了十万个请求怼到同一台redis上的情形。
            2、备份热key
                不要让key走到同一台redis上不就行了。我们把这个key，在多个redis上都存一份不就好了。
                接下来，有热key请求进来的时候，我们就在有备份的redis上随机选取一台，进行访问取值，返回数据。
                我们知道 hot key 之所以是 hot key，是因为它只有一个key，落地到一个实例上。所以我们可以给hot key加上前缀或者后缀，
                把一个hotkey 的数量变成 redis 实例个数N的倍数M，从而由访问一个 redis key 变成访问 N * M 个redis key。 
                N*M 个 redis key 经过分片分布到不同的实例上，将访问量均摊到所有实例

    2、BigKey问题
        1、 什么是大Key
            通常我们会将含有较大数据或含有大量成员、列表数的Key称之为大Key，下面我们将用几个实际的例子对大Key的特征进行描述：
        2、寻找big key
            1、redis-cli自带--bigkeys，例如：redis-cli -h <hostip> -a <password> --bigkeys
        3、big key 原因和带来的问题
            1、业务上线前规划设计考虑不足没有对Key中的成员进行合理的拆分，造成个别Key中的成员数量过多（大Key）；
            2、没有对无效数据进行定期清理，造成如HASH类型Key中的成员持续不断的增加（大Key）
        4、解决big key
            1、对大Key进行拆分
                如将一个含有数万成员的HASH Key拆分为多个HASH Key，并确保每个Key的成员数量在合理范围，在Redis Cluster结构中，大Key的拆分对node间的内存平衡能够起到显著作用。
            2、对大Key进行清理
                将不适合Redis能力的数据存放至其它存储，并在Redis中删除此类数据。
                或者使用其他的存储形式，考虑使用 cdn 或者文档性数据库 MongoDB。
            3、对失效数据进行定期清理
                例如我们会在HASH结构中以增量的形式不断写入大量数据而忽略了这些数据的时效性，
                这些大量堆积的失效数据会造成大Key的产生，可以通过定时任务的方式对失效数据进行清理。
            4、时刻监控Redis的内存水位
                突然出现的大Key问题会让我们措手不及，因此，在大Key产生问题前发现它并进行处理是保持服务稳定的重要手段。
                我们可以通过监控系统并设置合理的Redis内存报警阈值来提醒我们此时可能有大Key正在产生，
                如：Redis内存使用率超过70%，Redis内存1小时内增长率超过20%等。

                通过此类监控手段我们可以在问题发生前解决问题，如：LIST的消费程序故障造成对应Key的列表数量持续增长，将告警转变为预警从而避免故障的发生。

13、为什么Redis 6.0 引入多线程
    1、 Redis 最初选择单线程网络模型的理由是：CPU 通常不会成为性能瓶颈，瓶颈往往是内存和网络，因此单线程足够了
    2、业务系统所要处理的线上流量越来越大，Redis 的单线程模式会导致系统消耗很多 CPU 时间在网络 I/O 上从而降低吞吐量
        要提升 Redis 的性能有两个方向：
        1、优化网络 I/O 模块
        2、提高机器内存读写的速度
        后者依赖于硬件的发展，暂时无解。所以只能从前者下手，因此，利用多核优势成为了优化网络 I/O 性价比最高的方案
        3、Redis 的核心网络模型在 6.0 版本之前，一直是单 Reactor 模式：所有事件的处理都在单个线程内完成
        4、Redis6.0 后，引入多线程之后单 Reactor 模式会进化为 Multi-Reactors 模式，基本工作模式如下：
            1、区别于单 Reactor 模式，这种模式不再是单线程的事件循环，而是有多个线程（Sub Reactors）各自维护一个独立的事件循环，
            2、由 Main Reactor 负责接收新连接并分发给 Sub Reactors 去独立处理，最后 Sub Reactors 回写响应给客户端
