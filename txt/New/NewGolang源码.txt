1、golang 如何实现多态？
	1、interface
		Go接口是一组方法的集合，可以理解为抽象的类型，他提供了一种非侵入式的接口。然和类型，只要实现了该接口中的方法集，那么就属于这个类型。
		例如：
			type Duck interface{
				Quack()
				DuckGo()
			}
			type Chickken struct{
			}
			func(c Chicken) IsChicken() bool{
				fmt.println("a chicken")
			}
			func (c Chicken) Quack() {
    				fmt.Println("嘎嘎")
			}
			func (c Chicken) DuckGo() {
   				 fmt.Println("大摇大摆的走")
			}

			注意，这里只是实现了 Duck 接口方法，并没有将鸡类型和鸭子接口显式绑定。这是一种非侵入式的设计。
			func DoDuck(d Duck) {
  			 	 d.Quack()
    			 d.DuckGo()
			}

			func main() {
   				 c := Chicken{}
    			 DoDuck(c)
			}

			执行正常。如此是不是很类似于其他语言的多态，其实这就是 Go 多态的实现方法。
			核心思想： 我理解为“依赖于接口而不是实现接口，优先使用组合而不是继承
			其他语言，例如 php ,生命一个接口，每个实现都需要 继承该接口，如果接口改动实现也需要跟着改动，是一种侵入式的。

	2 空接口和nil 区别
        1、interface底层由两部分组成：类型、值(type, value)，当二者均为nil时，此时interface才为nil。
	3、golang interface底层源码分析
		1、interface 底层接口
		    1、iface 和 eface 都是 Go 中描述接口的底层结构体，区别在于 iface 描述的接口包含方法，而 eface 则是不包含任何方法的空接口：interface{}。
		    2、iface 内部维护两个指针，tab 指向一个 itab 实体， 它表示接口的类型以及赋给这个接口的实体类型。data 则指向接口具体的值，一般而言是一个指向堆内存的指针。
                type iface struct {
                    tab  *itab
                    data unsafe.Pointer
                }
            3、相比 iface，eface 就比较简单了。只维护了一个 _type 字段，表示空接口所承载的具体的实体类型。data 描述了具体的值。
                type eface struct {
                    _type *_type
                    data  unsafe.Pointer
                }

				从这个数据结构可以看出，只有当 2 个字段都为 nil，空接口才为 nil。空接口的主要目的有 2 个，一是实现“泛型”，二是使用反射。

	4、类型断言
		一个interface被多种类型实现时，有时候我们需要区分interface的变量究竟存储哪种类型的值，go可以使用comma,ok的形式做区分 value, ok := em.(T)：em 是 interface 类型的变量，T代表要断言的类型，value 是 interface 变量存储的值，ok 是 bool 类型表示是否为该断言的类型 T。总结出来语法如下：
			<目标类型的值>，<布尔参数> := <表达式>.( 目标类型 ) // 安全类型断言
			<目标类型的值> := <表达式>.( 目标类型 )　　//非安全类型断言
			 d1,ok := d.(Dog)
			    if !ok{
			        return
			    }
2、Context
	1、背景
		Go 1.7 标准库引入 context，中文译作“上下文”，准确说它是 goroutine 的上下文，context 主要用来在 goroutine 之间传递上下文信息，包括：取消信号、超时时间、截止时间、k-v 等。

		举个例子：在Go 里，我们不能直接杀死协程，协程的关闭一般会用 channel+select 方式来控制。但是在某些场景下，例如处理一个请求衍生了很多协程，这些协程之间是相互关联的：需要共享一些全局变量、有共同的 deadline 等，而且可以同时被关闭。再用 channel+select 就会比较麻烦，这时就可以通过 context 来实现。

	2、context 底层实现原理
		1、Context 是一个接口，定义了 4 个方法，它们都是幂等的。也就是说连续多次调用同一个方法，得到的结果都是相同的
			1、Done() <-chan struct{}	当 context 被取消或者到了 deadline，返回一个被关闭的 只读channel
				注意：当这个 channel 被关闭时，说明 context 被取消了，读一个关闭的 channel 会读出相应类型的零值。并且源码里没有地方会向这个 channel 里面塞入值。换句话说，这是一个 receive-only 的 channel。因此在子协程里读这个 channel，除非被关闭，否则读不出来任何东西。也正是利用了这一点，子协程从 channel 里读出了值（零值）后，就可以做一些收尾工作，尽快退出。
			2、    Err() error 在 channel Done 关闭后，返回 context 取消原因
			3、 Deadline() (deadline time.Time, ok bool)		返回 context 是否会被取消以及自动取消时间（即 deadline）
			4、Value() 获取之前设置的 key 对应的 value。


			这个接口主要被三个类继承实现，分别是emptyCtx、ValueCtx、cancelCtx

	3、context类型
		1、emptyCtx
		    1、emptyCtx 是context.Background 和 context.TODO()的底层实现。
		    它是一个int类型，实现了Context接口所有的方法，但是没有做任何处理，都是默认返回空值。
		    2、emptyCtx结构体类型，是一个不可取消，没有设置截止时间，没有携带任何值的Context
		    3、
		2、cancelCtx
            type cancelCtx struct {
            	Context

            	// 保护之后的字段
            	mu       sync.Mutex
            	done     chan struct{}
            	children map[canceler]struct{}
            	err      error
            }

            1、WithCancelCtx()的底层实现。它直接将接口 Context 作为它的一个匿名字段
            2、从 parent Context 创建一个带有取消方法的 child Context，该 Context 可以手动调用 cancel
            3、cancelCtx 被定义为一个可以取消的 Context，而由于 Context 的树形结构，当作为 parent Context 取消时需要同步取消节点下所有
                child Context，这时候只需要遍历 children map[canceler]struct{} 然后逐个取消即可
		3、timerCtx
            type timerCtx struct {
                cancelCtx
                timer *time.Timer // Under cancelCtx.mu.

                deadline time.Time
            }
            1、timerCtx基于cancelCtx,只是多了一个timer.Timer 和一个deadline。timer会在deadline
            到来时，自动取消context.
            2、withTimeout和 WithDeadline的底层实现。
		4、valueCtx
		    type valueCtx struct {
            	Context
            	key, val interface{}
            }

		  1、 withValue（）底层实现 。直接将Context作为匿名字段，Context指向他的父节点，通过withValue()可以创建
		   层层的valueCtx，存储goroutine间可以共享的变量。
		  2、取值的过程，是一个向上递归的过程。先比较当前节点的key，如果存在，直接返回value，否者顺着context向上，
		    最终找到跟节点，直接返回nil.
		  3、父节点没有办法获取子节点存储的值，子节点可以获取父节点存储的值。
	4、有了根节点 context，又提供了四个函数创建子节点 context：
			func WithCancel(parent Context) (ctx Context, cancel CancelFunc)
			func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc)
			func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)
			func WithValue(parent Context, key, val interface{}) Context
        这四个With函数，接收的都有一个partent参数，就是父Context，我们要基于这个父Context创建出子Context的意思，
        这种方式可以理解为子Context对父Context的继承，也可以理解为基于父Context的衍生

3、golang锁
 1、互斥锁 Mutex 和 读写锁 RWMutex
 	1、互斥锁 Mutex
 		1.互斥锁有两种操作，获取锁和释放锁
		2.当有一个goroutine获取了互斥锁后，任何goroutine都不可以获取互斥锁，只能等待这个goroutine将互斥锁释放
		3.互斥锁适用于读写操作数量差不多的情况
		4.读写都可以放入互斥锁中

	Go 标准库中提供了 sync.Mutex 互斥锁类型及其两个方法：
		Lock 加锁
		Unlock 释放锁
	2、互斥锁的实现原理
		type Mutex struct {
			state int32		// 表示当前互斥锁的状态
			sema uint32	// 用来唤醒 goroutine 所用的信号量。
		}
	    1、state
	        state字段同时被多个goroutine公用（使用atomic来保证原子性），第一个bit表示已加锁
	        第2个bit表示被某个goroutine唤醒，尝试获取锁，第三个bit表示当前锁是否处于饥饿状态。

		2、饥饿状态
			1、正常状态
			 正常模式下，所有等待锁的goroutine按照FIFO顺序等待。但是唤醒的goroutine不会直接拥有锁，而是会和新请求锁的goroutine竞争。
			 新请求锁的goroutine具有优势：它正在CPU上执行，并且数量比较多，
			 所以刚刚唤醒的goroutine有很大可能在锁竞争中失败。
			 在这种情况下，这个被唤醒的goroutine会加入到等待队列的前面。 如果一goroutine等待超过1ms没有获取锁，那么互斥锁将进入饥饿模式。

			2、饥饿状态
			1、饥饿模式下，解锁的goroutine会将锁直接交付给等待队列的最前面的goroutine。新来的goroutine将不会尝试去获得锁，而是放在等待队列的尾部。
            2、如果一个等待的goroutine获取了锁，并且满足一以下其中的任何一个条件：(1)它是队列中的最后一个；(2)它等待的时候小于1ms。它会将锁的状态转换为正常状态。

    3、当 Go struct 遇上 Mutex。不能复制原因。
          我们使用 Mutex 是为了不同 goroutine 之间共享某个变量, 所以需要让这个变量做到能够互斥, 不然该变量就会被互相被覆盖.
          Mutex 底层是由 state sema 控制的, 当 Mutex 变量被复制时, Mutex 的 state, sema 当时的状态也被复制走了,
          但是由于不同 goroutine 之间的 Mutex 已经不是同一个变量了,
          这样就会造成要么某个 goroutine 死锁或者不同 goroutine 共享的变量达不到互斥

    4、struct 如何与 不可复制 的类型一块使用 ?
        type URL struct {
            Ip       string
            mux   	 *sync.RWMutex
        }

    将嵌套的不可复制变量改成指针类型变量，就可避免，但是要注意空指针问题。

 	2、读写锁RWMutex
 		1.读写锁有四种操作 读上锁 读解锁 写上锁 写解锁
 		2.写锁最多有一个，读锁可以有多个(最大个数据说和CPU个数有关)
		3.写锁的优先级高于读锁，这是因为为了防止读锁过多，写锁一直堵塞的情况发生
 		4.当有一个goroutine获得写锁时，其他goroutine不可以获得读锁或者写锁，直到这个写锁释放
 		由此也可得知，如果当一个goroutine希望获取写锁时，不断地有其他goroutine在获得读锁和释放读锁会导致这个写锁一直处于堵塞状态，所以让写锁的优先级高于读锁可以避免这种情况，

 		注意：6.读写锁适用于读多写少的情景。
 		Go 标准库中提供了 sync.RWMutex 互斥锁类型及其四个方法：
 			1、Lock 加写锁
			2、Unlock 释放写锁
			3、RLock 加读锁
			4、RUnlock 释放读锁
4、Map 源码
	1、使用make(map[int][int]) 创建一个map 时 ，会为其分配内存，创建hmap的结构体，并返回其指针类型。
    		2、map中的数据被存放在一个数组中，数组的元素是桶（bucket）,每个桶至多包含8个键值对数据。
    			哈希值的低位low-order-8bits 用于区分桶，哈希值的高位high-order-8bits用于在一个独立的桶中区分出键。
    		3、hmap 和buckets的结构如下：
    				type hmap struct {
    				 count    // 代表哈希表中的元素个数，调用len(map)时，返回该字段的值
    				 overflow  // 溢出桶的数量
    				 buckets  // 指向buckets数组指针，
    				 oldbuckets // 指向老的额buckets数组的指针，发生扩容时使用
    				 nevacuate  // 表示扩容进度，小于此地址的buckets代表已经搬迁完成
    				 extra //  额外信息。存储overflow buckets
    				 ...
    				}


    			type bmap struct {
    				tophash [bucketscnt]  uint8 // tophash包含此桶中的每个键的哈希值高8位的信息。
    				keys  // keys数组，隐藏字段
    				values // value 数组，隐藏字段
    				overflow // 溢出bucket指针，隐藏字段
    			}
    	  kv的存储形式为”key0key1key2key3…key7val1val2val3…val7″，这样做的好处是：在key和value的长度不同的时候，节省padding空间

    	 4、map 解决键冲突
    		Golang 使用的数组+链地址法解决hash冲突，当多个key映射到同一个位置的时候，会把冲突的key 通过overflow 溢出桶的指针链接起来，
    		形成一个链表。
    		读取的时候：
    			1、通过哈希函数得到key的哈希值
    			2、把hash值通过位操作得到索引
    	        3、通过索引找到链表,遍历链表对比key，返回其valu

    	5、map 的扩容
    		1、装载因子
    			loadFactor := count / (2^B) （count 就是 map 的元素个数，2^B 表示 bucket 数量。）
    			装载因子是表示哈希表中元素的填满程度。它的计算公式：装载因子=填入哈希表中的元素个数/哈希表的长度。
    	        装载因子越大，填入的元素越多，空间利用率就越高，但发生哈希冲突的几率就变大。
    			反之，装载因子越小，填入的元素越少，冲突发生的几率减小，但空间浪费也会变得更多，而且还会提高扩容操作的次数
    		2、扩容流程
    			1、确定扩容机制
    				1、翻倍扩容
    					当装载因子 大于6.5时，说明大部分的bucket都快满了，查找和插入的效率变低，这个时候会触发【翻倍扩容】
    					创建一个新的buckets 容量是原来buckets的两倍。
    				2、等量扩容
    					1、当溢出桶的总数，大于等于桶总数的时候，认为溢出桶过多，
    					2、当溢出痛的数量大于2^15时，也会认为溢出桶数量太多，
    					以上都会触发等量扩容
    			2、扩容流程
    				1、由于 map 扩容需要将原有的 key/value 重新搬迁到新的内存地址，如果有大量的 key/value 需要搬迁，会非常影响性能。
    				   因此 Go map 的扩容采取了一种称为“渐进式”地方式，原有的 key 并不会一次性搬迁完毕，每次最多只会搬迁 2 个 bucket。
    				2、扩容主要涉及 hashGrow() 和 growWork() 两个函数. hashGrow() 是开启扩容, 并没有进行真正的数据"搬移",它只是分配好了新的 buckets
    					并将老的 buckets 挂到了 oldbuckets 字段上.
    					真正的 buckets 搬移动作是在 growWork() 函数.调用 mapassign()(插入,更新) 和 mapdelete()(删除) 函数时会尝试搬移 buckets 的工作.

    	6、map的遍历
    			1、随机选择开始的位置，然后依次遍历桶中的元素，桶中元素如果被遍历完，就会遍历当前桶对应的溢出桶，溢出桶都遍历结束之后才会遍历哈希中的下一个桶，直到所有的桶都被遍历完成。
    			2、如果正在扩容。如果 map 正处于扩容状态时，需要先判断当前遍历 bucket 是否已经完成搬迁，如果数据还在老的 bucket，那么就去老 bucket 中拿数据。
    	7、map的删除
    		1、计算 key 的哈希，找到落入的 bucket。检查此 map 如果正在扩容的过程中，直接触发一次搬迁操作。
    			在 bucket 中挨个 cell 寻找。找到对应位置后，对 key 或者 value 进行“清零”操作。最后，将 count 值减 1，将对应位置的 tophash 值置成 Empty。
    		2、删除掉map中的元素是否会释放内存
    			答：不会，删除操作仅仅将对应的tophash[i]设置为empty，并非释放内存。若要释放内存只能等待指针无引用后被系统gc
        8、使用建议
            1、从map设计可以知道，它并不是一个并发安全的数据结构。同时对map进行读写时，程序很容易出错。
                因此，要想在并发情况下使用map，请加上锁（sync.Mutex或者sync.RwMutex）。其实，Go标准库中已经为我们实现了并发安全的map——sync.Map

            2、遍历map的结果是无序的，在使用中，应该注意到该点。
                原因：Go 做得更绝，当我们在遍历 map 时，并不是固定地从 0 号 bucket 开始遍历，每次都是从一个随机值序号的 bucket 开始遍历，并且是从这个 bucket 的一个随机序号的 cell 开始遍历
            3、通过map的结构体可以知道，它其实是通过指针指向底层buckets数组。所以和slice一样，尽管go函数都是值传递，
               但是，当map作为参数被函数调用时，在函数内部对map的操作同样会影响到外部的map

            4、1.无论什么情况下len操作总是正常的
              2.同时read不会引发异常，同时read和write会异常，同时write会异常。
              3.read或write的同时，json.Marshall或json.Unmarshall此类解析方法也应避免使用，否则也会引发异常。
           5、map无序，若实现有序。可以将所有的keys取出来放在slice中，排序keys 然后在遍历map

5、Sync.Map
	sync.Map是协程安全的，并通过读写分离的机制，降低锁的粒度，提高并发性能。
		1、	type Map struct {
						mu Mutex 	// 互斥锁，当涉及到dirty数据的操作的时候，需要使用这个锁

						read atomic.Value // readOnly 。 是一个只读的数据结构，因为只读，并不会有读写冲突，从这个数据中读取总是安全的。

						dirty map[interface{}]*entry	// dirty数据 包含当前的map数据中的entries , 对于dirty的操作需要加锁，因为对它的操作可能会有读写竞争

						misses int // 当从Map中读取到entry的时候，如果read中不包含这个entry，会尝试从dirty中读取，这个时候会将misses加一，只有当misses累积到dirty的长度的时候，就会将dirty提升为read，避免从dirty中miss太多次，因为dirty需要加锁。
				}

		2、需要介绍下read的数据结构

			read的数据结构是：
				type readOnly struct {
					m       map[interface{}]*entry
					amended bool // 如果Map.dirty有些数据不在中read的时候，这个值为true
				}

			amended指明Map.dirty中有readOnly.m未包含的数据，所以如果从Map.read找不到数据的话，还要进一步到Map.dirty中查找


		3、介绍下entry数据结构
			type entry struct {
				p unsafe.Pointer // *interface{}
			}
			readOnly.m和Map.dirty存储的值类型是*entry,它包含一个指针p, 指向用户存储的value值。
			read和dirty有冗余数据，但这些数据是通过指针指向同一个数据，所以尽管Map的value会很大，但是冗余的空间占用还是有限的


		4、分别介绍load和store，delet，range

			4.1 Load
				加载方法，也就是提供一个键key,查找对应的值value。

				流程：
				1、首先从m.read中得到只读readOnly,从它的map中查找，不需要加锁。如果找到直接返回。如果没找到，并且m.dirty中有新数据，需要从m.dirty查找，这个时候需要加锁，并且 不管m.dirty中存不存在，都将misses计数加一。并且当misses值 和dirty中数据个数一样的时候。把dirty提升为read。接下来还是从read中直接读取。

				有两个需要关注的地方：
					1、一个是首先从m.read中加载，不存在的情况下，并且m.dirty中有新数据，加锁，然后从m.dirty中加载。
					2、二是这里使用了双检查的处理。
						if !ok && read.amended {
							m.mu.Lock()

						因为在加锁之前，m.dirty可能被提升为m.read,所以加锁后还得再检查m.read，后续的方法中都使用了这个方法。


			4.2 Store (更新或者新增一个entry)
				流程：
				1、如果m.read存在这个键，并且这个entry【没有被标记删除】，尝试直接存储。（因为m.dirty也指向这个entry,所以m.dirty也保持最新的entry）
				2、如果 m.read不存在这个值， 并且m.dirty中存在，则直接更新m.dirty的值
				3、如果m.read和 m.dirty中都不存在，那么是是一个新键值，插入到m.dirty中。（存在一个判断m.dirty是否有新更新数据操作。并且复制m.read数据到m.dirty中）

			4.3 delete （删除一个键值。）
				流程
				1、删除操作还是从m.read中开始， 如果这个entry不存在于m.read中，并且m.dirty中有新数据，则加锁尝试从m.dirty中删除。
				2、如果存在于m.read中。则从m.read中删除（注意：不是直接删除而是，打上已删除标记）

			4.4 Range(遍历操作)
				1、流程：（会根据read.amend值，先判断 m.dirty中是否有新数据，则提升m.dirty,然后在遍历）

6、切片（slice） 和 数组
	1、数组是一种有固定长度的基本数据结构，一旦创建长度就不允许修改，数组的空余位置用0填补，不允许越界，越界panic
	2、slice 是一个特殊的引用类型，本身也是个结构体
		type slice struct {
		    array unsafe.Pointer
		    len   int
		    cap   int
		}
	   1、属性len表示可用元素数量,读写操作不能超过这个限制,不然就会panic

       2、属性cap表示最大扩张容量,当然这个扩张容量也不是无限的扩张,它是受到了底层数组array的长度限制,超出了底层array的长度就会panic

		1、切片的创建
			1、通过数组创建
			2、通过 slice := make([]int ,3,5)
			切片是个引用类型,所以它作为参数传递给函数,函数操作的实质是底层数组
		2、	切片的扩容
			1、5、切片扩容后是新数组or 旧数组？
				1、如果原数组还有容量可以扩容，则在执行append（）操作后，会在原数组上直接操作，所以这时候，切片扩容后的数组还是指向的原来数组，并且原来数组会跟随改变。
				2、如果原来的数组的容量已经将达到了最大值，则在扩容时会根据扩容策略，开辟一片新的内存区域，把原来数组的值拷贝过来，然后执行append操作，这个时候不会影响原数组。
				1、扩容策略
					1、首先先判，如果新申请容量（cap）大于2倍的旧容量（old.cap）,最终容量（newCap）就是新申请的容量（cap）
					2、否则判断，如果旧切片的长度小于1024，则最终容量（newcap），就是旧容量（old.cap）的两倍。即newcap = 			doublecap
					3、否者判断，如果旧切片的长度大于等于1024，则最终容量（newcap）从旧容量	old.cap）的两倍。即newcap开始循环增加原来的1/4 即 （参考slice源码）newcap = old.cap for {newcap += newcap/4},直到最终容量（newcap) 大于等于新申请的容量cao .即 newcap 》= cap .
		3、切片作为函数参数是传值还是传引用
			理清三个重要的 概念。
	 	1、值传递
	 		值传递是指在调用函数时将实际参数拷贝一份传递到函数中，这样在函数中对参数进行修改不会影响到实际参数。

	 	2、传指针
	 		传指针是指 形参是指向实际参数的指针，当对形参的指向进行操作时，相当于对实参本身进行操作。
	 	3、引用传递是指调用函数时将实际参数的地址传递到函数中，在函数中对参数进行修改，影响实际参数。
	 		c++中才有引用传递。
	 	官方文档已经明确说明：Go里边函数传参只有值传递一种方式。但是，slice，channel，map 本身就是引用类型，因此可以修改外部的数据。

7、Sync.Once
	1、Once 可以用来执行且仅仅执行一次动作，常常用于用来初始化单例资源，或者并发访问只需初始化一次的共享资源，或者在测试的时候初始化一次测试资源。

	sync.Once 只暴露了一个方法 Do，你可以多次调用 Do 方法，但是只有第一次调用 Do 方法时 f 参数才会执行，这里的 f 是一个无参数无返回值的函数
		type Once struct {
		   done uint32 // 初始值为0表示还未执行过，1表示已经执行过
		   m    Mutex
	}

	2、Do函数
		1、调用 Do 函数时，首先判断done值是否为0，若为1，表示传入的匿名函数 f() 已执行过，无需再次执行；若为0，表示传入的匿名函数 f() 还未执行过，则调用 doSlow() 函数进行初始化。
		2、在 doSlow() 函数中，若并发的goroutine进入该函数中，为了保证仅有一个goroutine执行 f() 匿名函数。为此，需要加互斥锁保证只有一个goroutine进行初始化，同时采用了双检查的机制(double-checking)，再次判断 o.done 是否为 0，如果为 0，则是第一次执行，执行完毕后，就将 o.done 设置为 1，然后释放锁。
8、golang GC
	垃圾回收是编程语言中提供的自动的内存管理机制，目的是自动释放不需要的对象，让出存储器资源，这一过程无需由开发人员手动执行。

	1、golang GC 算法演变过程
		版本	GC 算法
			v1.1	Mark 、Sweep、STW （STW(stop the word)）
			v1.3	Mark STW,Sweep (标记清除)
			v1.5	三色标记
			v1.8	hybrid write barrier (三色标记基础上加入写屏障)

	2、Go V1.3之前的标记-清除(mark and sweep)算法
		此算法主要由两个步骤
			1、标记(Mark phase)
			2、清除(Sweep phase)

		1、第一步 暂停程序业务逻辑，程序找出它所有可达的对象，然后做上标记。
			操作非常简单，但是有一点需要额外注意：mark and sweep算法在执行的时候，需要程序暂停！即 STW(stop the world)。也就是说，这段时间程序会卡在哪儿
			参考图片：https://img.kancloud.cn/01/60/0160c38ec63623f3108550ff648f0959_1494x1248.png
		2、	标记完了之后，然后开始清除未标记的对象
			参考图：https://img.kancloud.cn/3e/a9/3ea9ec35364a573c669f5f32c03c8b50_1344x1326.png

		3、第四步, 停止暂停，让程序继续跑。然后循环重复这个过程，直到process程序生命周期结束。

		分析、标记-清扫(mark and sweep)的缺点
			1、STW，stop the world；让程序暂停，程序出现卡顿 (重要问题)。
			2、标记需要扫描整个heap，会产生heap碎片

	3、Go V1.3之前 和 v1.3版本的标记-清除(mark and sweep)算法	对比
		1、Go V1.3版本之前就是以上来实施的, 流程是：
			启动STW  => Mark标记 =》 Sweep清除 =〉 停止STW
			参考：https://img.kancloud.cn/c7/da/c7da67305d321015d28af3f505ccc748_2426x578.png
		2、Go V1.3 做了简单的优化,将STW提前, 减少STW暂停的时间范围.
			启动STW  => Mark标记 =》 停止STW =〉 Sweep清除
			参考 https://img.kancloud.cn/7f/c9/7fc93a9ae9387d34e9843eb1edec31fe_2410x520.png

		Go V1.3 及之前版本的 mark and Sweep 算法 最大的问题是 STW会造成程序卡顿。go V1.5提出了三色标记法，来优化这个问题。

	4、Go v1.5 三色标记法
		1、为了解决原始标记清除算法带来的长时间 STW。垃圾收集器都会实现三色标记算法的变种以缩短 STW 的时间。三色标记算法将程序中的对象分成白色、黑色和灰色三类：

            白色对象 — 潜在的垃圾，其内存可能会被垃圾收集器回收；
            黑色对象 — 活跃的对象，包括不存在任何引用外部指针的对象以及从根对象可达的对象；
            灰色对象 — 活跃的对象，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象；

        2、在垃圾收集器开始工作时，程序中不存在任何的黑色对象，垃圾收集的根对象会被标记成灰色，
        垃圾收集器只会从灰色对象集合中取出对象开始扫描，当灰色集合中不存在任何对象时，标记阶段就会结束。
            1、将根节点标记为灰色，其他节点标记为白色
            2、在灰色对象中选择一个标记为黑色
            3、将黑色对象指向的所有对象都标记为灰色
            4、重复前两个步骤直到所有对象中没有灰色对象
            5、清除所有白色对象

        3、为什么要有屏障保护
        如果在三色标记法中 一个白色对象被黑色对象引用，是注定无法通过这个黑色对象来保证自身存活的。
        为了防止这种现象发生，最简单的方式就是STW，直接禁止掉其他用户程序对对象饮用关系的干扰。但是STW过程明显的浪费资源。
        因此需要屏障技术来保证对象不丢失的情况下尽可能的提高GC效率，减少STW时间。

  5、三色变式
      1、 想要在并发或者增量的标记算法中保证正确性，我们需要达成以下两种三色不变性（Tri-color invariant）中的一种：
            1、强三色不变性  （黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象）
            2、弱三色不变性（黑色对象可以引用白色对象，白色对象存在其他灰色对象对它的引用，或者可达它的链路上游存在灰色对象）

            屏障技术就是在并发或增量标记过程中保证三色不变式的重要技术

              1、插入写屏障
                1、插入写屏弹是一种相对保守的屏障技术，它会将有存活可能的对象都标记为灰色以满足强三色不变式。
                2、在Golang中，对栈上指针的写入添加写屏障的成本很高，所以Go选择仅对堆上的指针插入增加写屏障，
                这样就会出现在扫描结束后，栈上可能存在引用白色对象的情况，
                所以需要对栈进行重新扫扫描，完成剩余对象的标记，这个过程需要STW。
                这期间会将所有goroutine挂起，当有大量应用程序时，时间可能会达到10～100ms。

             2、删除写屏障
                1、删除写屏障也叫基于快照的写屏障方案，必须在起始时，STW 扫描整个栈（注意了，是所有的 goroutine 栈），
                    被删除的对象，如果自身为灰色或者白色，那么被标记为灰色。满足了弱三色不变式原则，保护灰色对象到白色对象的可达路径不会断。
                3、回收精度低，一个对象即使被删除了最后一个指向它的指针，也依然可以活一轮GC，在下一轮GC中才被清除

            3、混合写屏障
               1、 插入写屏障和删除写屏障的短板：
                    1、插入写屏障：结束时需要STW来重新扫描栈，标记栈上引用的白色对象的存活；
                    2、删除写屏障：回收精度低，GC开始时STW扫描堆栈来记录初始快照，这个过程会保护开始时刻的所有存活对象。
                 Go V1.8版本引入了混合写屏障机制（hybrid write barrier），避免了对栈re-scan的过程，极大的减少了STW的时间。结合了两者的优点。

               2、在 v1.8 版本中，由插入写屏障和删除写屏障构成了如下所示的混合写屏障，其流程如下：
                     1、混合写屏障只在堆上启用，栈上不启用
                     2、GC 开始，扫描栈区。将栈上的全部可达对象标记为黑色，之后便不再需要进行重新扫描
                     3、GC 期间，任何在栈上新创建的对象都标记为黑色
                     4、堆上将被删除的对象标记为灰色
                     5、堆上将新添加的对象标记为灰色

      6、GC触发条件
            1、主动触发(手动触发)，通过调用 runtime.GC 来触发GC，此调用阻塞式地等待当前GC运行完毕。
            2、被动触发，分为两种方式：
                1、使用步调（Pacing）算法，其核心思想是控制内存增长的比例,每次内存分配时检查当前内存分配量是否已达到阈值（环境变量GOGC）：默认100%，即当内存扩大一倍时启用GC。
                2、当超过两分钟没有产生任何GC时，强制触发 GC
      7、频繁GC原因和解决方案

9、逃逸分析
   1、 什么是堆内存和栈内存？
    根据内存管理（分配和回收）方式的不同，可以将内存分为 堆内存 和 栈内存。
      1、堆内存：由内存分配器和垃圾收集器负责回收
      2、栈内存：由编译器自动进行分配和释放

     3、 一个程序运行过程中，也许会有多个栈内存，但肯定只会有一个堆内存。每个栈内存都是由线程或者协程独立占有，因此从栈中分配内存不需要加锁，并且栈内存在函数结束后会自动回收，性能相对堆内存好要高。

     4、而堆内存呢？
        由于多个线程或者协程都有可能同时从堆中申请内存，因此在堆中申请内存需要加锁，避免造成冲突，并且堆内存在函数结束后，需要 GC （垃圾回收）的介入参与，如果有大量的 GC 操作，将会吏程序性能下降得历害。

    1、说白了就是：逃逸分析是编译器用于决定变量分配到栈还是堆上的一种行为。
       go在一定程度上消除了堆和栈的区别，因为go在编译的时候进行了逃逸分析，来决定一个对象放到栈上还是堆上，
       不逃逸的对象放栈上，可能逃逸的放到堆上
    2、逃逸分析场景
        1、 情景1：典型的逃逸case，函数返回局部变量的指针。
                 func test1()*int{
                        var a =10
                        return &a
                    }
        2、 栈空间不足
               func test {
                            t := make([]int ,1000,1000)
                            s :=make([]itn,10000,10000)
                            for i:=0;i<len(s);i++{
                                s[i[]= i
                        }
                }

        3、动态类型逃逸
            很多函数参数为interface类型
            func main() {

            	fmt.Println("hello 程序猿编码")
            	fmt.Print("hello minger")
            }
            func Printf(format string, a ...interface{}) (n int, err error)
        4、被指针类型的slice，map 和 chan 引用的指针一定发生逃逸。
             备注：在stack overflow有人提问为什么使用指针的chan比使用值的chan慢30%，就是因为使用指针的chan发生了逃逸，gc拖慢了速度。
                   a := make([]*int,1)
                   b := 12
                   a[0] = &b

         5、逃逸分析的好处
                    终端运行命令查看逃逸分析日志：
                    go build -gcflags=-m        -m 会打印出逃逸分析的优化策略。

                1、减少gc压力，不逃逸的对象分配到栈上，当函数返回时就回收了资源，不需要gc标记清除
                2、逃逸分析后可以确定那变量可以分配到栈上，栈的分配比堆快，因此性能更好。
10、goroutine 内存泄漏
    1、什么是内存泄漏？
    内存泄露 memory leak，是指程序在申请内存后，无法释放已申请的内存空间。
    goroutine 泄漏会导致 内存中存活的goroutine数量不断上升，直到服务器宕机。
    2、golang 内存泄漏分析工具和场景。


            3、内存泄漏场景
                1、资源泄露。比如文件、数据库连接、TCP的连接，你如果忘记调用了它的Close方法，就会导致打开的文件描述符超过限制，或者底层的tcp连接不能被释放。
                   例如： resp.Body.Close() 没有关闭 导致的内存泄漏

                   http 源码包发现 一次建立连接，就会启动一个读goroutine和写goroutine。这就是为什么一次http.Get()会泄漏两个goroutine的来源，
                  resp.Body.Close() 没有调用 会导致 readLoop和 writeLoop 两个goroutine在 写入请求并获取response返回后，并没有跳出for循环，而继续阻塞在 下一次for循环的select 语句里面。
                  两个函数所在的goroutine并没有运行结束。

                   goroutine持续增加导致内存持续增加
                2、goroutine leak（协程泄露）
                    1、goroutine由于channel的读/写端未正常退出而一直阻塞，导致goroutine一直占用资源，而无法退出
                    例如：func leak() {
                          ch := make(chan struct{})
                          go func() {
                              ch <- struct{}{}
                          }()
                      }
                3、Mutex 导致 泄漏。
                   第一个互斥锁 sync.Mutex 加锁了，由于他可能在处理业务逻辑，或者是忘记 Unlock 解锁了。
                   因此导致后面的所有 sync.Mutex 想加锁，却因锁未释放又都阻塞住了。 建议在加锁后来一句defer mutex.Unlock()

                    var mutex sync.Mutex
                    	for i := 0; i < 10; i++ {
                    		go func() {
                    			mutex.Lock()
                    			total += 1
                    		}()
                    	}

                4、解决泄漏。
                    1、预防
                        1、在代码部署之前,功过Uber 开源的 go-leak库来检查程序中是否存在泄漏。
                            goleak 通过对运行时的栈分析获取 goroutine 状态.
                            在现有测试的首行添加 defer goleak.VerifyNone(t)，即可集成 goleak 泄漏检测：

                    2、监控
                        1、早期的工具
                             1、golang 提供的 pprof 工具可以很方便的分析性能上的问题比如cpu的使用情况，堆内存分配，goroutine 死锁情况等
                               1、浏览器方式
                                  如果你的应用程序是一直运行的，比如 web 应用，那么可以使用net/http/pprof库，它能够在提供 HTTP 服务进行分析。
                                   1、 //引用pprof
                                        import "net/http"
                                        import_ "net/http/pprof"
                                   2、你的 HTTP 服务都会多出/debug/pprof，在浏览器中访问即可 ，会显示goroutine堆栈和内存分配信息。
                               2、命令行方式
                                    使用命令 go tool pprof url可以获取指定的profile文件，比如：profile类型alloc已分配的内存，inuse代表使用中的内存。
                                    最常用的：top、list、traces，分别介绍一下。
                                     1、top 按指标大小列出前10个函数，比如内存是按内存占用多少，CPU是按执行时间多少。
                                     2、list 查看某个函数的代码，以及该函数每行代码的指标信息，如果函数名不明确，会进行模糊匹配，比如list main会列出main.main和runtime.main。
                                     3、traces 打印所有调用栈，以及调用栈的指标信息。

                             2、现在 通过Prometheus 监控收集线上资源的占用情况，并把监控收集到的数据，通过kibana仪表盘进行展示。
11、反射
    1、golang的反射实现原理
        通过反射机制可以动态获取对象的类型、值、方法甚至动态改变对象的成员。
    2、反射的规则
        1、从接口值到反射对象的反射。
            1、从relfect.Value中获取接口interface的信息

        2、从反射对象到接口值的反射。
            1、已知类型后转换为其对应的类型的做法如下，直接通过Interface方法然后强制转换
                realValue := value.Interface().(已知的类型)
            2、未知原有类型【遍历探测其Filed】

        3、为了修改反射对象，其值必须可设置。
            reflect.Value是通过reflect.ValueOf(X)获得的，只有当X是指针的时候，才可以通过reflec.Value修改实际变量X的值，

    3、Golang reflect慢主要有两个原因
        1、涉及到内存分配以及后续的GC；
        2、reflect实现里面有大量的枚举，也就是for循环，比如类型之类的。

12、WaitGroup
    	WaitGroup是多个goroutine之间协作的一种实现方式，主要功能就是阻塞等待一组goroutine执行完成。
    	常用的使用场景：主goroutine调用Add函数设置需要等待的goroutine的数量,当每个goroutine执行完成后调用Done函数(将counter减1)，Wait函数用于阻塞等待直到该组中的所有goroutine都执行完成

    	1、waitGroup方法及数据结构概念。

      	type WaitGroup struct {
    		noCopy noCopy  / 该WaitGroup对象不允许拷贝使用,只能用指针传递
    		state1 [12]byte // 用户存储计数器(counter)和waiter的值。只需要64位，其中高32位是counter值，低32位值是waiter值，不直接使用unit64位，是因为uint64的原子操作需要64位操作系统，而32位系统下，可能会出现崩溃。所以使用btye数组来实现。32位系统下4字节对齐，64位系统下8字节对齐，所以申请12个字节。其中必定有8个字节是符合8字节对齐的。在state（）函数中有进行判断。
    	}

        state[0],   state[1],   state[2]
       64位   waiter,     counter,    sema
       32位    sema ,      waiter,   counter,
        从结构体中我们看到 waitgroup结构体中state1的格式很重要。共占12个字节,用于存储counter和waiter的值 sema就是传说中的信号量。

            1、waiter 是等待者计数，
            2、counter 是任务计数，
            3、sema 是信号量


    	2、state函数
    		state是一个内部函数，用于获取counter和 waiter的值

    	//获取counter  、 waiter的值  (counter是uint64的高32位，waiter是uint64的低32位)
    	func (wg *WaitGroup) state() *uint64 {
    		// 根据state1的起始地址分析,若是8字节对齐的,则直接用前8个字节作为*uint64类型
    		// 若不是,说明是4字节对齐,则后移4个字节后,这样必为8字节对齐,然后取后面8个字节作为*uint64类型
    		if uintptr(unsafe.Pointer(&wg.state1))%8 == 0 {
    			return (*uint64)(unsafe.Pointer(&wg.state1))
    		} else {
    			return (*uint64)(unsafe.Pointer(&wg.state1[4]))
    		}
    	}

    	3、Add 函数
    		用于增加或减少计数器(counter)的，如果计数器为0，则释放调用Wait方法时的阻塞，如果计数器为负，则panic
    		参考流程图：
    			https://mmbiz.qpic.cn/mmbiz_png/picLDrXZzlobmEsicxu1Bic6jmxjTu44hiaLlgNGupxmib49p514r4aqtyciaDWibcPOfdEzaY44S6rqYsNln0icVFk75w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1

    			关键判断：
    			//1.counter > 0,说明还不需要释放信号量，可以直接返回
    		//2. waiter  = 0 ,说明没有等待的goroutine，也不需要释放信号量，可以直接返回
    		if v > 0 || w == 0 {
    			return
    		}

    	4、done 函数
    		//将计数器(counter)的值减1
    		相当于Add(-1)

    	5、wait 函数
    		调用Wait方法会阻塞当前调用的goroutine直到 counter的值为0。会一直阻塞，一直等待，直到无需等待或信号量触发，才返回
    		参考流程图：
    		https://mmbiz.qpic.cn/mmbiz_png/picLDrXZzlobmEsicxu1Bic6jmxjTu44hiaLyuze241iaqn1nGjTcHf360keZkQxwPFXic23dW6SHiaPkvNia0ZYHiaqZtA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1

    	6、注意点
    	1.Add()必须在Wait()前调用

    	2.Add()设置的值必须与实际等待的goroutine个数一致，如果设置的值大于实际的goroutine数量，可能会一直阻塞。如果小于会触发panic

    	3. WaitGroup不可拷贝，可以通过指针传递，否则很容易造成BUG
13、内存对齐
	1、为什么要内存对齐
		1、CPU访问内存时，并不是逐个字节访问的，而是以字长 位单位进行访问的。比如32位CPU ,子长的单位为4字节，那么CPU 访问内存的
        单位也是4字节。
        2、内存对齐的优点：
        	1、进行内存对齐，减少内存的访问次数，提高内存读写的性能
        	2、内存对齐，便于实现变量操作的原子性。
	2、go语言通过unsafe.Alignof 描述对齐规则
		1、对任意类型的变量X，unsafe.AlignOf（x）至少为1
		2、对于struct结构体类型变量X，计算每一个字段f 的 unsafe.Alignof(x),unsafe.AlignOf(x)等于其中最大值
		3、对于array数组类型的变量x，unsafe.Align(x) 等于构成数组的元素类型的对齐倍数。

	3、struct内存对齐的技巧
		1、合理布局可以减少内存占用
			假设一个 struct 包含三个字段，a int8、b int16、c int64
			顺序会对 struct 的大小产生影响顺序会对 struct 的大小产生影响
			type demo1 struct {
				a int8
				b int16
				c int32
			}

			type demo2 struct {
				a int8
				c int32
				b int16
			}
			每个字段按照自身的对齐倍数来确定在内存中的偏移量，字段排列顺序不同，上一个字段因偏移而浪费的大小也不同。

			1、接下来逐个分析，首先是 demo1：
			1、a 是第一个字段，默认是已经对齐的，从第 0 个位置开始占据 1 字节。
			2、b 是第二个字段，对齐倍数为 2，因此，必须空出 1 个字节，偏移量才是 2 的倍数，从第 2 个位置开始占据 2 字节。
			3、c 是第三个字段，对齐倍数为 4，此时，内存已经是对齐的，从第 4 个位置开始占据 4 字节即可。
			因此 demo1 的内存占用为 8 字节

			其实是 demo2：

		    1、是第一个字段，默认是已经对齐的，从第 0 个位置开始占据 1 字节。
			2、c 是第二个字段，对齐倍数为 4，因此，必须空出 3 个字节，偏移量才是 4 的倍数，从第 4 个位置开始占据 4 字节。
			3、b 是第三个字段，对齐倍数为 2，从第 8 个位置开始占据 2 字节。
			demo2 的对齐倍数由 c 的对齐倍数决定，也是 4，因此，demo2 的内存占用为 12 字节。

			因此，在对内存特别敏感的结构体的设计上，我们可以通过调整字段的顺序，减少内存的占用。

	4、 空 struct{} 的对齐
			空 struct{} 大小为 0，作为其他 struct 的字段时，一般不需要内存对齐。但是有一种情况除外：即当 struct{} 作为结构体最后一个字段时，需要内存对齐。因为如果有指针指向该字段, 返回的地址将在结构体之外，如果此指针一直存活不释放对应的内存，就会有内存泄露的问题（该内存不因结构体释放而释放）。

			type demo3 struct {
				c int32
				a struct{}
			}

			type demo4 struct {
				a struct{}
				c int32
			}

			func main() {
				fmt.Println(unsafe.Sizeof(demo3{})) // 8
				fmt.Println(unsafe.Sizeof(demo4{})) // 4
			}

			可以看到，demo4{} 的大小为 4 字节，与字段 c 占据空间一致，而 demo3{} 的大小为 8 字节，即额外填充了 4 字节的空间。

        参考链接：https://geektutu.com/post/hpg-struct-alignment.html
14、什么是野指针
    1、什么是野指针
        野指针：指向内存被释放的内存或者没有访问权限的内存的指针。
    3、golang 怎么解决避免野指针
    		golang中不存在野指针，因为golang有自己的垃圾回收和逃逸分析。
    		Golang会在返回局部变量的指针时，进行“逃逸分析”，如果它分析出来返回的是指针的话，分配内存的时候，
    		就不会在栈上分配，而是逃逸到堆上去分配，从而避免被垃圾回收。
15、Go内存管理和内存分配。

    1、分配内存的三大组件。
        Go分配内存的过程，主要由三大组件所管理，级别从上到下分别是：mheap,mcentral, mcache。
        1、mheap
          Go在程序启动的时候，首先会向操作系统申请一大块内存，并交由mheap堆 进行全局管理。
          mheap会将申请的这一块内存，切分成不同规格大小的内存块，称为mspan。
        2、mcentral
          启动一个Go程序，会初始化很多的mcentral，每个mcentral只负责管理一种特定规格的mspan内存块。
          相当于mcentral 实现了在mheap基础上对mspan的精细化管理。
        3、mcache
          由于mcentral在Go程序中全局可见，每次协程来mcentral申请内存的时候，都需要加锁释放锁。因此使用mcache作为代理来缓冲
          mcentral的压力。
          在一个 Go 程序里，每个线程M会绑定给一个处理器P，在单一粒度的时间里只能做多处理运行一个goroutine，每个P都会绑定一个叫 mcache 的本地缓存。
          当需要进行内存分配时，当前运行的goroutine会从mcache中查找可用的mspan。从本地mcache里分配内存时不需要加锁，这种分配策略效率更高。
        4、mspan 供应链
           1、 mcache 的 mspan 数量并不总是充足的，当供不应求的时候，mcache 会从 mcentral 再次申请更多的 mspan，同样的，如果 mcentral 的 mspan 数量也不够的话，mcentral 也会向它的上级 mheap 申请 mspan。再极端一点，如果 mheap 里的 mspan 也无法满足程序的内存申请，mheap 只能跟操作系统申请了。
           2、以上的供应流程，只适用于内存块小于 64KB 的场景，原因在于Go 没法使用工作线程的本地缓存mcache和全局中心缓存 mcentral 上管理超过 64KB 的内存分配，所以对于那些超过 64KB 的内存申请，会直接从堆上(mheap)上分配对应的数量的内存页（每页大小是 8KB）给程序