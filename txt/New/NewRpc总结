
1、RPC框架流程原理
    1、服务消费方(client)以本地调用方式调用服务
    2、client stub 接收到调用后负责将方法、参数等封装成能够进行网络传输的消息体
    3、client stub 将消息进行编码并发送到服务端
    4、server stub 收到消息后进行解码
    5、server stub 根据解码结果调用本地的服务
    6、本地服务执行并将结果返回给 server stub
    7、server stub 将返回导入结果进行编码并发送至消费方
    8、client stub 接收到消息并进行解码
    9、服务消费方(client)得到结果

    参考：链接：https://juejin.cn/post/6992867064952127524

2、GRPC的流程原理 同1 类似
    1、grpc 的Stub层，通过protobuf3协议,定义好服务接口、参数等生成.proto文件，通过工具protoc-gen-go生成客户端和服务端共用的对照表，
        想生成什么语言文件就用相应的插件，这样就实现了跨语言。
    2、gRPC RPCRuntime层基于HTTP/2，将调用网络包发送到服务器
    3、GRPC Server端。启动服务，并调用服务注册相关的方法。
    4、grpc 客户端。建立连接和绑定实现的接口

3、grpc的通信协议： protobuf3
        1、protobuf支持的字段类型
            如int32、int64、uint32、uint64、sint32、sint64、bool和enum，采用可变长编码，即varints。 可变长编码。
            sin32: 可变长编码，存储负数时建议使用
            bool： 布尔类型
            string : 字符串类型
            float: 固定占用4个字节，
            double：固定占用8个字节

        2、Protobuf原理
            protobuf会对proto协议文件进行序列化，最终转换成二进制数据，在这个转换过程中，protobuf做了一些优化，使得转换出来的二进制数据尽可能的小，同时也具有安全，编解码快等特点

            1、消息类型编码
                我们定义了一个Animal的消息类型，那protobuf是怎么把它编码成二进制的呢？
                1、其实它是把message转成一系列的key-value，key就是字段号，value就是字段值，大概这样子存：
                [tag1][value1][tag2][value2][tag3][value3]...
                2、解码时，会从左往右解析每一个key-value，假如遇到某个key-value无法解析了，那么就直接跳过，不会影响到其它key-value的解析。
                另外注意到，实际上存储的是tag-value，而不是key-value，根据key转换成tag，也是有公式的
                tag = (key << 3) | wire_type
                3、value也不是直接转成二进制就完事的，它会针对不同的数据类型做不过压缩编码
                    1、可变长编码类型
                            如int32、int64、uint32、uint64、sint32、sint64、bool和enum，采用可变长编码，即varints。 可变长编码。
                            Varint 中的每个 byte 的最高位 bit 有特殊的含义，如果该位为 1，表示后续的 byte 也是该数字的一部分，如果该位为 0，则结束。其他的 7 个 bit 都用来表示数字。因此小于 128 的数字都可以用一个 byte 表示。大于 128 的数字，比如 300，会用两个字节来表示：1010 1100 0000 0010。


                    2、负数可变长编码类型
                        如果要表示的数是一个负数，采用上面所说的方式编码，就会占用很多字节，因为对于比较常用（数值比较大）的负数来说，转成补码后会有很多个1，也就是说占用的字节会比较多，
                        ，因此Google又新增加了一种数据类型，叫sint，专门用来处理这些负数，其实现原理是采用zigzag编码，zigzag编码的映射函数为：
                        ZigZag(n) = (n << 1) ^ (n << k)，k为31或者63
                            最终的效果就是把所有的整数映射为正整数，比如0->0, -1->1, 1->1, -2->3这样子，然后就可以用上面所说的编码方式进行编码了，解码时通过逆函数解析即可
                    3、固定字节数类型
                        这种就很简单了，直接固定字节数就行，比如fixed32，它固定占用4个字节。而且可以看到，protobuf中float和double也是固定占用4个字节和8个字节，并没有实现压缩。

                    4、string类型
                        按照固定的格式编码，格式为：value = length + content
                        其中length就是content占用的字节数，采用可变长编码，content就是string的具体内容。

        3、Protobuf优缺点

            优点：
            1、小：生成的字节流采用了各种压缩方式，相对xml和json这类文件更小。
            2、快：编解码基本都是位运算，也没有复杂的嵌套关系，速度快。
            3、安全：这里的安全，是指protobuf没有把字段名写入到字节流里，只是写入了字段号信息。另外，相对于xml和json来说，因为被编码成二进制，破解成本增大
            4、语言无关和平台无关：把proto文件转成字节流，可以采用不同的语言，也就是说整个编解码过程完全不依赖某种语言的特性。

            缺点：
            可读性差：因为最终是转成二进制流，不像xml和json能够直接查看明文。


        protobuf3的优点
        1. 效率高
        	1、从序列化后的数据体积角度，与XML、JSON这类文本协议相比，ProtoBuf通过T-(L)-V（TAG-LENGTH-VALUE）方式编码，不需要", {, }, :等分隔符来结构化信息，同时在编码层面使用varint压缩，所以描述同样的信息，ProtoBuf序列化后的体积要小很多，在网络中传输消耗的网络流量更少，进而对于网络资源紧张、性能要求非常高的场景，ProtoBuf协议是不错的选择。

        	2、从序列化/反序列化速度角度，与XML、JSON相比，ProtoBuf序列化/反序列化的速度更快，比XML要快20-100倍。

        2、支持跨平台、多语言、比较安全
        	ProtoBuf是平台无关的，无论是Android与PC，还是C#与Java都可以利用ProtoBuf进行无障碍通讯。
        	proto3支持C++, Java, Python, Go, Ruby, Objective-C, C#。

        	没有idl文件无法解析二进制数据流，ProtoBuf在一定程度上可以保护数据，提升核心数据被破解的门槛，降低核心数据被盗爬的风险

        3、扩展性、兼容性好
        	具有向后兼容的特性，更新数据结构以后，老版本依旧可以兼容，这也是ProtoBuf诞生之初被寄予解决的问题。因为编译器对不识别的新增字段会跳过不处理。



        缺点：
        	XML，JSON是自描述的，而ProtoBuf则不是。
        	ProtoBuf是二进制协议，编码后的数据可读性差，如果没有idl文件，就无法理解二进制数据流，对调试不友好。


        protobuf3 的编码方式
        	1、Varint 编码
        		Varint 编码的优势在于值越小的数字，占用的字节更少。一般 int32 的数字都需要占用 4 个字节。使用 Varint 进行编码则有可能缩减到 1 个字节。反过来，如果是比较大的数字，则可能需要占用 5 个字节
        		理解了 Varint 的目的（节省空间），来看看其原理：
        			1、Varint 中的每个字节的最高位 bit 有特殊的含义，该位为 1 表示后续的字节也是该数字的一部分，如果该位为 0 则是最后一个字节。其他的 7 个bit都用来表示数字，从最低有效字节开始。
        			2、300 的二进制表示为 100101100，通过 Varint 编码后的二进制表示为 10101100 00000010，详细过程如下：
        				1、按照7bits进行划分（最高位留给msb） =》 加上msb  => 反转，varints从最低有效字节开始存起

        	2、ZigZag编码
        		对于负数来说，二进制最高有效位为 1，如果用 varint 来编码，无疑要占用比较多的子节。因此我们可以搭配 zigzag 来编码。
        		ZigZag 编码将有符整型转化成无符的整型，其原理是将最高位的符号位放到最低位（－1 除外），这样大大减少了字节占用。

        protobuf3的版本兼容
        	Protobuf 支持向前向后兼容
        	1、向前兼容
        			向前兼容则指旧版本的解码程序能够正确解析新版本协议的数据。
        	2、向后兼容
        			向后兼容即升级的解码程序能够正确解析旧版本协议的数据。

        	 demo 1、
        		 1、协议，即通信双方约定好的规则。收到数据时，可以根据约定好的规则进行解包。假设我们使用简单粗暴的编解码方法，将结构体定义的成员按类型依此打解包。如下图，我们约定好的协议包括三个字段，类型都为 int32，那解码函数将从接收到的字节流中依次取出 4 个字节并按整型解析。
        		 例如： struct old_message {
        		 		 int 32 a = 1
        		 		 int 32 b = 2
        		 		 int 33 d = 4
        		 	  }

        		 	  a 		b 			d
        		 	  0x12		0x12		0x12

        		 如果发送方升级了协议，如下图：
        		  	 struct old_message {
        		 		 int 32 a = 1
        		 		 int 32 b = 2
        		 		 int 32 c = 3
        		 		 int 32 d = 4
        		 	  }
        		 	  		 	  a 		c			b
        		 	  0x12		0x12		0x1a7			0x12
        		 	  编码时是：key+length+content

        		 	  如果旧的解码程序还是按照依次取出 3 个 int32 去解析的话，毫无疑问是错误的（会把结构体 old_message 的成员 d 的值解析成 0x1a )。如果有办法能跳过新增字段，就可以做到兼容，即旧的解码程序能正确解析出旧协议定义的字段，新增字段一律忽略。

        		 	  Protobuf 采用的方法很简单也很实用，把 tag 和其类型一起打进去字节流，解码程序只要解析出不认识的 tag，就能知道该字段是新协议定义的，再通过其类型可以推断出该字段内容的长度，就能正确的跳过这部分 buffer，继续解析下一个字段。

        		 	  当旧的解码程序解析到 tag 为 3 时，发现在旧协议里找不到该 tag，又从其类型 int 64 知道该 tag 的值占了 8 个字节，于是他跳过这 8 个字节，继续解析剩下的字节流。

        		 	  实现：
        		 	  	Protobuf 的实现中，将每个字段的 key 设为 varint 编码后的 (tag number << 3) | wire_type。即 key 的最低三位表示字段类型，将 key 右移三位后的值表示 tag number。wire_type 如下表格所示：
        		使用建议：
        			1、常用消息字段(尤其是 repeated 字段)的 tag number 尽量分配在 1 ~ 15 之间。tag number 超过 16，key 的编码将占用多一个字节
        			2、尽可能多的（全部）使用 optional 字段
        			3、不能修改字段的 tag number
        			4、不能增删任何 required 字段

        		参考链接：http://masutangu.com/2016/09/02/talk-about-protobuf

        4、proto3和proto2的区别
            1、在第一行非空白非注释行，必须写：syntax = "proto3";
            2、枚举类型的第一个字段必须为 0。
            3、移除了 default 选项
            4、字段规则移除了 “required”，并把 “optional” 改名为 “singular”；


4、HTTP1.0 、HTTP1.1 和 HTTP2.0区别
  1、HTTP不足
  1、TCP连接数过多
  	1、HTTP1.0 只允许一条tcp连接上处理一个request
  	2、HTTP1.1 支持管道，通过管道，允许浏览器多个请求可以同时发送到服务器，但是服务器的响应只能够一个接着一个的返回，
  		在HTTP1.1 浏览器默认开启keep-alive
  2、HTTP头部过多重复
  	1、HTTP1.X  中，头部有host Connection,origin,Content-type  等一堆头部，都在不同的请求中重复出现
  	除了浪费大量流量，还会导致TCP的初始化拥塞窗口（initcwnd）快速满了，当多个请求准备在同一个tcp连接上发送时，
  	会导致大量的延迟。（当 initcwnd >= ssthresh 时，tcp就会进入“拥塞控制算法”，把发送的速度调慢，避免快速导致网络拥塞，慢慢的增加调整到网络的最佳值）
  3、HTTP1.x 使用的文本协议
  	文本协议虽然具有可读性，方便debug，但是在高性能网络上会有影响传输性能

  2、HTTP2
  	1、兼容HTTP1.X的语义
  	2、允许多个request/response 在同一个tcp连接上发送，实现真正的IO复用
  	3、高效的压缩头部（http header）
  		采用HPACK 处理重复冗余的头部，大致是（客户端发送请求前，在内部创建一个hash表，索引对应着头部和值，并将此对
  		应表发送到服务器，服务器首次接收到以后，也维护一个一摸一样的表，之后有重复头部时，客户端直接发送索引值即可。

  	4、支持server push
  		HTTP2.0 打破了HTTP1 中一问一答的方式，允许服务器往客户端推送数据。（
  		服务器主要通过 PUSH_PROMIS 帧），把预估客户端的可能需要的资源，在其没有请求的前直接发送给对方，让对方缓存。

  	5、有自己的流量控制，保证各个stream 不被互相打扰
  		HTTP2 通过WINDOW_UPDATE帧告诉对方自己准备接收多少字节的数据，注意只有DATA帧才会受到限制，因为其他帧都不大。

  	6、支持请求优先级发送，优先级越高如核心scc,html 优先发送给客户端。
  		客户端在开启一个流的时候，通过设置HEADER帧中的PRIORITY这个flag 来指定流的优先级，这样子就可以
  		做到优先级越高例如：核心css，html 优先发送给客户端。


  3、HTTP2 中的帧和流概念
  	1、帧（frame）
  		HTTP2 中二进制协议的基本单元叫frame(帧)，不同frame有不同的作用，如：
  		1、•SETTING 帧：建立连接时，向对方传达一些配置信息如是否开启 server push 功能、最大帧 size等等（牢记，下文不累述此）；
          2、•HEADERS 帧：发送 http 的 request 或者response的头部；
          3、•CONTINUATION 帧：headers 要跨越多个帧，用此来指示头部上一个 HEADERS；本质就是 HEADERS 帧，但是为了轻松处理，就用明确的类型来区分这种情况；
          4、•DATA 帧：发送body数据用；
          5、•PUSH_PROMISE 帧：用来告知对端初始化哪些数据，就是以上说到的 server push 功能
          6、•WINDOW_UPDATE 帧：用来做流量控制

      2、流(stream)
      	简单说，客户端与服务器端之间相互发送的帧，都通过一个个独立流来传输的，多个流可以在同一个http2连接中并发
      	而每个流都有一个ID（stream Identifier），frame就是通过此来识别流。
      	流你可以理解为一个抽象概念，就是为了区分不同的请求，用于多路复用。



5、之前我自己简单实现过一个rpc的框架：（主要参考网上的博客）
    1、定义服务端和客户端消息的编码，序列化协议。
        1、采用encoding/gob 和 application/json （Gob 是Go语言自己以二进制形式序列化和反序列化程序数据的格式，可以在 encoding 包中找到。这种格式的数据简称为 Gob（即 Go binary 的缩写）
    2、定义服务端和客户端 网络传输的协议及框架。
        1、http协议，及httpClient （以后可以考虑采用netty网络通信框架）
    3、客户端。
        1、获取可用的服务链接。
        2、实现发送请求，接受并处理响应结果。
        3、负载均衡策略用的是 轮询&随机，也可以使用（一致性hash）
     4、服务端
        1、启动服务，通过反射将结构体映射为服务。
     5、实现一个简单的支持心跳保活的注册中心
        1、定时器每隔1s检测服务，从而实现心跳检测。
        2、把服务地址注册到一个map列表中维护。
     6、实现简单的超时的处理机制
        1、客户端超时。使用 context 包中 context.WithTimeout实现，控制权交给用户，控制更为灵活
        2、服务端超时。time.After() 结合 select+chan 完成。（服务端开启子协程处理请求，处理完成后，通过channel通知，并通过time.After监控处理是否超时）

6、HTTP 和 RPC 的区别
    1、两则都是应用调用另一个应用的解决方案
        1、暴露接口  使用http调用。
        2、远程过程调用rpc

    2、传输协议
        RPC，可以基于TCP协议，也可以基于HTTP协议
        HTTP，基于HTTP协议（在TCP协议之上进行封装）

    3、传输效率
        RPC，使用自定义的TCP协议，可以让请求报文体积更小，或者使用HTTP2协议，也可以很好的减少报文的体积，提高传输效率
        HTTP，如果是基于HTTP1.1的协议，请求中会包含很多无用的内容，如果是基于HTTP2.0，
        那么简单的封装以下是可以作为一个RPC来使用的，这时标准RPC框架更多的是服务治理

    4、性能消耗，主要在于序列化和反序列化的耗时
        RPC，可以基于高效的二进制传输
        HTTP，大部分是通过json来实现的，字节大小和序列化耗时


grpc如何处理超时

gRPC 基于 HTTP2，HTTP2 传输的最小单位是 Frame（帧）。HTTP2 的帧包含很多类型：DATA Frame、HEADERS Frame、PRIORITY Frame、RST_STREAM Frame、CONTINUATON Frame 等。一个 HTTP2 请求/响应可以被拆成多个帧并行发送，每一帧都有一个 StreamID 来标记属于哪个 Stream。服务端收到 Frame 后，根据 StreamID 组装出原始请求数据。

gRPC 系列——grpc超时传递原理

	1、客户端设置 timeout
		用户定义好 protobuf 并通过 protoc 生成桩代码后，桩代码中已经包含了 gRPCCient 接口的实现，每一个在 protobuf 中定义的 RPC，底层都会通过 ClientConn. Invoke 向服务端发起调用：


		分析源码可以看到客户端发起请求时，如果设置了带 timeout 的ctx，则会导致底层 HTTP2 HEADERS Frame 中追加 `grpc-timeout` 字段。 grpc-timeout 字段值被转化成 XhYmZs 字符串形式的超时时间
	2、服务端解析 timeout
		服务端通过 Serve 方法启动 grpc Server，监听来自客户端连接。
		1、decodeHeader 会遍历 frame 中所有 Fields，并调用 processHeaderField 对 HTTP2 HEADERS 帧中的特定的 Field 进行处理。
		2、比如可以从 :path 中解析出包含 protobuf package、service name 和 RPC method name 的完整路径；
		3、比如可以从 grpc-timeout 中解析出上游传递过来的 timeout；
		4、如果此时服务端又发起对其他 gRPC 服务的调用，且使用的是透传的 ctx，这个 timeout 会减去在本进程中耗时，从而导致这个 timeout 传递到下一个 gRPC 服务端时变短，这样即实现了所谓的 超时传递 。


	参考链接： https://xiaomi-info.github.io/2019/12/30/grpc-deadline/