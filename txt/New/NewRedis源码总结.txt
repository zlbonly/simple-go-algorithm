
   Redis 实现和分析

1、
    5、redis对象 （redisObject）
     1、redis 使用对象来表示数据库中的键和值，每次新建一个键值对时，会创建两个对象，一个对象用作键值对的 键（键对象），另一个对象
         用作键值对的值（值对象）
     2、redis没有使用 简单动态字符串（SDS）,链表，字典，压缩链表，集合 等这些数据结构来实现键值对 数据库，而是基于这些数据结构创建了一个
        对象系统，这个系统包含字符串对象，列表对象，哈希对象，集合对象和有序集合对象。没种对象都实现了至少一种前面提到的数据结构。
        redisObject对象 数据结构：

        typedef struct redisObject{
            unsigned type:4; // 类型
            unsigned encoding:4; // 编码
            void *ptr; // 指向底层实现数据结构的指针
           unsigned lru:22 // lru属性 该属性记录了对象最后一次被命令程序访问的时间。
           refcount
        }

    在redisObject中
    1、type表示属于哪种数据类型，
    2、encoding表示该数据的存储方式」，也就是底层的实现的该数据类型的数据结构。
    3、ptr指针，指向对象的底层实现数据结构

     redisObject图：
    https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/redisObject.jpeg

    参考链接：https://cloud.tencent.com/developer/news/645221
2、Redis支持哪几种数据类型？
        1、string：最基本的数据类型，二进制安全的字符串，最大512M。
                常用命令：set、get、decr、incr、mget 等。

            String类型的数据结构存储方式 encoding 有三种int、raw、embstr。那么这三种存储方式有什么区别呢？

            所以Redis的string类型一共有三种存储方式，当字符串长度小于等于44，底层采用embstr；当字符串长度大于44，底层采用raw；
            当设置是整数，底层则采用int。
            如果字符串小于等于44，实际的数据和RedisObject在内存中地址相邻，如果字符串大于44，实际的数据和RedisObject在内存中地址不相邻。

            1、Int
                Redis中规定假如存储的是「整数型值」，比如set num 123这样的类型，就会使用 int的存储方式进行存储，在redisObject的「ptr属性」中就会保存该值。
                如图：
                    https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/redis-string-int.jpeg

            2、SDS
                假如存储的「字符串是一个字符串值并且长度大于32个字节」就会使用SDS（simple dynamic string）方式进行存储，并且encoding设置为raw；若是「字符串长度小于等于32个字节」就会将encoding改为embstr来保存字符串。

                如图：
                    https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/redis-stirng-sds.jpeg
                    底部实现介绍 SDS.参考 2.1

        2、hash：key-value对的一种集合。
               Hash 是一个键值（key-value）的集合。Redis 的 hash 是一个 string 的 key 和 value 的映射表，Hash 特别适合存储对象。
                 1、常用命令 ：hget、hset、hgetall 等。
                 2、应用场景 ：hash 特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。比如我们可以 hash 数据结构来存储用户信息，商品信息等等。比如下面我就用 hash 类型存放了我本人的一些信息：
                 3、底层实现：
                 Hash对象的实现方式有两种分别是ziplist、hashtable，其中hashtable的存储方式key是String类型的，value也是以key value的形式进行存储。
                 字典类型的底层就是hashtable实现的，明白了字典的底层实现原理也就是明白了hashtable的实现原理，hashtable的实现原理可以于HashMap的是底层原理相类比。
                    1、hashTable实现  参考 2.2（字典总结）
                    2、ziplist实现 参考 2.3(压缩链表总结)

             初始的哈希对象都是采用压缩链表作为底层实现的，只有当哈希对象中key-value对的数量超过OBJ_HASH_MAX_ZIPLIST_ENTRIES时， Redis才会将压缩链表实现的哈希对象转化为由src/dict.h中所描述的dict类型作为底层实现。
                hash-max-ziplist-entries 512，表示当hash项（field，value）数＞512即ziplist项＞1024的时候转为dict
                hash-max-ziplist-value 64，表示当hash中的value长度超过64的时候转为dict。

        3、list：按照添加顺序保持顺序的字符串列表。
                常用命令：lpush、rpush、lpop、rpop、lrange（获取列表片段）等。
              底层实现是双向链表 2.4

        4、set：无序的字符串集合，不存在重复的元素。
            Set 是 string 类型的无序集合。集合是通过 hashtable 实现的。set 中的元素是没有顺序的，而且是没有重复的。
            常用命令： sdd、spop、smembers、sunion 等。

                Redis中列表和集合都可以用来存储字符串，但是「Set是不可重复的集合，而List列表可以存储相同的字符串」，Set集合是无序的这个和后面讲的ZSet有序集合相对。
                Set的底层实现是「ht和intset」，
                1、ht（哈希表）前面已经详细了解过，下面我们来看看inset类型的存储结构
                2、inset也叫做整数集合，用于保存整数值的数据结构类型，它可以保存int16_t、int32_t 或者int64_t 的整数值。
                在整数集合中，有三个属性值encoding、length、contents[]，分别表示编码方式、整数集合的长度、以及元素内容，length就是记录contents里面的大小。

               在整数集合新增元素的时候，若是超出了原集合的长度大小，就会对集合进行升级，具体的升级过程如下
                            1、首先扩展底层数组的大小，并且数组的类型为新元素的类型。
                            2、然后将原来的数组中的元素转为新元素的类型，并放到扩展后数组对应的位置。
                            3、整数集合升级后就不会再降级，编码会一直保持升级后的状态。

        5、sorted set (ZSET)：已排序的字符串集合。
                常用命令： zadd、zrange、zrem、zcard 等。

        sort set 底部实现是ziplist 和 skiplist
        ziplist：满足以下两个条件的时候元素数量少于128的时候每个元素的长度小于64字节
        skiplist：不满足上述两个条件就会使用跳表，具体来说是组合了map和skiplistmap用来存储member到score的映射，这样就可以在O(1)时间内找到member对应的分数skiplist按从小到大的顺序存储分数skiplist每个元素的值都是[score,value]对

        1、ziplist(参考2.3)
          ziplist：同时满足以下两个条件的时候，zset使用ziplist实现
               1、元素数量少于128的时候
               2、每个元素的长度小于64字节

          ziplist编码的有序集合使用紧挨在一起的压缩列表节点来保存，第一个节点保存member，第二个保存score。ziplist内的集合元素按score从小到大排序，score较小的排在表头位置。

        2、skiplist（参考2.6）
        skiplist：不满足上述两个条件就会使用跳表，具体来说是组合了hashmap和skiplist
      skiplist编码的有序集合底层是一个命名为zset的结构体，而一个zset结构同时包含一个字典和一个跳跃表。
      跳跃表按score从小到大保存所有集合元素。而字典则保存着从member到score的映射，这样就可以用O(1)的复杂度来查找member对应的score值。
      虽然同时使用两种结构，但它们会通过指针来共享相同元素的member和score，因此不会浪费额外的内存。

        底层实现 参考 2.4 hashTable 和  2.6 skipList




2、底层数据结构
1、简单动态字符串 （SDS）
Redis没有直接使用 C 语言的字符串，而是自己创建了名为 SDS (simple dynamic string, SDS) 的字符串。

  1） redis 3.2之前版本实现
    在redis3.2.x之前，SDS的存储结构如下：
    struct sdshdr {
        int len; //存长度
        int free; //存字符串内容的柔性数组的剩余空间
        char buf[]; //柔性数组，真正存放字符串值
    };

    Redis 3.2 之前的SDS主要是通过int len; int free; char buf[];这三个字段来确定一个字符串的。其中len表示buf中已占用字节数，free表示buf中剩余可用字节数，buf是数据空间。

    优点：
        1、有单独的统计变量len和free（称为头部），可以很方便的得到字符串的长度。
        2、内容存放在柔性数组buf中，SDS对上层暴露的指针不是指向结构体SDS的指针，而是直接指向柔性数组buf的指针。上层可以像读取C字符串一样读取SDS的内容，兼容C语言处理字符串的各种函数。
        3、由于有长度的统计变量len的存在，读写字符串时不依赖“0”终止符，保证了二进制安全。

    为什么要用柔性数组？
    柔性数组的地址和结构体是连续的，这样查找内存更快（因为不需要额外通过指针找到字符串的位置）；
    可以更快的通过柔性数组的首地址偏移得到结构体首地址，进而能很方便的获取其余变量。

    3.2版本之前的缺点：不同长度的字符串需要占用相同大小的头部，显然是浪费了空间。

    2） redis 3.2及 3.2之后版本实现 （改进以5.0+ 为例子）
        struct  __attribute__ ((__packed__) ) sdshdr16 {
            uint16_t len; //字符串长度
            uint16_t alloc; // //已分配的总空间
            unsigned char flags; // 标识是哪种存储类型
            char buf[]; //存储字符串内容的柔性数组
        };


        redis 3.2及之后的版本 根据字符串的长度，分成了5种类型sdshdr5、sdshdr8、sdshdr16、sdshdr32、sdshdr64。
        并且 sdshdr5居然没有头部（len和alloc），而其他四种数据结构，多了一个flags字段。

         sdshdr5、sdshdr8、sdshdr16、sdshdr32、sdshdr64 四种结构的成员变量类似，唯一的区别是len和alloc的类型不同。结构体中4个字段的具体含义如下：
         1、len表示buf中已占用字节数。
         2、alloc表示buf中已分配字节数，记录的是为buf分配的总长度，不同于free。
         3、flags标识当前结构体的类型，低3位用作标识位，高5位预留。
         4、buf柔性数组，真正存储字符串的数据空间。
            创建SDS的大致流程是，首先计算好不同类型的头部和初始长度，然后动态分配内存。需要注意的是：
        1、创建空字符串是SDS_TYPE_5会被强制转换为SDS_TYPE_8。
        2、长度计算时有“+1”操作，是为了算上结束符“0”。
        3、返回值是指向sds结构buf字段的指针

 补充知识：
     C 语言中，用 “\0” 表示字符串的结束，如果字符串本身就有 “\0” 字符，字符串就会报截断，既非二进制安全，若通过某种机制，保证写字符串时不会受损坏的内容，则是二进制安全。

1.2、动态字符串（SDS）的好处
    1、常数复杂度获取字符串长度
        SDS使用结构体实现，结构体中的len属性直接记录了该SDS结构体中buf数组中已使用的长度，因此获取字符串长度时，只需要获取len属性的值，这个操作的复杂度为O(1)。
    2、杜绝缓冲区溢出
        因为C字符串不记录自身的长度，所以当进行字符串复制的时候，如果分配内存不够，便有可能产生缓冲区溢出。
        而在Redis中，当SDS API需要对SDS进行修改时，API会先检查SDS的空间是否满足修改所需的要求，如果不满足的话，API会自动将SDS的空间扩展至执行修改所需的大小，然后才执行实际的修改操作，所以使用SDS既不需要手动修改SDS的空间大小，也不会出现前面所说的缓冲区溢出问题。
    3、减少修改字符串时带来的内存重分配次数
        常规C字符串，再执行拼接操作或者截断操作时，通常会对数组进行内存重分配，而内存重分配操作涉及复杂的算法，并且可能执行系统调用，所以它通常是一个比较耗时的操作。
        Redis作为数据库，会对数据进行频繁的修改，并且对速度要求极为严苛，所以每次修改字符串长度都需要进行内存重分配会对性能造成极大的影响
        因此，SDS实现了空间预分配和惰性空间释放两种优化策略。

        1） 空间预分配
            在需要对 SDS 进行空间扩展的时候， 程序不仅会为 SDS 分配修改所必须要的空间， 还会为 SDS 分配额外的未使用空间。
            举一个例子，我们将字符串“Redis”扩展到“Redis111”，应用程序并不仅仅分配3个字节，仅仅让它恰好满足分配的长度，而是会额外分配一些空间。
            具体如何分配，见下述代码注释。我们讲其中一种分配方式，假设它会分配8字节的内存空间。现在总共的内存空间为5+8 = 13，而我们只用了前8个内存空间，还剩下5个内存空间未使用。
            那么我们为什么要这样做呢？这是因为如果我们再继续对它进行扩展，如改成“Redis11111”，在扩展 SDS 空间之前，SDS API 会先检查未使用空间是否足够，如果足够的话，
            API 就会直接使用未使用空间那么我们就不用再进行系统调用申请一次空间了，直接把追加的“11”放到之前分配过的空间处即可。这样一来，会大大减少使用内存分配系统调用的次数，提高了性能与效率

            sds sdsMakeRoomFor(sds s, size_t addlen) {

                void *sh, *newsh;
                size_t avail = sdsavail(s); // 获取当前字符串可用剩余空间
                size_t len, newlen;
                char type, oldtype = s[-1] & SDS_TYPE_MASK;
                int hdrlen;

                /* 如果可用空间大于追加部分的长度，说明当前字符串还有额外的空间，足够容纳扩容后的字符串，不用分配额外空间，直接返回 */
                if (avail >= addlen) return s;

                len = sdslen(s);
                sh = (char*)s-sdsHdrSize(oldtype);
                newlen = (len+addlen);
                if (newlen < SDS_MAX_PREALLOC) //SDS_MAX_PREALLOC = 1MB，如果扩容后的长度小于1MB，直接额外分配扩容后字符串长度*2的空间
                    newlen *= 2;
                else
                    newlen += SDS_MAX_PREALLOC; //扩容后长度大于等于1MB，额外分配扩容后字符串+1MB的空间

                 ...
                 真正的去分配空间
                 ...
                 sdssetalloc(s, newlen);
                 return s;
            }

        2）惰性空间释放
            惰性空间释放用于优化 SDS 的字符串截取或缩短操作。当 SDS 的 API 需要缩短 SDS 保存的字符串时，程序并不立即回收缩短后多出来的字节，是使用free/alloc来记录这些数量。这样一来，如果将来要对 SDS 进行增长操作的话，这些未使用空间就可能会派上用场。
            比如我们将“Redis111”缩短为“Redis”，然后又改成“Redis111”，这样，如果我们立刻回收缩短后多出来的字节，然后再重新分配内存空间，是非常浪费时间的。
            如果等待一段时间之后再回收，可以很好地避免了缩短字符串时所需的内存重分配操作， 并为将来可能有的增长操作提供了扩展空间


1.3、SDS 常见面试题：
    1、SDS如何兼容C语言字符串？如何保证二进制安全？
        SDS对象中的buf是一个柔性数组，上层调用时，SDS直接返回了buf。由于buf是直接指向内容的指针，所以兼容C语言函数。而当真正读取内容时，SDS会通过len来限制读取长度，而非“0”，所以保证了二进制安全。
    2、sdshdr5的特殊之处是什么？
        sdshdr5只负责存储小于32字节的字符串。一般情况下，小字符串的存储更普遍，所以Redis进一步压缩了sdshdr5的数据结构，将sdshdr5的类型和长度放入了同一个属性中，用flags的低3位存储类型，高5位存储长度。创建空字符串时，sdshdr5会被sdshdr8替代。
        sdshrd5其实对内存空间的更加节约。
    3、SDS 如何动态扩容 （参考空间预分配）

2 、redis 字典
    Redis的字典使用哈希表作为底层实现，一个哈希表里面可以有多个哈希表节点，而每个哈希表节点就保存了字典的一个键值对。
   1、哈希表节点
    typedef struct dictEntry {
        void *key; // 键
        union {   // 值
            void *val;
            uint64_t u64;
            int64_t s64;
        } value;
        struct dictEntry *next;  //指向下个哈希表节点，形成链表

    } dic

    2 、哈希表
       typedef struct dictht {
           dictEntry **table; // 哈希表数组
           unsigned long size; // 哈希表大小
           unsigned long sizemask; //  哈希表大小掩码，用于计算索引值（总是等于 size - 1）
           unsigned long used;  // 该哈希表已有节点的数量
       } dictht;

    3、字典
      typedef struct dict {
          dictType *type; //  类型特定函数
          void *privdata; // 私有数据
          dictht ht[2]; // 哈希表
          // rehash 索引当 rehash 不在进行时，值为 -1
          int rehashidx; /* rehashing not in progress if rehashidx == -1 */
          //  目前正在运行的安全迭代器的数量
          int iterators; /* number of iterators currently running */

      } dict;

      说明：（ht 属性包含两个项的数组，数组中的每一项都是一个dictht哈希表，一般情况下，字典只使用ht[0]哈希表，ht[1]哈希表只会在对ht[0]
      哈希表进行rehash时使用。rehashidx 记录当前的进度，如果目前没有在进行rehash ，那么它的值为-1）
    如图：  https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/redisObject.jpeg


    4、 哈希表解决键冲突：
        当有两个或者以上数量的键被分配到了哈希表数组的同一个索引上面时，我们称为这些键冲突

        解决方案： 哈希表使用链地址法 来解决键冲突，每个哈希表节点都有一个next指针，多个哈希表节点可以用next指针构成一个单向链表，被分配到同一个索引上
        的多个节点可以用这个单向链表连接起来。（redis总是将新节点添加到链表的表头位置（复杂度为O(1))）,排在其他节点的前面。
    5、重新散列 rehash(扩展和压缩)
    在字典的底层实现中，value对象以每一个dictEntry的对象进行存储，当hash表中的存放的键值对不断的增加或者减少时，需要对hash表进行一个扩展或者收缩。

       1、rehash过程
           1、为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。
           2、在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。
           3、在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外，
                还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。
           4、随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ，
                这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。
    6、渐进式rehash 和 rehash执行期间的哈希表操作。

        1、假如在rehash的过程中数据量非常大，Redis不是一次性把全部数据rehash成功，这样会导致Redis对外服务停止，Redis内部为了处理这种情况采用「渐进式的rehash」。
         为了避免rehash对服务器性能造成影响，服务器不是一次性的将ht[0]里面的所有键值对全部rehash到ht[1],而是分多次，渐进式的将ht[0]里面的
         键值对慢慢的rehash到ht[1].

         2、在渐进式rehash的过程中，字典会同时使用ht[0]和ht[1]两个hash表，所以在渐进式rehash期间，字典的删除（delete）,查找(find),更新（update）
         等操作会在两个哈希表上进行。例如，要在字典中查找一个键的话，程序会先在ht[0]里面进行查找，如果没有找到的话，就会继续到ht[1]里面进行查找。
          另外。在渐进式rehash执行期间，新添加到字典的键值对，一律会被保存到ht[1]里面，而ht[0]则不再进行任何添加操作，这一措施保证了ht[0]包含的键值对
          数量会只减不增，并随着rehash操作的执行而最终变成空表。
3、redis 压缩列表(ziplist)
     1、压缩链表产生的原因
        Redis中所实现的经典双端链表了，而这种链表存在一个问题，便是在存储小数据的时候， 内存使用效率过低，
    例如当一个链表节点中只保存一个字节的unsigned char数据时，我们需要为这个节点保存24个字节的额外数据，
    其中包含listNode.prev指针，listNode.next指针，以及指向具体数据的listNode.value指针， 同时对于链表节点所占用内存的反复申请与释放，也容易导致内存碎片的产生。
     为了解决经典双端链表在保存小数据而导致内存效率过低的问题，Redis设了一套压缩链表的数据数据结构ziplist来对这种场景下的链表应用进行优化。

     2、压缩链表
    压缩列表是Redis 为了节约内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型数据结构。
        Redis的有序集合、哈希以及列表都直接或者间接使用了压缩列表。当有序集合或哈希的元素数目比较少，
        且元素都是短字符串时，Redis便使用压缩列表作为其底层数据存储方式。列表使用快速链表（quicklist）数据结构存储，
        而快速链表就是双向链表与压缩列表的组合

        1、压缩链表的内存分布
         压缩链表与经典双端链表最大的区别在于，双端链表的节点是分散在内存中并不是连续的，压缩链表中所有的数据都是存储在一段连续的内存之中的，

        字节数组（Redis使用字节数组表示一个压缩列表，字节数组逻辑划分为多个字段）
            zlbytes | zltail | zllen | entry1 | entry2 | ......zlend

            1、zlbytes：表示整个压缩链表所占用内存的长度（以字节为单位），占4个字节，因此压缩列表最长(2^32)-1字节；
            2、zltail：该字段固定是一个四字节的无符号整数，用于表示在链表中最后一个节点的偏移字节量，借助这个字段，我们不需要遍历整个链表便可以在链表尾部执行Pop操作。；
            3、zllen：压缩列表的元素数目，占两个字节；那么当压缩列表的元素数目超过(2^16)-1怎么处理呢？此时通过zllen字段无法获得压缩列表的元素数目，必须遍历整个压缩列表才能获取到元素数目；
            4、entryX：压缩列表存储的若干个元素，可以为字节数组或者整数；entry的编码结构后面详述；
            5、zlend：压缩列表的结尾，占一个字节，恒为0xFF。

        2、压缩列表节点
           每个压缩列表节点都是由 previous_entry_length ,encoding,content三个部分组成。
            i) previous_entry_length 属性以字节为单位，记录了压缩列表中前一个节点的长度。
                主要用于压缩列表遍历（使用指向当前节点起始节点指针C，减去当前节点previous_entry_length属性的值，就可以得出一个指向前一个
                节点起始地址的指针p）。
            ii） encoding： 这个字段用于表示该节点使用的编码方式，具体是按照整形数进行编码还是按照字符串进行编码， 当节点使用的是字符串编码时，该字段还会指明字符串数据的字节长度。
            iii) content : 节点保存的值 （可以是字节数组/整数），具体类型和长度 由节点encoding属性决定。


       3、连锁更新 （新增和删除压缩列表节点，可能导致压缩列表执行空间重分配操作，但是概率极低，redis本身忽略，）
        参考：
        https://segmentfault.com/a/1190000017328042


4、链表

   1、Redis中的列表在3.2之前的版本是使用ziplist和linkedlist进行实现的。在3.2之后的版本就是引入了quicklist。
    ziplist压缩列表上面已经讲过了，我们来看看linkedlist和quicklist的结构是怎么样的。
    linkedlist是一个双向链表，他和普通的链表一样都是由指向前后节点的指针。插入、修改、更新的时间复杂度O(1)，但是查询的时间复杂度确实O(n)。

    2、 linkedlist和quicklist的底层实现是采用链表进行实现
    如图：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/redis-linkedlist.jpeg

        ／/链表节点
        typedef struct listNode {
            struct listNode *prev;  // 前置节点
            struct listNode *next;  // 后置节点
            void *value; // 节点的值，任意的类型
        } listNode;

        //链表
        typedef struct list {
            listNode *head; // 表头节点
            listNode *tail; // 表尾节点
            void *(*dup)(void *ptr);  // 节点值复制函数
            void (*free)(void *ptr);   // 节点值释放函数
            int (*match)(void *ptr, void *key);  // 节点值对比函数
            // 链表所包含的节点数量
            unsigned long len;
        } list;

    在Redis中，还特殊的定义了一个迭代器，专门用来迭代，记录迭代的方向与当前迭代的节点：

    typedef struct listIter {
        listNode *next;    // 当前迭代到的节点
        int direction;    // 迭代的方向
    } listIter;

    Redis中链表的主要特性主要如下：
    1、多态：这是Redis链表中最重要的特点，在链表定义里使用函数指针来定义复制、释放与比较函数，将具体实现交予其它模块，类似于在这定义了三个接口，而且大量使用void指针，使其可以指向任何的数据类型，这也是Redis整体的特征。
    2、尽可能少的时间花销：从上述代码不难看出，Redis为了减少在时间上的开销，自带了链表长度的计数器len，以及表头与表位指针，从而使得获取长度、头结点与尾节点的时间复杂度为O(1)，而且在插入一个新的节点时，Redis会使用前插法使得插入节点的时间复杂度也为O(1)。

5、快速链表（quickList）
    快速链表（quicklist）数据结构存储，而快速链表就是双向链表与压缩列表的组合
    1、为什么有快速链表
        压缩链表由于使用的是有一段连续的内存，这就意味着，执行插入操作导致内存大小发生变化时，便会引起一次内存的重新分配过程，
        同时还会执行一定量的数据移动。特别是对于压缩链表较长的情况下，大批量的数据移动势必会降低系统的性能。
        而在上述这个方面恰恰就是经典双端链表的优势，故此Redis设计实现了一种快速链表的数据结构，兼具经典双端链表与压缩链表的特点，实现了时间与空间上的一种折衷。
    2、redis 在3.2后提出了快速链表的实现
        在Redis中，作者结合了经典双端链表以及压缩链表的特性，实现了快速链表的数据结构。简单来说，使用双端链表的形式描述整个快速链表，
        而每一个快速链表的节点都是使用一个压缩链表作为底层数据存储，可以存储若干个数据节点。同时基于链表数据结构通常对头部与尾部的访问最为频繁，
        而对链表中间的数据访问并不是特别频繁，因此出于节省空间的目的，会对中间节点底层压缩链表所使用的内存进行压缩
        typedef struct quicklistNode {
            struct quicklistNode *prev;
            struct quicklistNode *next;
            unsigned char *zl;
            unsigned int sz;
            unsigned int count : 16;
            unsigned int encoding : 2;
            unsigned int container : 2;
            unsigned int recompress : 1;
            unsigned int attempted_commpress : 1;
            unsigned int extra : 10;
        } quicklistNode;

        快速链表数据结构quicklist便是以双端链表的形式，组织维护所有的quicklistNode节点的，下面便是quicklist的数据结构：
        typedef struct quicklist
        {
            quicklistNode *head;
            quicklistNode *tail;
            unsigned long count;
            unsigned long len;
            int fill : 16;
            unsigned int compress : 16;
        } quicklist;
        同样的，为了实现对这个快速链表中数据节点的遍历，Redis设计了快速链表迭代器的数据结构：
        typedef struct quicklistIter
        {
            const quicklist *quicklist;
            quicklistNode *current;
            unsigned char *zi;
            long offset;
            int direction;
        } quicklistIter;
        在这个数据结构中：

        quicklistEntry.quicklist指向这个数据节点所在的快速链表；quicklistEntry.node指向这个数据节点所在的链表节点；quicklistEntry.zi指向数据节点在链表节点之中的位置。
        如果数据节点中存储的是字符串编码的数据，那么quicklistEntry.value和quicklistEntry.sz这两个字段用来标记这个字符串编码数据。
        如果数据节点中存储的是整数编码的数据，那么会从对应的压缩链表中解码出这个整数数据，将之存储在quicklistEntry.longval字段中。
        quiclistEntry.offset的含义与quicklistIter.offset一致，都是表示当前数据节点在链表节点的压缩链表中的偏移。

6、redis 跳跃表（skiplist）
    跳跃表（skiplist）是一种有序的数据结构，他通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。跳跃表支持平均O(logN) ,最坏O（N）复杂度的节点查找
    ，还可以通过顺序性操作来批量处理节点。

    1、先介绍 跳表
        1、在介绍跳表前，我们先来回顾一下基本链表，并思考为何一步一步演化成跳表的数据结构。
        如图0：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/skiplist-01.png
        在这样一个链表中，如果我们要查找某个数据，那么需要从头开始逐个进行比较，直到找到包含数据的那个节点，
        或者找到第一个比给定数据大的节点为止（没找到）。也就是说，时间复杂度为O(n)。
        同样，当我们要插入新数据的时候，也要经历同样的查找过程，从而确定插入位置。

        2、假如我们每隔一个节点增加一个指针，让指针指向下下个节点，
        如下图02：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/skiplist-02.png

        现在当我们想查找数据的时候，可以先沿着这个新链表进行查找。当碰到比待查数据大的节点时，
        再回到原来的链表中进行查找。比如，我们想查找23，查找的路径是沿着下图中标红的指针所指向的方向进行的：
        如下图03：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/skiplist-03.png
            1、23首先和7比较，再和19比较，比它们都大，继续向后比较。
            2、但23和26比较的时候，比26要小，因此回到下面的链表（原链表），与22比较。
            3、23比22要大，沿下面的指针继续向后和26比较。23比26小，说明待查数据23在原链表中不存在，而且它的插入位置应该在22和26之间
        在这个查找过程中，由于新增加的指针，时间复杂度不再是O(N)了，也即我们不再需要与链表中每个节点逐个进行比较了。需要比较的节点数大概只有原来的一半。

        3、利用同样的方式，我们可以在上层新产生的链表上，继续扩展指针，从而产生第三层链表。如下图：
            如下图04：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/skiplist-04.png
            在这个新的三层链表结构上，如果我们还是查找23，那么沿着最上层链表首先要比较的是19，发现23比19大，
            接下来我们就知道只需要到19的后面去继续查找，从而一下子跳过了19前面的所有节点。可以想象，当链表足够长的时候，
            这种多层链表的查找方式能让我们跳过很多下层节点，大大加快查找的速度

        4、skiplist正是受这种多层链表的想法的启发而设计出来的。实际上，按照上面生成链表的方式，上面每一层链表的节点个数，
            是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到O(log n)。
            但是，这种方法在插入数据的时候有很大的问题。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的2:1的对应关系。
            如果要维持这种对应关系，就必须把新插入的节点后面的所有节点（也包括新插入的节点）
            重新进行调整，这会让时间复杂度重新蜕化成O(n)。删除数据也有同样的问题。
        5、skiplist为了避免这一问题，它不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是为每个节点随机出一个层数(level)。附源码：

                #define ZSKIPLIST_MAXLEVEL 32
                #define ZSKIPLIST_P 0.25

                int zslRandomLevel(void) {
                    int level = 1;
                    while ((random()&0xFFFF) < (ZSKIPLIST_P * 0xFFFF))
                        level += 1;
                    return (level<ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;
                }

        执行插入操作时计算随机数的过程，是一个很关键的过程，它对skiplist的统计特性有着很重要的影响。这并不是一个普通的服从均匀分布的随机数，而是服从一定规则的：

        1、首先，每个节点肯定都有第1层指针（每个节点都在第1层链表里）。
        2、如果一个节点有第i层(i>=1)指针（即节点已经在第1层到第i层链表中），那么它有第(i+1)层指针的概率为p。（p: Redis 的 zset 中 SKIPLIST_P 设定的 0.25。晋升概率）
        3、节点最大的层数不允许超过一个最大值，记为MaxLevel（Redis里是32）

       6、比如，一个节点随机出的层数是3，那么就把它链入到第1层到第3层这三层链表中。为了表达清楚，下图展示了如何通过一步步的插入操作从而形成一个skiplist的过程：
        如图05：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/skiplist-05.png

        从上面skiplist的创建和插入过程可以看出，每一个节点的层数（level）是随机出来的，而且新插入一个节点不会影响其它节点的层数。
            因此，插入操作只需要修改插入节点前后的指针，而不需要对很多节点都进行调整。这就降低了插入操作的复杂度。实际上，
            这是skiplist的一个很重要的特性，这让它在插入性能上明显优于平衡树的方案。这在后面我们还会提到。

       7、skiplist，指的就是除了最下面第1层链表之外，它会产生若干层稀疏的链表，这些链表里面的指针故意跳过了一些节点（而且越高层的链表跳过的节点越多）
        。这就使得我们在查找数据的时候能够先在高层的链表中进行查找，然后逐层降低，
        最终降到第1层链表来精确地确定数据位置。在这个过程中，我们跳过了一些节点，从而也就加快了查找速度。
        刚刚创建的这个skiplist总共包含4层链表，现在假设我们在它里面依然查找23，下图给出了查找路径：
       如图06：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/skiplist-06.png

    2、在介绍redis中是如何实现跳表。
            Redis使用跳跃表作为Zset的实现.

            1、 zskiplistNode 节点

            /* ZSETs use a specialized version of Skiplists */

            typedef struct zskiplistNode {
                sds ele;
                double score;
                struct zskiplistNode *backward;
                struct zskiplistLevel {
                    struct zskiplistNode *forward;
                    unsigned long span;
                } level[];
            } zskiplistNode;

            字段说明：
            i） * backward （后退指针：用于从表尾部向表头部访问节点，每个节点只有一个后退节点，每次只能后退至前一个节点。）
            2）score 和 ele( *obj) : 分值和成员， score是一个double浮点数，跳跃表中的所有节点都按分值大小进行排序。
               *obj成员对象是一个指针，指向一个字符串对象，而字符串对象保存着一个SDS值。
               分数值相同的节点，按照成员对象在字典序中的大小来进行排序。
            3） 层level
                   跳跃表的节点level数组可以包含多个元素，每个元素都包含一个指向其他节点的指针和 跨度。
                   每次创建新的跳跃表节点的时候，redis都会根据幂次定律随机生成一个介于1～32的值作为level数组的大小，这个值就是level

                zskiplistNode *forward： 每个层都有一个指向表尾方向的前进指针，用于从表头向表尾方向访问节点。
                unsigned long span： 层的跨度用于记录两个节点之间的距离。


            2、zskiplist 用于保存跳跃表节点 （ 跳表结构管理节点）
            typedef struct zskiplist {
                struct zskiplistNode *header, *tail;
                unsigned long length; //     // 长度
                int level; //     // 跳表高度(所有节点最高层高)
            } zskiplist;

            3、zset结构

            typedef struct zset {
                dict *dict;
                zskiplist *zsl;
            } zset;

         1、 插入过程
            zadd [zset name] [score] [value]：
           1、 在map中查找value是否已存在，如果存在现需要在skiplist中找到对应的元素删除，再在skiplist做插入
           2、插入过程也是用score来作为查询位置的依据，和skiplist插入元素方法一样。并需要更新value->score的map

            如果score一样怎么办？根据value再排序，按照顺序插入
         2、删除过程
            zrem [zset name] [value]：从map中找到value所对应的score，然后再在跳表中搜索这个score,value对应的节点，并删除

         3、排名是怎么算出来的
            zrank [zset name] [value]的实现依赖与一些附加在跳表上的属性：
            1、跳表的每个元素的Next指针都记录了这个指针能够跨越多少元素，redis在插入和删除元素的时候，都会更新这个值
            2、然后在搜索的过程中按经过的路径将路径中的span值相加得到rank

       跳表就是空间换取时间。

   3、为什么采用跳表，而不使用哈希表或平衡树实现呢
        1、skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。
            因此，在哈希表上只能做单个key的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。

        2、在做范围查找的时候，平衡树比skiplist操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。
            如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。

        3、平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速

        4、从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，
            具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。

    参考链接：https://segmentfault.com/a/1190000037473381

    2、redis   ZSET 实现 skipList
    	1、skipList 特点
    		1、一个跳跃表通常有多层组成，redis默认是32层
    		2、跳表的第0层包含所有的元素，且节点值是有序的
    		3、每一层都是一个有序的链表，层数越高越稀疏，这6样在高层此中能跳过 “许多不符合条件的数据”
    		4、如果元素X出现在第 i 层，则所有比i小的层 都包含该元素 x
    		5、每个节点包含key，及其对应的value 和一个指向该节点第n层的下个节点的指针数据，x -> next[level]表示
    		第level层的x的第下一个节点。



    	2、skiplist的查询，插入，删除过程
    		1、skiplist的查询过程
    			1、查询第一个比x大的节点的前一个值，看是否相等。相等则存在，否则查找下一层，直到层数为0
    			以已有数据：13，22，75，80，99 为例子

    			level2 	  		  13  -> 	75 		-> 	99

    			level1 			  13  -> 22 -> 75 	-> 99

    			level 0 		13 -> 22 -> 75 -> 80 -> 99

    			先从最高层 leve2开始
    			1、level2 找到 第一个比80 的 99 的前一个节点75 。 80 介于 75  ～ 99 之间，则 进入level1 层进行查找（注意：此处已经跳过13-75节点了）
    			2、在第level1 层仍然发现 	level1.Node 75 < 80 < level1.Node74->next 则进入level0
    			3、level0.Node75-> next 等于80，找到节点

    		2、skiplist的插入流程
    			1、从最高成开始找到每一层比84 大的节点的前一个值。出入prev[level]
    				prev[2] = level2.node75
    				prev[1] = level1.node75
    				prev[0] = level0.node75
    			2、初始化一个新节点84
    			3、为X随机选择一个高度h，这里假设选择2
    			4、x->next[0 ~ h-1] = prev[0 ~ h-1]->next
    			5、prev[0 ~ h-1 ]->next[0~h-1] = x


    		3、skiplist 删除操作 同插入操作。包含3步（1、查找到需要删除的结点，2、删除结点，3、调整指针）

    	3、redis  ZSET的实现
    		redis 使用skiplist和 字典 两种数据结构来实现 zset
    			1、字典保存成功的分值，以保证能以O（1）的时间复杂度查找成员的分值，但是字典是无序的，每次进行范围查询都需要进行重新排序
    			2、使用跳跃表来进行范围查询，可以获取有序的集合。使用跳跃表进行 查找时，会把查找操作的时间复杂度O(1)变成O（logN）
    		因此redis使用两种数据结构来共同实现有序集合。

6、Redis的内存回收机制
    Redis的内存回收主要分为过期删除策略和内存淘汰策略两部分。
        expires过期字典的键指向数据库的某隔键，而值则记录了数据库键的过期时间，过期时间是一个以毫秒为单位的unix时间戳
    1、过期删除策略 （删除达到过期时间的key）
        i） 定时删除： 在设置键的过期时间的同时，创建一个定时器（timer），让定时器在键的过期时间来临时，立即执行对键的删除操作
              优点： 对内存友好，可以及时删除，但是对CPU执行时间不友好。
        ii) 惰性删除：放任过期键不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话就删除该键，如果没有过期，就返回该键。
             优点：对cpu执行时间优化，但是对内存不友好，如果一个键过期，如果不是删除，内存会一直被占用

        iii) 定期删除： 每隔一段时间，扫描Redis中过期key字典，并清除部分过期的key。该策略是前两者的一个折中方案，
                还可以通过调整定时扫描的时间间隔和每次扫描的限定耗时，在不同情况下使得CPU和内存资源达到最优的平衡效果。

    2、redis采用惰性删除和定期删除两种策略来删除过期的键。
        redisDb结构体定义
            我们知道，Redis是一个键值对数据库，对于每一个redis数据库，redis使用一个redisDb的结构体来保存，它的结构如下
        typedef struct redisDb {
                dict *dict;                 /* 数据库的键空间，保存数据库中的所有键值对 */
                dict *expires;              /* 保存所有过期的键 */
                dict *blocking_keys;        /* Keys with clients waiting for data (BLPOP)*/
                dict *ready_keys;           /* Blocked keys that received a PUSH */
                dict *watched_keys;         /* WATCHED keys for MULTI/EXEC CAS */
                int id;                     /* 数据库ID字段，代表不同的数据库 */
                long long avg_ttl;          /* Average TTL, just for stats */
        } redisDb;

        从结构定义中我们可以发现，对于每一个Redis数据库，都会使用一个字典的数据结构来保存每一个键值对，dict的结构图如下：
        redisDb定义的第二个属性是expires，它的类型也是字典，Redis会把所有过期的键值对加入到expires，之后再通过定期删除来清理expires里面的值。
        加入expires的场景有：
            1、set指定过期时间expire。（如果设置key的时候指定了过期时间，Redis会将这个key直接加入到expires字典中，并将超时时间设置到该字典元素。）
            2、调用expire命令 （显式指定某个key的过期时间）
            3、恢复或修改数据 （从Redis持久化文件中恢复文件或者修改key，如果数据中的key已经设置了过期时间，就将这个key加入到expires字典中）
        以上这些操作都会将过期的key保存到expires。redis会定期从expires字典中清理过期的key。

    3、Redis清理过期key的时机
        1、Redis在启动的时候，会注册两种事件，一种是时间事件，另一种是文件事件。
        （可参考启动Redis的时候，Redis做了什么）时间事件主要是Redis处理后台操作的一类事件，
         比如客户端超时、删除过期key；文件事件是处理请求。
         在时间事件中，redis注册的回调函数是serverCron，在定时任务回调函数中，通过调用databasesCron清理部分过期key。（这是定期删除的实现。）

        2、每次访问key的时候，都会调用expireIfNeeded函数判断key是否过期，如果是，清理key。（这是惰性删除的实现。）

        3、每次事件循环执行时，主动清理部分过期key。（这也是惰性删除的实现。）

    4、为什么要有内存回收策略。
        Redis结合了定期删除和惰性删除，基本上能很好的处理过期数据的清理，但是实际上还是有点问题的，如果过期key较多，定期删除漏掉了一部分，
        而且也没有及时去查，即没有走惰性删除，那么就会有大量的过期key堆积在内存中，导致redis内存耗尽，因此需要内存淘汰策略。
        清理掉老数据，以保证新数据的存入。
    5、Redis的内存淘汰机制
        1、noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错。
        2、allkeys-lru：当内存不足以容纳新写入数据时，在键空间（server.db[i].dict）中，移除最近最少使用的 key（这个是最常用的）。
        3、allkeys-random：当内存不足以容纳新写入数据时，在键空间（server.db[i].dict）中，随机移除某个 key。
        4、volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间（server.db[i].expires）中，移除最近最少使用的 key。
        5、volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间（server.db[i].expires）中，随机移除某个 key。
        6、volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间（server.db[i].expires）中，有更早过期时间的 key 优先移除。


       在配置文件中，通过maxmemory-policy可以配置要使用哪一个淘汰机制。

    6、什么时候会进行淘汰？
        Redis会在每一次处理命令的时候（processCommand函数调用freeMemoryIfNeeded）判断当前redis是否达到了内存的最大限制，
        如果达到限制，则使用对应的算法去处理需要删除的key。伪代码如下：

        int processCommand(client *c)
        {
            ...
            if (server.maxmemory) {
                int retval = freeMemoryIfNeeded();
            }
            ...
        }


     参考链接：https://juejin.cn/post/6844903873618903048

7、redis 持久化  RDB&AOF
        1、RDB
            RDB是一种快照存储持久化方式，具体就是将Redis某一时刻的内存数据保存到硬盘的文件当中，
            默认保存的文件名为dump.rdb，而在Redis服务器启动时，会重新加载dump.rdb文件的数据到内存当中恢复数据

        工作原理
        1、Redis调用fork()，产生一个子进程。
        2、子进程把数据写到一个临时的RDB文件。
        3、当子进程写完新的RDB文件后，把旧的RDB文件替换掉。

            1） 开启RDB持久化方式
                1） save命令
                       当客户端向服务器发送save命令请求进行持久化时，服务器会阻塞save命令之后的其他客户端的请求，直到数据同步完成。
                        如果数据量太大，同步数据会执行很久，而这期间Redis服务器也无法接收其他请求，所以，最好不要在生产环境使用save命令。

                2） bgsave命令
                    1、当客户端发服务发出bgsave命令时，Redis服务器主进程会forks一个子进程来解决数据同步问题，在将数据保存到rdb文件之后，子进程会退出。
                    2、所以，与save命令相比，Redis服务器在处理bgsave采用子线程进行IO写入，而主进程仍然可以接收其他请求，但forks子进程是同步的，所以forks子进程时，一样不能接收其他请求，这意味着，如果forks一个子进程花费的时间太久(一般是很快的)，bgsave命令仍然有阻塞其他客户的请求的情况发生。
                    3、我们可以控制单个Redis实例的最大内存，来尽可能降低Redis在fork时的事件消耗。以及上面提到的自动触发的频率减少fork次数，或者使用手动触发，根据自己的机制来完成持久化。

                3） 通过配置文件自动触发
                自动触发的场景主要是有以下几点：

                1.根据我们的 save m n 配置规则自动触发；
                2.从节点全量复制时，主节点发送rdb文件给从节点完成复制操作，主节点会触发 bgsave；
                3.执行 debug reload 时；
                4.执行shutdown时，如果没有开启aof，也会触发。
                eg: save 900 1   #900s内如果有1条数据写入，就产生RDB快照

                配置文件自动生成rdb文件后台使用的是bgsave方式。

             特别说明 bgsave 命令： 其实是一种写时复制的机制
                1、fork创建出的子进程，与父进程共享内存空间。也就是说，如果子进程不对内存空间进行写入操作的话（Redis的子进程只做数据落盘的操作，也不会去写数据），
                内存空间中的数据并不会复制给子进程，这样创建子进程的速度就很快了！(不用复制，直接引用父进程的物理空间，玩的是指针)。
                2、当Redis父进程修改数据时，父进程会将原先的数据复制一份生成新的副本，然后修改父进程的指针，指向新的数据，此时父进程修改的新的数据不会影响到子进程。此时子进程的指针仍然指向旧的数据，
                子进程看到的数据还是bgsave时候的数据。当下一次执行bgsave时，新fork出来的子进程指针才会指向这次新的数据。

          2、AOF
                与RDB存储某个时刻的快照不同，AOF持久化方式会记录客户端对服务器的每一次写操作命令，并将这些写操作以追加的方式保存到以后缀为aof文件中，
                在Redis服务器重启时，会加载并运行aof文件的命令，以达到恢复数据的目的。
                1、开启AOF的方式
                    方式一：bgrewriteaof命令
                    方式二：通过配置文件自动触发 redis默认不开启AOF持久化方式，我们可以在配置文件中开启并进行更加详细的配置：

                2、AOF 重写
                 随着运行时间的增长，执行的命令越来越多，会导致AOF文件越来越大，
                 当AOF文件过大时，redis会执行重写机制来压缩AOF文件。重写机制主要是将文件中无效的命令去除。
                 比如：
                 1、同一个key的值，只保留最后一次写入
                 2、已删除或者已过期数据相关命令会被去除
                 3、这样就避免了，aof文件过大而实际内存数据小的问题(如频繁修改数据时，命令很多，实际数据很少)

                 重写的触发方式：
                        1、手动执行 bgrewriteaof 触发AOF重写
                  3、重写的过程
                      1、从主进程中fork出子进程，并拿到fork时的AOF文件数据写到一个临时AOF文件中
                      2、在重写过程中，redis收到的命令会同时写到AOF缓冲区和重写缓冲区中，这样保证重写不丢失重写过程中的命令
                      3、重写完成后通知主进程，主进程会将AOF缓冲区中的数据追加到子进程生成的文件中
                      4、redis会原子的将旧文件替换为新文件，并开始将数据写入到新的aof文件上

              作者：奔跑的Robi
              链接：https://www.jianshu.com/p/f72008c4d49f
              来源：简书
              著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

           3、混合持久化
            重启 Redis 时，我们很少使用 RDB来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 RDB来说要慢很多，
            这样在 Redis 实例很大的情况下，启动需要花费很长的时间。Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。
            通过如下配置可以开启混合持久化(前提必须先开启aof):
            aof‐use‐rdb‐preambleyes #开启混合持久化
            这种方式结合了RDB和AOF的优点，既能快速加载又能避免丢失过多的数据。

            过程：
            1、如果开启了混合持久化，AOF在重写时，不再是单纯将内存数据转换为RESP命令写入AOF文件，而是将重写这一刻之前的内存做RDB快照处理，并且将RDB快照内容和增量的AOF修改内存数据的命令存在一起，
            都写入新的AOF文件，新的文件一开始不叫appendonly.aof，等到重写完新的AOF文件才会进行改名，覆盖原有的AOF文件，完成新旧两个AOF文件的替换。
            于是在 Redis 重启的时候，可以先加载 RDB 的内容，
            然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，因此重启效率大幅得到提升。

            4、从持久化中恢复数据
                启动时会先检查AOF文件是否存在，如果不存在就尝试加载RDB。那么为什么会优先加载AOF呢？因为AOF保存的数据更完整，通过上面的分析我们知道AOF基本上最多损失1s的数据。



        参考链接：https://juejin.cn/post/6844903873618903048
 8、redis哨兵机制（Sentinel)
        Redis主从架构解决了服务负载的压力分担,读写分离有效的分离了流量.另外从库挂了，还有可以通过主库来持续进行服务。
       但是 Redis 主从复制有一个很大的缺点就是没有办法对 master 进行动态选举（当 master 挂掉后，会通过一定的机制，从 slave 中选举出一个新的 master），需要使用 Sentinel 机制完成动态选举

        1、哨兵机制简介
        1）Sentinel(哨兵) 进程是用于监控 Redis 集群中 Master 主服务器工作的状态

        2）在 Master 主服务器发生故障的时候，可以实现 Master 和 Slave 服务器的切换，保证系统的高可用（High Availability）

        3、哨兵进程的工作方式

        1、主观下线和客观下线：
                1）每个 Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的 Master 主服务器，Slave 从服务器以及其他 Sentinel（哨兵）进程发送一个 PING 命令。（此处我们还没有讲到集群，下一章节就会讲到，这一点并不影响我们模拟哨兵机制）

                2. 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）。

                3. 如果一个 Master 主服务器被标记为主观下线（SDOWN），则正在监视这个 Master 主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认 Master 主服务器的确进入了主观下线状态。

                4. 当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认 Master 主服务器进入了主观下线状态（SDOWN）， 则 Master 主服务器会被标记为客观下线（ODOWN）。
        2、Sentinel集群选举Leader：
            a、每个在线的哨兵节点都可以成为领导者，当它确认（比如哨兵3）主节点下线时，会向其它哨兵发is-master-down-by-addr命令，征求判断并要求将自己设置为领导者，由领导者处理故障转移；
            b、当其它哨兵收到此命令时，可以同意或者拒绝它成为领导者；
            c、如果哨兵3发现自己在选举的票数大于等于num(sentinels)/2+1时，将成为领导者，如果没有超过，继续选举…………
        3、故障转移机制，Sentinel Leader决定新主节点
               当Sentinel集群选举出Sentinel Leader后，由Sentinel Leader从redis从节点中选择一个redis节点作为主节点：
              1、 过滤故障的节点
              2、 选择优先级slave-priority最大的从节点作为主节点，如不存在则继续
              3、 选择复制偏移量（数据写入量的字节，记录写了多少数据。主服务器会把偏移量同步给从服务器，当主从的偏移量一致，则数据是完全同步）最大的从节点作为主节点，如不存在则继续
              4、 选择runid（redis每次启动的时候生成随机的runid作为redis的标识）最小的从节点作为主节点


        当Sentinel 收集到足够多的主观下线投票之后，它会将主服务器判断为客观下线，并发起一次针对主服务器的故障转移操作。

        哨兵模式的优缺点
        优点：

        1、哨兵模式是基于主从模式的，所有主从的优点，哨兵模式都具有。
        2、主从可以自动切换，系统更健壮，可用性更高(可以看作自动版的主从复制)。
        缺点：
        Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂
        参考链接：https://segmentfault.com/a/1190000022808576

    2、哨兵模式脑裂问题
        哨兵模式的 redis 集群，假如原来只有一个主服务，经过故障转移后，产生多个主服务，这样脑裂现象出现了。

        redis的主从模式下脑裂是指因为网络问题，导致redis 主节点跟从节点和Sentinel集群处于不同的网络分区，
        此时因为Sentinel集群无法感知到 主节点的存在，就会将某一个从节点提升为主节点。
        此时就存在两个不同的主节点，就像一个大脑分裂成了两个。
        例子：
            在切换过程中，既然客户端仍然和原主库通信，这就表明，原主库并没有真的发生故障（例如主库进程挂掉）。
            我们猜测，主库是由于某些原因无法处理请求，也没有响应哨兵的心跳，才被哨兵错误地判断为客观下线的。
            结果，在被判断下线之后，原主库又重新开始处理请求了，而此时，哨兵还没有完成主从切换，
            客户端仍然可以和原主库通信，客户端发送的写操作就会在原主库上写入数据了。

        解决脑裂：
            1、sentienl 部署
                1、sentinel 节点个数最好 >= 3。
                2、sentinel 节点个数最好是基数。
                3、sentinel 的选举法定人数设置为 (n/2 + 1)。
                如果 sentinel 个数总数为 3，那么最好 quorum == 2，这样最接近真实：少数服从多数，不会出现两个票数一样的代表同时被选上，进行故障转移。
            2、redis配置
            Redis 已经提供了两个配置项来限制主库的请求处理，分别是 min-slaves-to-write 和 min-slaves-max-lag。
            1、min-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量；
            2、min-slaves-max-lag：这个配置项设置了主从库间进行数据复制时，从库给主库发送 ACK 消息的最大延迟（以秒为单位）。
               说明：
               1、 我们可以把 min-slaves-to-write 和 min-slaves-max-lag 这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为 N 和 T。这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的请求了。
               2、 即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves-max-lag 的组合要求就无法得到满足，原主库就会被限制接收客户端请求，客户端也就不能在原主库中写入新数据了。
               列子：
                假设我们将 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 12s，把哨兵的 down-after-milliseconds 设置为 10s，主库因为某些原因卡住了 15s，导致哨兵判断主库客观下线，开始进行主从切换。
                同时，因为原主库卡住了 15s，没有一个从库能和原主库在 12s 内进行数据复制，原主库也无法接收客户端请求了。这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。

 9、Redis有三种集群模式，分别是：
    参考链接：https://segmentfault.com/a/1190000022808576
        * 主从模式
            为了避免单点故障，通常的做法是将数据库复制多个副本以部署在不同的服务器上，这样即使有一台服务器出现故障，其他服务器依然可以继续提供服务。
        Redis 提供了复制（replication）功能，可以实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上
         1、 在复制的概念中，数据库分为两类，一类是主数据库（master），另一类是从数据库(slave）。
            主数据库可以进行读写操作，当写操作导致数据变化时会自动将数据同步给从数据库。
            而从数据库一般是只读的，并接受主数据库同步过来的数据。一个主数据库可以拥有多个从数据库，而一个从数据库只能拥有一个主数据库。
         2、 主从复制原理
                1、从数据库启动成功后，连接主数据库，发送 SYNC 命令；
                2、主数据库接收到 SYNC 命令后，开始执行 BGSAVE 命令生成 RDB 文件并使用缓冲区记录此后执行的所有写命令；
                3、主数据库 BGSAVE 执行完后，向所有从数据库发送快照文件，并在发送期间继续记录被执行的写命令；
                4、从数据库收到快照文件后丢弃所有旧数据，载入收到的快照；
                5、主数据库快照发送完毕后开始向从数据库发送缓冲区中的写命令；
                6、从数据库完成对快照的载入，开始接收命令请求，并执行来自主数据库缓冲区的写命令；（从数据库初始化完成）
                7、主数据库每执行一个写命令就会向从数据库发送相同的写命令，从数据库接收并执行收到的写命令（从数据库初始化完成后的操作）

                8、出现断开重连后，2.8之后的版本会将断线期间的命令传给重数据库，增量复制。
                9、主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。Redis 的策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。

         3、引入主从复制机制的目的有两个
            1、一个是读写分离，分担 "master" 的读写压力
            2、一个是方便做容灾恢复

         4、主从复制缺点
           1、Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复（也就是要人工介入）；
           2、主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性；
           3、如果多个 Slave 断线了，需要重启的时候，尽量不要在同一时间段进行重启。因为只要 Slave 启动，就会发送sync 请求和主机全量同步，当多个 Slave 重启的时候，可能会导致 Master IO 剧增从而宕机。
           4、Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂；

        * Sentinel模式
            参考8

        * Cluster模式
            Redis集群没有使用一致性hash,而是引入了哈希槽的概念，当需要在 Redis 集群中放置一个 key-value 时，根据 CRC16(key) mod 16384的值，决定将一个key放到哪个桶中。
            Cluster 集群模式（Redis官方）
            Redis Cluster是一种服务器 Sharding 技术，3.0版本开始正式提供。
            Redis 的哨兵模式基本已经可以实现高可用，读写分离 ，但是在这种模式下每台 Redis 服务器都存储相同的数据，很浪费内存，所以在 redis3.0上加入了 Cluster 集群模式，实现了 Redis 的分布式存储，也就是说每台 Redis 节点上存储不同的内容。

            Redis Cluster 是Redis的集群实现，内置数据自动分片机制，集群内部将所有的key映射到16384个Slot中，集群中的每个Redis Instance负责其中的一部分的Slot的读写。
            集群客户端连接集群中任一Redis Instance即可发送命令，当Redis Instance收到自己不负责的Slot的请求时，会将负责请求Key所在Slot的Redis Instance地址返回给客户端，
            客户端收到后自动将原请求重新发往这个地址，对外部透明。一个Key到底属于哪个Slot由crc16(key) % 16384 决定。
            在Redis集群的实现中，使用哈希算法（公式是CRC16(Key) mod 16383）将Key映射到0~16383范围的整数。这样每个整数对应存储了若干个Key-Value数据，这样一个整数对应的抽象存储称为一个槽（slot）。每个Redis Cluster的节点——准确讲是master节点——负责一定范围的槽，所有节点组成的集群覆盖了0~16383整个范围的槽。

            Redis 集群的数据分片是redis进行分布式存储的一种，它引入了hash槽的概念，每个redis节点存储一定范围的hash槽 ，redis集群有16384个hash槽，每个key通过CRC16校验后对16384取模来决定存储在哪个槽哪个节点
            比如当前有三个节点 那么：
            节点 A 包含 0 到 5500号哈希槽.
            节点 B 包含5501 到 11000 号哈希槽.
            节点 C 包含11001 到 16384号哈希槽.



            面试问题：为什么RedisCluster会设计成16384个槽呢?
                1.如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大。

                如上所述，在消息头中，最占空间的是 myslots[CLUSTER_SLOTS/8]。 当槽位为65536时，这块的大小是: 65536÷8÷1024=8kb因为每秒钟，redis节点需要发送一定数量的ping消息作为心跳包，如果槽位为65536，这个ping消息的消息头太大了，浪费带宽。

                2.redis的集群主节点数量基本不可能超过1000个。

                如上所述，集群节点越多，心跳包的消息体内携带的数据越多。如果节点过1000个，也会导致网络拥堵。因此redis作者，不建议redis cluster节点数量超过1000个。 那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了。没有必要拓展到65536个。

                3.槽位越小，节点少的情况下，压缩率高

                Redis主节点的配置信息中，它所负责的哈希槽是通过一张bitmap的形式来保存的，在传输过程中，会对bitmap进行压缩，但是如果bitmap的填充率slots / N很高的话(N表示节点数)，bitmap的压缩率就很低。 如果节点数很少，而哈希槽数量很多的话，bitmap的压缩率就很低。

                而16384÷8÷1024=2kb，怎么样，神奇不！

                综上所述，作者决定取16384个槽，不多不少，刚刚好！

    Redis 集群的主从复制模型
        为了保证高可用，redis-cluster集群引入了主从复制模型，一个主节点对应一个或者多个从节点，当主节点宕机的时候，就会启用从节点。当其它主节点 ping 一个主节点 A 时，
        如果半数以上的主节点与 A 通信超时，那么认为主节点 A 宕机了。如果主节点 A 和它的从节点 A1 都宕机了，那么该集群就无法再提供服务了。

     集群的特点
           1、所有的 redis 节点彼此互联(PING-PONG机制)，内部使用二进制协议优化传输速度和带宽。
           2、节点的 fail 是通过集群中超过半数的节点检测失效时才生效。
           3、客户端与 Redis 节点直连，不需要中间代理层.客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。


11、Redis 是单线程的？为什么还那么快。
  1、redis是单线程介绍
  	1、我们所说的redis单线程，指的是“其网络IO和键值对读写是由一个线程完成的”，也就是说，Redis中
  	只有网络请求模块和数据操作模块是单线程的。而其他的如持久化模块其实是支持多线程的。
  	2、Redis为什么这么快。
  		1、Redis 操作基于内存，绝大多数操作的性能瓶颈不在 CPU
  		2、单线程模型，避免了线程间切换带来的性能开销
  		3、redis为每一个数据结构，都设计了一种极多种底层实现 。例如string => SDS ,以便提供更好的性能。
  		4、Redis 采用了 IO 多路复用机制，就是为了让单线程(进程)的服务端应用同时处理多个客户端的事件。
  			Redis 的 I/O 多路复用模型进行一下描述说明：
  			1、一个 socket 客户端与服务端连接时，会生成对应一个套接字描述符(套接字描述符是文件描述符的一种)，每一个 socket 网络连接其实都对应一个文件描述符。
  			2、多个客户端与服务端连接时，Redis 使用 「I/O 多路复用程序」 将客户端 socket 对应的 FD 注册到监听列表(一个队列)中。当客服端执行 read、write 等操作命令时，I/O 多路复用程序会将命令封装成一个事件，并绑定到对应的 FD 上。
  			3、文件事件处理器」使用 I/O 多路复用模块同时监控多个文件描述符（fd）的读写情况，当 accept、read、write 和 close 文件事件产生时，文件事件处理器就会回调 FD 绑定的事件处理器进行处理相关命令操作。
  			4、整个文件事件处理器是在单线程上运行的，但是通过 I/O 多路复用模块的引入，实现了同时对多个 FD 读写的监控，当其中一个 client 端达到写或读的状态，文件事件处理器就马上执行，从而就不会出现 I/O 堵塞的问题，提高了网络通信的性能。

  3、为什么Redis 6.0 引入多线程

  	使用多线程的目的主要是为了提高CPU和I/O利用率。
  	1、Redis的操作基本都是基于内存的，CPU资源根本就不是Redis的性能瓶颈,使用多线程提升Redis的CPU利用率完全是没有必要的。
  	2、Redis 采用I/O多路复用提高I/O利用率。

  	但是。多路复用的IO模型中，在处理网络请求时，调用 select （其他函数同理）的过程是阻塞的，也就是说这个过程会阻塞线程，如果并发量很高，此处可能会成为瓶颈。

  	因此 猜测 redis6.0采用多个I/O线程来处理网络请求，网络请求的解析可以由其他线程完成。
  	然后把解析后的请求交由主线程进行实际的读写，提升网络请求处理的并行度。

  	结论：Redis 6.0 的多 IO 线程只是用来处理网络请求的，对于读写命令，Redis 仍然使用单线程来处理。

12、主从数据库不一致如何解决
       场景描述，对于主从库，读写分离，如果主从库更新同步有时差，就会导致主从库数据的不一致
       1、忽略这个数据不一致，在数据一致性要求不高的业务下，未必需要时时一致性
       2、强制读主库，使用一个高可用的主库，数据库读写都在主库，添加一个缓存，提升数据读取的性能。
       3、选择性读主库，添加一个缓存，用来记录必须读主库的数据，将哪个库，哪个表，哪个主键，
            作为缓存的 key,设置缓存失效的时间为主从库同步的时间，如果缓存当中有这个数据，
            直接读取主库，如果缓存当中没有这个主键，就到对应的从库中读取。

13、假如 Redis  里面有 1  亿个 key ，其中有 10w 个 个 key  是以某个固定的已知的前缀开头的，如果将它们全部找出来？
    使用 keys 指令可以扫出指定模式的 key 列表。

    对方接着追问：如果这个 redis 正在给线上的业务提供服务，那使用 keys 指令会有什么问题？
    这个时候你要回答 redis 关键的一个特性：redis 的单线程的。keys 指令会导致线程阻塞一段时间，
    线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用 scan 指令，scan 指令可以无阻塞的提取出指定模式的 key 列表，
    但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 keys 指令长。使用 Redis  做过异步队列吗，是如何实现的使用 list 类型保存数据信息，
    rpush 生产消息，lpop 消费消息，当 lpop 没有消息时，可以 sleep 一段时间，然后再检查有没有信息，如果不想 sleep 的话，可以使用 blpop,  在没有信息的时候，会一直阻塞，
    直到信息的到来。redis 可以通过 pub/sub 主题订阅模式实现一个生产者，多个消费者，当然也存在一定的缺点，当消费者下线时，生产的消息会丢


14、redis事务
   1、Redis事务


   	1、Redis中的事务是可以视为一个队列，即我们可以通过MULTI开始一个事务，这相当于我们声明了一个命令队列
   	接下来，我们向Redis中提交的每条命令，都会进入这个命令队列。当我们输入EXEC命令时，将触发当前事务，
   	这相当于我们从命令队列中取出命令执行，所以Redis中一个事务从开始到执行会经历 开始事务，命令入队 ，
   	执行事务 三个阶段。

   	2、玩Redis事务相关命令：

   		1、MULTI ：开启事务，redis会将后续的命令逐个放入队列中，然后使用EXEC命令来原子化执行这个命令系列。
   		2、EXEC：执行事务中的所有操作命令。
   		3、DISCARD：取消事务，放弃执行事务块中的所有命令。
   		4、WATCH：监视一个或多个key,如果事务在执行前，这个key(或多个key)被其他命令修改，则事务被中断，不会执行事务中的任何命令。
   		5、UNWATCH：取消WATCH对所有key的监视。

   	3、事务执行失败的错误场景
   		1、语法错误（编译器错误），在开启事务后，修改key1 => 11,修改key2 => 222 但是k2的语法错误，
   		最终导致事务提交失败，k1和 k2保留原值
   		2、Redis 类型错误（运行时错误），在开启事务后，修改k1 => 11,修改key => 2222,但是将k2的类型
   		作为list， 在运行时检测类型错误，最终导致事务提交失败，此时事务并没有回滚，而是跳过错误命令继续执行，
   		key1 的值改变，key2保留原值。

   	4、WATCH监视key
   		Redis事务是非原子性的，要让Redis事务完全具有事务回滚的能力，需要借助于命令WATCH来实现。

   		当使用EXEC执行事务命令时，首先会比对WATCH所监控的键值对，如果没有改变，他会执行事务队列中的命令，提交事务；
   		如果发生改变，将不会执行事务中的任何命令，同时事务回滚。当然无论是否回滚，Redis都会取消执行事务前的WATCH命令。
   	5、Redis事务为什么不支持回滚？
   		1、Redis认为，Redis 命令只会因为错误的语法而失败（并且这些语法不能在入队时发现），或是命令用在了错误的类型键上面
   		，也就是说，从实用性角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发过程被发现，而不是出现在生产环境中
   		2、因为不需要对回滚进行支持，所以Redis的内部可以保持简单且快速。

   	6、管道和事务的区别。
   	1、pipeline是客户端的行为，对于服务器来说是透明的，可以认为服务器无法区分客户端发送来的查询命令是以普通命令的形式还是以pipeline的形式发送到服务器的；
   	2、而事务则是实现在服务器端的行为，用户执行MULTI命令时，服务器会将对应这个用户的客户端对象设置为一个特殊的状态，
   	    在这个状态下后续用户执行的查询命令不会被真的执行，而是被服务器缓存起来，直到用户执行EXEC命令为止，服务器会将这个用户对应的客户端对象中缓存的命令按照提交的顺序依次执行。