

1、MyIsam 和 Innodb区别
    1. InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；
    2. InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败；
    3. InnoDB 是聚集索引，MyISAM 是非聚集索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。
        但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。
        而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。
    4. InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描。而MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；
    5. InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。
        这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；

    MyISAM引擎中 也是使用b+tree作为索引数据结构，叶子结点的data域存放的是数据记录的地址。
    myIsam的索引文件，仅仅保存数据的记录
    myIsam 中，主索引和辅助索引在结构上没有区别，都是存放地址，只是主索引要求key是唯一的，而辅助索引的key可以重复。

2、索引覆盖
    1、索引覆盖，是指从非主键索引就能查到的记录，而不需要查询主键索引中的记录，避免了回表的产生，减少了数的搜索次数，提升查询的性能

    demo: student 表，现在name上建立有索引，但是年龄和name经常需要一起查询，因此可以删除name索引，建立name_age索引，
    select age,name from student时 就可以直接获取name,和age，而不需要在进行回表。

3、聚簇索引和非聚集索引（辅助索引/二级索引）
   1、聚集索引不是一种单独的索引类型，而是一种数据存储方式。索引键值的逻辑顺序，据定了表数据行的物理存储顺序。
   2、非聚集索引是逻辑上连续，物理存储上并不连续

   myisam 都是非聚集索引 （共3个文件.frm存储表定义，.MYD 存储扩展名，.MYI存储索引文件）
   innodb 主键索引是聚集索引，其他都是非聚集索引。（数据文件及索引文件）

4、联合索引和最左匹配
    1、在MySQL建立联合索引时会遵守最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。
    2、最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，
    比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，
        如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。
    3、 =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式


5、MYSQL 索引 （B+索引）
    总结：为什么使用B++ 树作为索引的数据结构
        1、先介绍，二叉树，二叉搜索树(avl)，红黑树，b树，b++存放数据优点。

        1、平衡二叉树
            平衡二叉树又被称为AVL树，本质还是二叉查找树
            平衡二叉树是一颗空树或者它的左右两个子树的高度差的绝对值不超过1，并且左右子树也是平衡树
            非叶子节点值大于左子节点值而小于右子节点值
            非叶子节点最多拥有两个子节点
        2、红黑树
            每个节点要么是红色要么是黑色
            根节点是黑色
            每个叶子节点(NIL)是黑色
            每个红色节点的两个子节点一定为黑色
            任意一个节点到每个叶子节点的路径都包含数量相同的黑色节点
            如果一个节点存在黑子节点，那么该节点肯定有两个子节点

        3、平衡二叉树 和 红黑树区别
         1、红黑树放弃了追求完全平衡，追求大致平衡，在与平衡二叉树的时间复杂度相差不大的情况下，保证每次插入最多只需要三次旋转就能达到平衡，实现起来也更为简单。

        4、B树又叫平衡多路查找树，
            每个节点中，都包含数据(key和data域)和指针，相互间隔
            叶节点具有相同的深度，叶节点的指针为空
            节点中的数据索引从左到右递增排列
            所有索引元素不重复

        5、B+树
            非叶子节点中不存储data，只存储索引，可以放更多的索引
            叶子节点包含所有索引字段
            叶子节点包含数据(key和data域)和指针
            叶子节点用指针连接，提高区间访问的性能
        InnoDB使用B+树的原因。
        1、avl树 和 红黑树 多用于内存排序，每个节点存放一个数据，相同数量的数据，树的深度太大，每次读取消耗大量的磁盘io
        2、B+树非叶子节点只存储key值，而B-树存储key值和data值，这样B+树每次读取时可以读取到更多的key值
        3、mysql进行区间访问时，由于B+树叶子节点之间用指针（双向链表）相连，只需要遍历所有的叶子节点即可；而B-树则需要中序遍历那样遍历
        4、B+树非叶子节点只存储key值，而B-树存储key值和data值，导致B+树的层级更少，查询效率更高
        5、 B+树所有关键词地址都存在叶子节点上，所以每次查询次数都相同，比B-树稳定


        innodb存储引擎一页的大小为16kb，一般主键类型为int占4个字节，或bigint占8个字节，指针类型页一般4个或8个字节，也就是说一个页中大概存储16*1024/16=1024个key，
        深度为3的B+tree索引（三页）可以维护1024*1024*1024=10亿条记录，实际情况每个节点不可能填满，
        B+tree的高度一般为2-4曾，mysql的innodb存储引擎将根节点常驻内 存，也就是查找某一键值的行记录最多需要1-3次磁盘IO操作

   1)	二叉查找树
      首先，让我们先看一张图：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/mysql_temp1.jpeg
    二叉查找树分析：
       图中的圆为二叉查找树的节点，节点中存储了键（key）和数据 (data)。键对应user表中的id，数据对应user表中的行数据数据。
       二叉查找树的特点就是任何节点的左子节点的键值都小于当前节点的键值，右子节点的键值都大于当前节点的键值。顶端的节点我们称为根节点，没有子节点的节点我们称之为叶节点。

       eg:
       如果我们需要查找 id=12 的用户信息，利用我们创建的二叉查找树索引，查找流程如下：
       将根节点作为当前节点，把 12 与当前节点的键值 10 比较，12 大于 10，接下来我们把当前节点>的右子节点作为当前节点。
       继续把 12 和当前节点的键值 13 比较，发现 12 小于 13，把当前节点的左子节点作为当前节点。
       把 12 和当前节点的键值 12 对比，12 等于 12，满足条件，我们从当前节点中取出 data，即 id=12，name=xm。
       利用二叉查找树我们只需要 3 次即可找到匹配的数据。如果在表中一条条的查找的话，我们需要 6 次才能找到。

    2) 平衡二叉树
        上面我们讲解了利用二叉查找树可以快速的找到数据。但是，如果上面的二叉查找树是这样的构造：
        见图：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/mysql_temp2.jpeg
        这个时候可以看到我们的二叉查找树变成了一个链表。如果我们需要查找 id=17 的用户信息，我们需要查找 7 次，也就相当于全表扫描了。
        导致这个现象的原因其实是二叉查找树变得不平衡了，也就是高度太高了，从而导致查找效率的不稳定。

        为了解决这个问题，我们需要保证二叉查找树一直保持平衡，就需要用到平衡二叉树了。
        平衡二叉树又称 AVL 树，在满足二叉查找树特性的基础上，要求每个节点的左右子树的高度差不能超过 1。
        如图3。
        https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/mysql_temp3.jpeg

        由平衡二叉树的构造我们可以发现第一张图中的二叉树其实就是一棵平衡二叉树。

        平衡二叉树保证了树的构造是平衡的，当我们插入或删除数据导致不满足平衡二叉树不平衡时，平衡二叉树会进行调整树上的节点来保持平衡。具体的调整方式这里就不介绍了。
        平衡二叉树相比于二叉查找树来说，查找效率更稳定，总体的查找速度也更快。


   3） B树
        因为内存的易失性。一般情况下，我们都会选择将 user 表中的数据和索引存储在磁盘这种外围设备中。
        但是和内存相比，从磁盘中读取数据的速度会慢上百倍千倍甚至万倍，所以，我们应当尽量减少从磁盘中读取数据的次数。
        另外，从磁盘中读取数据时，都是按照磁盘块来读取的，并不是一条一条的读。
        如果我们能把尽量多的数据放进磁盘块中，那一次磁盘读取操作就会读取更多数据，那我们查找数据的时间也会大幅度降低。
        如果我们用树这种数据结构作为索引的数据结构，那我们每查找一次数据就需要从磁盘中读取一个节点，也就是我们说的一个磁盘块。
        我们都知道平衡二叉树可是每个节点只存储一个键值和数据的。那说明什么？说明每个磁盘块仅仅存储一个键值和数据！那如果我们要存储海量的数据呢？
        可以想象到二叉树的节点将会非常多，高度也会极其高，我们查找数据时也会进行很多次磁盘 IO，我们查找数据的效率将会极低！

        如图4：
            https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/mysql_temp4.jpeg

           为了解决平衡二叉树的这个弊端，我们应该寻找一种单个节点可以存储多个键值和数据的平衡树。也就是我们接下来要说的 B 树
           B 树（Balance Tree）即为平衡树的意思，下图即是一棵 B 树：
           如图5： https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/mysql_temp5.jpeg

         图中的 p 节点为指向子节点的指针，二叉查找树和平衡二叉树其实也有，因为图的美观性，被省略了。

         图中的每个节点称为页，页就是我们上面说的磁盘块，在 MySQL 中数据读取的基本单位都是页，所以我们这里叫做页更符合 MySQL 中索引的底层数据结构。

         从上图可以看出，B 树相对于平衡二叉树，每个节点存储了更多的键值（key）和数据（data），并且每个节点拥有更多的子节点，子节点的个数一般称为阶，上述图中的 B 树为 3 阶 B 树，高度也会很低。
         基于这个特性，B 树查找数据读取磁盘的次数将会很少，数据的查找效率也会比平衡二叉树高很多。
         eg:
         假如我们要查找 id=28 的用户信息，那么我们在上图 B 树中查找的流程如下：
         先找到根节点也就是页 1，判断 28 在键值 17 和 35 之间，那么我们根据页 1 中的指针 p2 找到页 3。
         将 28 和页 3 中的键值相比较，28 在 26 和 30 之间，我们根据页 3 中的指针 p2 找到页 8。
         将 28 和页 8 中的键值相比较，发现有匹配的键值 28，键值 28 对应的用户信息为（28，bv）


    4) B+ 树
            B+ 树是对 B 树的进一步优化。让我们先来看下 B+ 树的结构图：
            如图6：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/mysql_temp6.jpeg


       根据上图我们来看下 B+ 树和 B 树有什么不同：

       ①B+ 树非叶子节点上是不存储数据的，仅存储键值，而 B 树节点中不仅存储键值，也会存储数据。

       之所以这么做是因为在数据库中页的大小是固定的，InnoDB 中页的默认大小是 16KB。

       如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的 IO 次数又会再次减少，数据查询的效率也会更快。

       另外，B+ 树的阶数是等于键值的数量的，如果我们的 B+ 树一个节点可以存储 1000 个键值，那么 3 层 B+ 树可以存储 1000×1000×1000=10 亿个数据。

       一般根节点是常驻内存的，所以一般我们查找 10 亿数据，只需要 2 次磁盘 IO。

       ②因为 B+ 树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的。

       那么 B+ 树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。而 B 树因为数据分散在各个节点，要实现这一点是很不容易的。

       有心的读者可能还发现上图 B+ 树中各个页之间是通过双向链表连接的，叶子节点中的数据是通过单向链表连接的。

       其实上面的 B 树我们也可以对各个节点加上链表。这些不是它们之前的区别，是因为在 MySQL 的 InnoDB 存储引擎中，索引就是这样存储的。

       也就是说上图中的 B+ 树索引就是 InnoDB 中 B+ 树索引真正的实现方式，准确的说应该是聚集索引（聚集索引和非聚集索引下面会讲到）。

       通过上图可以看到，在 InnoDB 中，我们通过数据页之间通过双向链表连接以及叶子节点中数据之间通过单向链表连接的方式可以找到表中所有的数据。

       MyISAM 中的 B+ 树索引实现与 InnoDB 中的略有不同。在 MyISAM 中，B+ 树索引的叶子节点并不存储数据，而是存储数据的文件地址。

    二、聚集索引 VS 非聚集索引
    在上节介绍 B+ 树索引的时候，我们提到了图中的索引其实是聚集索引的实现方式。

    那什么是聚集索引呢？在 MySQL 中，B+ 树索引按照存储方式的不同分为聚集索引和非聚集索引。

    这里我们着重介绍 InnoDB 中的聚集索引和非聚集索引：

    ①聚集索引（聚簇索引）：以 InnoDB 作为存储引擎的表，表中的数据都会有一个主键，即使你不创建主键，系统也会帮你创建一个隐式的主键。

    这是因为 InnoDB 是把数据存放在 B+ 树中的，而 B+ 树的键值就是主键，在 B+ 树的叶子节点中，存储了表中所有的数据。

    这种以主键作为 B+ 树索引的键值而构建的 B+ 树索引，我们称之为聚集索引。

    ②非聚集索引（非聚簇索引）：以主键以外的列值作为键值构建的 B+ 树索引，我们称之为非聚集索引。

    非聚集索引与聚集索引的区别在于非聚集索引的叶子节点不存储表中的数据，而是存储该列对应的主键，想要查找数据我们还需要根据主键再去聚集索引中进行查找，这个再根据聚集索引查找数据的过程，我们称为回表。

    明白了聚集索引和非聚集索引的定义，我们应该明白这样一句话：数据即索引，索引即数据。


参考连接：   http://www.liuzk.com/410.html


6、事务的隔离级别和 ACID特性
	在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务，事务处理可以用来维护数据库的完整性。

	ACID 特性：
		事务的ACID特性:
       1、 原子性(atomicity):一个事务是一个不可分割的最小工作单位，事务中的所有操作要么都做，要么都不做。

       2、 一致性(consistency):事务前后数据的完整性必须保持一致.事务必须是使数据库从一个一致性状态变到另一个一致性状态,一致性与原子性是密切相关的。

       3、 隔离性(isolation):一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的,并发执行的各个事务之间不能互相干扰。有四种隔离级别

       4、· 持久性(durability):指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。


	注意： 事务的原子性和持久性 通过redo log(重做日志) 来实现，事务的持久性通过undo log 来实现。

		Innodb 引擎 通过 Force Log at Commmit 机制 实现事务的持久性和一致性。即当事务提交时，必须先将事务的所有日志写入重做日志文件，进行持久化，直到事务的Commited操作完成才算完成。（该日志 包括 redo log 和 undo log）
		1、Redo log
			重做日志用来实现事务的持久性和原子性。其有两部分组成：一是内存中的重做日志缓存（redo log buffer），二是重做日志文件（redo log file）

		2、Undo log
			undo log 主要用来实现事务的回滚和MVCC操作。当对数据库进行修改时，InnoDB 引擎不仅会产生redo，还会产生一定量的undo 。如果执行的事务和语句由于某种原因失败了，又或者用户执行了一条RollBAck请求回滚，就可以利用undo信息将数据也回滚到修改之前的样子。

			 undo log 另一个作用实现MVCC。当用户读取一行数据时，若该记录已经被其他事务占用，当然事务可以通过undo读取之前的行版本信息，即实现一致性非锁定读取。

			 undo log 也会产生 redo log . 因为undo log 也需要执行久化保护。
			 Innnodb 引擎需要执行fsync 刷盘操作吧 重做日志缓存 刷新到 磁盘文件中。



	在数据库中，为了有效的保证并发读取数据的正确性，提出了事务隔离级别

	1、Read UnCommitted  未提交读 。（允许脏读，也就是可能读取到其他会话中未提交事务修改的数据）
	2、Read Committed    已提交读 （只能读取到已经提交的数据。但是存在不可重复读的问题）
	3、Repeated Read 	 可重复读 （在同一个事务中内的查询都是和事务开始时候一致的。可重复读隔离级别，是InnoDb 的默认隔离级别。该级别消除了不可重复读，但是存在幻读现象）
	4、Serializable 串行读（完全串行化的读，每次读都需要获得表级的共享锁，读写都会被组塞）
		这个级别的实现很简单，读加共享锁，写加排它锁，读写互斥。使用的是悲观锁的理论，实现比较简单，数据安全，但是并发能力弱


	不可重复读 和 幻读的区别：
		不可重复读重点在于update 和 delete ，而幻读的重点在于insert.
		在可重复读隔离级别中，当前sql第一次读取到数据的时候，就将这些数据加锁，其他事务无法修改这些数据，就可以实现重复读取了。但是该方法无法锁住insert的数据，所以事务A先前读取了数据，或者修改了全部数据，事务B还是可以insert数据提交，这时事务A就会发现莫名多了一条之前没有的数据，这就是幻读。幻读不能通过行锁来解决，需要使用Serializable隔离级别。


7、	InnoDB锁类型
	1、悲观锁和乐观锁
		乐观锁和悲观锁 是两种思想，主要解决 数据竞争时候的并发问题

		悲观锁：

			悲观锁是指 数据对外界的修改保持保守的态度，
			在整个数据修改过程中，数据处于锁定状态。悲观锁的实现，往往依靠数据库提供的锁机制,以保证操作最大程度的独占性.

		乐观锁：
			相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。
			乐观锁（Optimistic Locking）认为对同一数据的并发操作不会总发生，属于小概率事件，不用每次都对数据上锁，也就是不采用数据库自身的锁机制，而是通过程序来实现。
			在程序上，我们可以采用版本号机制或者时间戳机制实现。

			Innodb使用乐观锁实现MVCC（可以介绍一致性锁定读和一致性非锁定读）


        1、锁机制划分
            乐观锁
            悲观锁

        2、锁粒度
            表锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。
            行锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高
            只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！

        3、兼容性
            共享锁S
            排他锁X
            例子：
            不同事务可以同时对同一行记录加 S 锁。

            如果一个事务对某一行记录加 X 锁，其他事务就不能加 S 锁或者 X 锁，从而导致锁等待。

            如果事务 T1 持有行 r 的 S 锁，那么另一个事务 T2 请求 r 的锁时，会做如下处理:

            T2 请求 S 锁立即被允许，结果 T1 T2 都持有 r 行的 S 锁

            T2 请求 X 锁不能被立即允许

            如果 T1 持有 r 的 X 锁，那么 T2 请求 r 的 X、S 锁都不能被立即允许，T2 必须等待 T1 释放 X 锁才可以，因为 X 锁与任何的锁都不兼容

            select ... lock in share mode：加 S 锁

            select ... for update：加 X 锁


    4、算法（行锁算法）
            1、记录锁（Record-Lock） 锁定一行记录（记录锁存在于包括主键索引在内的唯一索引并且精准匹配中，锁定单条索引记录。）

            2、gap-lock锁 （间隙锁，锁定一个区间） （间隙锁存在于非唯一索引中，锁定开区间范围内的一段间隔，它是基于临键锁实现的。）
            3、next-key Lock (记录锁+间隙锁 锁定行记录+区间)
                （临键锁存在于非唯一索引中，该类型的每条记录的索引上都存在这种锁，它是一种特殊的间隙锁，锁定一段左开右闭的索引区间）

            InnoDB的默认事务隔离级别是RR，在这种级别下，如果你使用select ... in share mode或者select ... for update语句，
            那么InnoDB会使用临键锁，因而可以防止幻读；但即使你的隔离级别是RR，
            如果你这是使用普通的select语句，那么InnoDB将是快照读，不会使用任何锁，因而还是无法防止。

    4、意向锁

    1、产生原因
    解决表锁与之前可能存在的行锁冲突，避免为了判断表是否存在行锁而去扫描全表的系统消耗。
    2、意向锁加锁规则
    事务在获取行级 S 锁之前，必须获取其对应表的 IS 或 IX 锁
    事务在获取行级 X 锁之前，必须获取其对应表的 IX 锁

    3、作用
    一种快速判断手动加的表锁与之前可能存在的行锁冲突的机制。（数据库在执行事务过程中，更新数据时会帮我们自动加行锁），数据库在加行锁前要先加意向互斥锁。意向互斥锁是一种表锁。

    4、例子分析
    事务 A 锁住了表中的一行，让这一行只能读，不能写。之后，事务 B 申请整个表的写锁。

    如果事务 B 申请成功，那么理论上它就能修改表中的任意一行，这与 A 持有的行锁是冲突的。

    数据库需要避免这种冲突，就是说要让 B 的申请被阻塞，直到 A 释放了行锁。

    数据库要怎么判断这个冲突呢？

    step1：判断表是否已被其他事务用表锁锁表
    step2：判断表中的每一行是否已被行锁锁住。（注意step2，这样的判断方法效率实在不高，因为需要遍历整个表）

    于是就有了意向锁。

    在意向锁存在的情况下，事务 A 必须先申请表的意向互斥锁，成功后再申请一行的行锁。

    在意向锁存在的情况下，上面的判断可以改成

    step1：不变
    step2：发现表上有意向互斥锁，说明表中有些行被行锁锁住了，因此，事务 B 申请表的写锁会被阻塞。


    5、插入意向锁

    插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁。该锁用以表示插入意向，
    当多个事务在同一区间（gap）插入位置不同的多条数据时，事务之间不需要互相等待。假设存在两条值分别为 4 和 7 的记录，
    两个不同的事务分别试图插入值为 5 和 6 的两条记录，每个事务在获取插入行上独占的（排他）锁前，都会获取（4，7）之间的间隙锁，
    但是因为数据行之间并不冲突，所以两个事务之间并不会产生冲突（阻塞等待）。

    插入意向锁特性：
    插入意向锁是一种特殊的间隙锁 —— 间隙锁可以锁定开区间内的部分记录。
    插入意向锁之间互不排斥，所以即使多个事务在同一区间插入多条记录，只要记录本身（主键、唯一索引）不冲突，
    那么事务之间就不会出现冲突等待。

    ！！！  需要强调的是，虽然插入意向锁中含有意向锁三个字，但是它并不属于意向锁而属于间隙锁，因为意向锁是表锁而插入意向锁是行锁。

    说明：
    我甚至可以简单理解为，插入意向锁是为了避免普通间隙锁导致的并发插入问题才引入的，其实就是告诉其它事务，
    我是一把插入意向锁，我的权利比普通间隙锁大，你们可以不用管它，想怎么插入，就怎么插入吧。


8、死锁概念：
    是指两个或两个以上的进程在执行过程中,
    因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去.
    此时称系统处于死锁状态或系统产生了死锁,这些永远在互相等竺的进程称为死锁进程.
    表级锁不会产生死锁.所以解决死锁主要还是针对于最常用的InnoDB.


    demo1：2.2 锁申请级别不够出现的死锁的例子
    session 1                                           session 2
    begin;	                                            begin;


    select au_name from authors where au_id=1 lock for share mode；


                                                select au_name from authors where au_id=1 lock for share mode；

    update authors set au_name=‘newname’ where au_id=1;



                                                update authors set emal=‘newemal@163.com’ where au_id=1;


    分析：开始两个事务由于上的都是共享锁，所以在对au_id=1加锁都是成功的，
    但是当session1去update au_id=1为记录时默认申请的是排它锁，由于排它锁与共享锁互斥所以等待，
    同样session1的互斥锁也阻塞了session2 的update语句造成两个事务互相等待而造成死锁。

    解决方案：在事务中如果需要更新数据就需要上对应级别的锁，
    即排它锁；而不应该先申请共享锁，update的时候再申请排它锁，否则就会出现上述的死锁情况。


    1、死锁分析
            1、可以用show engine innodb status，查看最近一次死锁日志，找出死锁SQL，并分析死锁日志

    2、如何避免死锁
            2、为表添加合理的索引，如果不走索引将会为表的每一行记录加锁，死锁的概率就会大大增大；
            3、避免大事务，尽量将大事务拆成多个小事务来处理；因为大事务占用资源多，耗时长，与其他事务冲突的概率也会变高；
            4、设置锁等待超时参数：innodb_lock_wait_timeout，这个参数并不是只用来解决死锁问题，
                在并发访问比较高的情况下，如果大量事务因无法立即获得所需的锁而挂起，会占用大量计算机资源，
                造成严重性能问题，甚至拖跨数据库。我们通过设置合适的锁等待超时阈值，可以避免这种情况发生
            5、上线前充分压测 和代码review

9、一致性非锁定读

        1、一致性非锁定读 是指InnoDB存储引擎通过行版本控制的方式来读取当前执行时间数据库中的数据。
        如果读取的行正在执行DELETE或UPDATE操作，这时读取操作不会因此去等待行上锁的释放。相反的，
        InnoDB引擎会读取行的一个快照数据。
        流程：
            1、sql query  -》 XLocked  -〉 直接返回 （Snapshot Data） (快照数据)

            之所以称为非锁定度，是因为不需要等待访问数据行上的X锁的释放。快照数据是指该行之前版本的数据，通过undo段来实现（undo用来在事务中回滚数据）。

            说明： 快照数据是指该行的之前版本的数据，通过undo段来实现，而 undo用来在事务中回滚数据，因此读取
            快照数据没有额外的开销。

        2、一致性非锁定读机制，极大的提高了数据库的并发性。在InnoDB引擎默认的设置下，是默认的读取方式。但是快照数据可能不止一个，在不同的事务隔离级别中，快照数据读取的定义不同。
            1、在READ COMMITTED 在 读已提交隔离级别下，非锁定读总是读取被锁定行的最新一份的快照数据。
            2、在REPEATABLE READ 在可重复读隔离级别下，非一致性锁定读总是读取事务开始时的行数据版本。

            demo:
                会话a  											会话B
                 begin(开启事务)
            1、 select * from parent where id = 1
                                                                begin 开启事务
                                                                update paraent set id = 3 where id = 1;

            2、	 select * from parent where id = 1;
                                                                Commit

            3、	 select * from parent where id =1;

                 Commit


            总结 ：
                1、在 读已提交隔离级别中，会话a  步骤3 查询不到数据，因为 当前行被锁定，读取改行版本最新的一个快照数据 id已经变成了3
                2、在 可重复读隔离级别中，总是读取事务开始的行快照数据。因此 会话A的步骤3 还是可以读取出id=1 的数据的。

10、一致性锁定读
	 在InnnoDB 的默认配置下，事务的隔离级别 为可重复读，使用的是一致性非锁定读，但是 在某些情况下，需要对数据的读取操作进行加锁以保证数据逻辑的一致性。
	 InnnoDB 引擎，通过
	 1、select  for  update (添加X锁)
	 2、select lock in share mode  （添加S锁）

	  支持对只读操作的 一致性锁定读。
	 	select for update 会给 当前读取的行加上一个 X锁（排它锁），其他事务不能对已锁定的行加锁 只能阻塞。


 11、什么是MVCC?
    MVCC 多本版本并发控制，在Innodb引擎默认的"可重复读"隔离级别中，通过MVCC 来实现数据的可重复读，提升事务的并发读取能力。

    1、Innodb 中 每开启一个事务，我们都会从数据库中获得一个事务 ID（也就是事务版本号），
        这个事务 ID 是自增长的，通过 ID 大小，我们就可以判断事务的时间顺序。
    2、InnoDB 的叶子段存储了数据页，数据页中保存了行记录，而在行记录中有一些重要的隐藏字段：
       1、 DB_ROW_ID：6-byte，隐藏的行 ID，用来生成默认聚簇索引。如果我们创建数据表的时候没有指定聚簇索引，这时 InnoDB 就会用这个隐藏 ID 来创建聚集索引。采用聚簇索引的方式可以提升数据的查找效率。
       2、 DB_TRX_ID：6-byte，操作这个数据的事务 ID，也就是最后一个对该数据进行插入或更新的事务 ID。
       3、 DB_ROLL_PTR：7-byte，回滚指针，也就是指向这个记录的 Undo Log 信息。
    3、InnoDB 将行记录快照保存在了 Undo Log 里，我们可以在回滚段中找到它们

    2. 在 可重复读（REPEATABLE READ） 隔离级别下， InnoDB 的 MVCC 是如何工作的
       1、Select   InnoDB 会根据以下两个条件检查每行记录：
        InnoDB只查找版本早于当前事务版本的数据行（也就是，行的系统版本号小于或等于事务的系统版本号），这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的。
        行的删除版本要么未定义，要么大于当前事务版本号。这可以确保事务读取到的行，在事务开始之前未被删除
        只有符合上述两个条件的记录，才能返回作为查询结果。
       2、插入（INSERT）InnoDB为新插入的每一行保存当前系统版本号作为行版本号。
       3、删除（DELETE） InnoDB为删除的每一行保存当前系统版本号作为行删除标识。
            删除在内部被视为更新，行中的一个特殊位会被设置为已删除。
       4、更新（UPDATE） InnoDB为插入一行新记录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识


11、分布式事务
	分布式事务指的是允许多个独立的事务资源参与到一个全局的事务中。全局事务必须要求在其中的所有参与事务要么都提交，要么都回滚。在使用分布式事务中，InnoDB 存储引擎的事务隔离级别必须设置 Serializable

	1、MySQL 数据库也支持分布式事务
		InnoDB 引擎提供了对XA事务的支持，并且通过XA事务来支持分布式事务的实现。

		XA 事务 由一个或者多个资源管理器，一个事务管理器以及一个应用程序组成。
		分布式事务使用两段水提交的方式。
		1、在第一阶段，所有参与全局事务的节点都开始准备，告诉事务管理器他们准备好了。
		2、在第二阶段，事务管理器告诉资源管理器执行ROLLBACK 还是COMMIT。如果一个节点显示不能提交，则所有的节点都被告知要回滚。



12、Mysql 主从复制
	1、 复制是Mysql 数据库提供的一种高可用高性能的解决方案。mysql 的主从复制 是数据可以从一个Mysql 数据库服务器主节点复制到一个或者多个从节点。MySQL 默认采用异步复制方式。
	2、主从复制形式
		1、一主一从
		2、一主多从 （提高系统读性能）
		3、多主一从
	3、主从复制原理
		主从复制涉及三个线程 ，一个运行在主节点（log dump thread）,两个运行在从线程（I/O 线程，SQL线程）
		步骤：
		1、当从节点连接主节点时，主节点会创建一个log dump 线程，用于发送bin-log的内容。在读取bin-log中的操作时，此线程会对主节点上的bin-log加锁，当读取完成，甚至在发动给从节点之前，锁会被释放。

		2、当从节点上执行`start slave`命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的bin-log。I/O线程接收到主节点binlog dump 进程发来的更新之后，保存在本地relay-log中。
		3、SQL线程负责读取relay log中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。
	4、主从好处
		1、读写分离。让主库负责写，从库负责读，提高系统系能
		2、高可用和架构扩展。（如果是单机部署数据库，就会导致I/O访问频率过高。有了主从复制，增加多个数据存储节点，将负载分布在多个从节点上，降低单机磁盘I/O访问的频率，提高单个机器的I/O性能）


13、索引优化 和联合索引
	1、建索引的几大原则
		1.最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。

		2.=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式。

		3.尽量选择区分度高的列作为索引，区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。

		4.索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’)。

		5.尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可。

	2、MySQL提供了Explain可以分析SQL语句。Explain 用来分析 SELECT 查询语句。

	Explain比较重要的字段有：

	select_type : 查询类型，有简单查询、联合查询、子查询等
	key : 使用的索引
	rows : 预计需要扫描的行数
	possiable_key ： 可能用到的索引
	type: 扫描方式
	    ‘Tips：常见的扫描方式
	        system：系统表，少量数据，往往不需要进行磁盘IO
	        const：常量连接
	        eq_ref：主键索引(primary key)或者非空唯一索引(unique not null)等值扫描
	        ref：非主键非唯一索引等值扫描
	        range：范围扫描
	        index：索引树扫描 * ALL：
	        全表扫描(full table scan)

	        type扫描方式由快到慢  system > const > eq_ref > ref > range > index > ALL

	3、慢查询日志
    慢查询日志用来记录在 MySQL 中执行时间超过指定时间的查询语句。通过慢查询日志，可以查找出哪些查询语句的执行效率低，以便进行优化
	具体指运行时间超过long_query_time值的SQL，则会被记录到慢查询日志中

	MySQL 慢查询日志是排查问题的 SQL 语句，以及检查当前 MySQL 性能的一个重要功能。如果不是调优需要，一般不建议启动该参数，因为开启慢查询日志会或多或少带来一定的性能影响。


	show variables like '%slow_query_log%';
		* slow_query_log //是否开启，默认关闭，建议调优时才开启
	* slow_query_log_file //慢查询日志存放目录



14、分库分表
    导语：
    随着业务的增长，mysql中保存的数据会越来越多。此时，数据库很容易成为系统性能的一个瓶颈，单机存储容量、IO、CPU处理能力都有限，
    当单表的数据量达到1000W或100G以后，库表的增删改查操作面临着性能大幅下降的问题。分库分表是一种解决办法。

   1、 分库分表实际上就是对数据进行切分。我们一般可以将数据切分分为两种方式：垂直（纵向）切分和水平（横向）切分。

   2、垂直切分 （垂直切分常见有垂直分库和垂直分表两种。）

       1. 垂直分库
            垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库。思想与”微服务治理“类似，将系统拆分为多个业务，每个业务使用自己单独的数据库。
            （我们现在的微服务就是采用该模式，用户库，活动库，酬勤库）
       2、垂直分表
            垂直分表是基于数据库中的表字段来进行的。业务中可能存在一些字段比较多的表，表中某些字段长度较大。这些长字段我们又只是偶尔需要用到。
            这时候我们就可以考虑将表进行垂直拆分了。将某些不常用的，但是长度又很大的字段拎出来放到另外一张表。

            （例如用户的登录信息，和 用户基础信息表分离）
            原因：MySQL底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外的性能开销。另外数据库以行为单位将数据加载到内存中，
                这样表中字段长度较短且访问频率较高，内存能加载更多的数据，命中率更高，减少了磁盘IO，从而提升了数据库性能。
        3. 垂直切分优缺点
        优点：

        1. 不同系统可以使用不同的库表，解决业务系统层面的耦合，业务清晰

        2. 高并发场景下，垂直切分一定程度地提升IO、数据库连接数，缓解单机硬件资源的瓶颈

   3、水平切分
        单表数据依然过大，存在单库读写、存储性能瓶颈时候，这时候就可以考虑水平切分了。
        水平切分又可以分为库内分表和分库分表。是根据表内数据的内在逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，
        每个表中只包含一部分数据，从而使得单个表的数据量变小，达到分布式的效果。

        1、库内分表
            库内分表就是在同一个db上，将表按照某种条件拆分为多张表。（例如 post 根据帖子id ，把评论分为不同的表）

        2、分库分表
            分库分表就是将表不仅拆分，而且拆分到不同机器上。 （使用比较少）


    3 分库分表带来的问题
        1、事务一致性问题 （分布式事务）
        2、跨节点关联查询 join 问题
            切分之前，系统中很多列表和详情页所需的数据可以通过sql join来完成。
            而切分之后，数据可能分布在不同的节点上，此时join带来的问题就比较麻烦了，考虑到性能，尽量避免使用join查询。

            解决这个问题的一些方法：
                1、a. 全局表：
                2、b. 字段冗余：
                3、c. 数据组装：
                    在系统层面，分两次查询，第一次查询的结果集中找出关联数据id，然后根据id发起第二次请求得到关联数据。最后将获得到的数据进行字段拼装

        (3) 全局主键避重问题
            在分库分表环境中，由于表中数据同时存在不同数据库中，主键平时使用的自增长将无用武之地，
            某个分区数据库自生成的ID无法保证全局唯一。因此需要单独设计全局主键，以避免跨库主键重复问题。

            例如雪花算法


14、update更新语句执行的流程
    1、与select 流程不同，update会涉及两个日志模块，分别是redo log和 bin log
    redo log是InnoDB存储引擎的日志，Server层的日志为bin log。redo log是循环写入，bin log是追加写入，不会覆盖之前的日志
    demo:
    mysql> UPDATE T SET age = age+1 WHERE id = 1;

    1、执行器先找引擎找id=1这行记录。id为主键，引擎通过索引找到记录；
    2、执行器拿到行记录，对age+1，调用引擎写接口，更新数据；
    3、引擎将新记录更新到内存，并将更新记录写入redo log，redo log处于prepare状态，随时可以提交事务；
    4、执行器生成bin log写入磁盘；
    5、执行器调用引擎提交事务接口，把redo log成commit状态，更新完成。

    为了让两份日志逻辑一致，上述操作使用了二阶段提交


15、mysql日志
	MySQL的日志主要有：二进制日志、通用查询日志、慢查询日志、错误日志、事务日志等。

1、binlog日志
	binlog是Mysql sever层维护的一种二进制日志，用来记录操作MySQL数据库中的写入性操作（包括增删改，但不包括查询），

	1、二进制的主要作用有两个：
		1、复制，配置了主从复制的时候，主服务器会将其产生的二进制日志发送到slave端，slave端会利用这个二进制日志的信息在本地重做，实现主从同步。
		2、恢复，因为二进制日志包含了备份以后的所有更新，因此可以用于最大限度地恢复数据库。因此，建议二进制日志单独保存到一个磁盘上，以便磁盘损坏以后进行数据恢复。
  	2、binlog的格式有三种：STATEMENT、ROW、MIXED 。下面我们来了解下这三种格式的区别：
		1、STATMENT：基于SQL语句的复制(statement-based replication, SBR)，记录的是SQL语句本身，不记录SQL语句对应每行的数据变化，即你写的什么SQL语句就记录什么。



		优点：产生的日志较少

		2、ROW：基于行的复制(row-based replication, RBR)，记录的是每行实际数据的变更

			特点：因此它会产生大量的日志，可读性差，但是它准确性强，能精准记录数据的变更。

			例如：例如 “update stu set age=16” 这条语句意思是将stu表中所有行的age列的值修改为16，对应就有很多行数据的变更。如果是ROW格式，那么binlog记录的就不是这条SQL语句本身（DDL和DCL语句记录的是本身），而是对应到每行的实际数据变更操作，假如stu表有100行，那么就会记录100条操作
	3、MIXED：混合模式复制(mixed-based replication, MBR)，以上两种模式的混合使用，由MySQL根据执行的SQL语句选择日志的记录格式。



2、错误日志 error 日志
	MySQL的错误日志记录了 mysqld 启动和停止时，以及服务器在运行过程中出现的任何严重错误。

	一般在my.ini中配置
3、redo.log
	可以结合实现事务的原子性，和持久性来介绍。

	例如事务的实现原理，就可以介绍原子性和持久性，介绍redo.log 和undo.log

	1、redo.log
		1、Redo log包括两部分，重做日志缓冲（redo log buffer）和重做日志文件（redo log file），前者是易失的缓存，后者是持久化的文件。
			举一个事务的例子：

			步骤1:begin;
			步骤2:insert into t1 …r
			步骤3:insert into t2 …
			步骤4:commit;
			这个事务的写入过程实际拆解如下：

			begin ->insert =>  更新数据到缓冲池 -》 写入redo log buffer =>  insert =>  更新数据到缓冲池 -》 写入redo log buffer  并将redo log buffer 写入redo log file 中 redo log处于prepare阶段。
			=》 写入binlog =〉 提交事务，事务处于commit状态

		重点关注在这个事务提交前，将 redo log 的写入拆成了两个步骤，prepare 和 commit，这就是"两阶段提交”。

		实际上，两阶段提交是分布式系统常用的机制。MySQL使用了两阶段提交后，也是为了保证事务的持久性。Redo log 和bingo 有一个共同的数据字段，叫 XID,崩溃恢复的时候，会按顺序扫描 redo log。
		1、假设在写入binlog前系统崩溃，那么数据库恢复后顺序扫描 redo log，碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务，而且binlog也没写入，所以事务就直接回滚了。
		2、假设在写入binlog之后，事务提交前数据库崩溃，那么数据库恢复后顺序扫描 redo log，碰到既有 prepare、又有 commit 的 redo log，就直接提交，保证数据不丢失。

	 注意！！ mysql 就是通过以上 redo log 来实现持久性的。

	 	2、redo log和binlog的不同。
	 		1、产生位置不同。
				redo log是innodb的存储引擎产生的，而binlog是数据库的server层实现的。换句话说，如果你使用MySQL，换其他存储引擎，那么可能没有redo log，但是还是会有binlog。
			2、日志记录的内容形式不同。
				binlog是一种逻辑日志，记录对应的SQL语句，而redo log记录了物理日志，是针对每个数据页的修改。
			3、日志写入磁盘时间不同。
				binlog只有在事务提交后完成一次写入，对于一个事物而言，在binlog中只有一条记录。而redo log在事务进行中不断被写入，而且是并发写入的，不是顺序写入的。
			4、保存方式不同。
				redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。


4、undo log
	Undo log保证了事务的原子性。undo log有两个作用：提供回滚和多个行版本控制(MVCC)。

	1、在对数据库进行修改时，innoDB引擎除了会产生redo log，还会产生undo log。InnoDB实现回滚，靠的是undo log：当事务对数据库进行修改时，InnoDB会生成对应的undo log；如果事务执行失败导致事务需要回滚，就利用undo log中的信息将数据回滚到修改之前的样子。
			比如一条 ` INSERT语句，对应一条 DELETE 的 undo log ，对于每个 UPDATE 语句，对应一条相反的 UPDATE 的undo log 。
	2、undo log还要另外一个重要作用，就是用于mvcc中，进行多版本控制，也就是实现事务隔离性的基础，当用户读取一行记录时，如果这个记录已接被其他事务占用，那么当前事务就可以通过undo读取之前的行版本信息，用来实现非锁定读取，就是“快照读”。

	所以redo log是一种物理日志（数据页的修改），而undo log是一种逻辑日志（数据记录）。

	补充：一致性的实现 （我们可以认为原子性、持久性和隔离性都是为了实现事务的一致性。）




5、脏读、不可重复读和幻读的区别，以及如何解决幻读
	1、脏读（读取未提交的数据）
	2、不可重复读（前后数据多次读取，结果集内容不一致）
		不可重复读即当事务 A 按照查询条件得到了一个结果集，这时事务 B 对事务 A查询的结果集数据做了修改操作，之后事务 A 为了数据校验继续按照之前的查询条件得到的结果集与前一次查询不同，导致不可重复读取原始数据。
	3、幻读（前后数据多次读取，结果集数量不一致）
		错误的理解：幻读是指当事务 A 按照查询条件得到了一个结果集，这时事务 B 对事务 A 查询的结果集数据做新增操作，之后事务 A 继续按照之前的查询条件得到的结果集平白无故多了几条数据，好像出现了幻觉一样。
		我的理解：
			幻读，并不是说两次读取获取的结果集不同，幻读侧重的方面是某一次的 select 操作得到的结果所表征的数据状态无法支撑后续的业务操作。更为具体一些：select 某记录是否存在，不存在，准备插入此记录，但执行 insert 时发现此记录已存在，无法插入，此时就发生了幻读。

		其实 RR 也是可以避免幻读的，通过对 select 操作手动加 行X锁（SELECT ... FOR UPDATE 这也正是 SERIALIZABLE 隔离级别下会隐式为你做的事情），同时还需要知道，即便当前记录不存在，比如 id = 1 是不存在的，当前事务也会获得一把记录锁（因为InnoDB的行锁锁定的是索引，故记录实体存在与否没关系，存在就加 行X锁，不存在就加 next-key lock间隙X锁），其他事务则无法插入此索引的记录，故杜绝了幻读。

	Mysql得到默认隔离级别RR，如果MVCC解决不可重复读，但是存在幻读的情况。
		1、InnoDB 中 MVCC 实现
			在 InnoDB 中为每行增加两个隐藏的字段，分别是该行数据创建时的版本号和删除时的版本号，这里的版本号是系统版本号（可以简单理解为事务的 ID），每开始一个新的事务，系统版本号就自动递增，作为事务的 ID 。通常这两个版本号分别叫做创建时间和删除时间。

			1、INSERT InnoDB 为新插入的每一行保存当前系统版本号作为版本号。
			2、SELECT
				只会查找版本早于当前事务版本的数据行（行的系统版本号小于或等于事务的系统版本号)，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的。

行锁的算法
	1、记录锁(Record Lock) 当我们的查询能命中一条记录的时候，InnoDB就会使用记录锁，锁住所命中的这一行记录。
	2、间隙锁(Gap Lock)
		我们的查询没有命中记录的时候，这时候InnoDB就会加上一个间隙锁。

	3、	临键锁，是记录锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间。


	总结：
	1、唯一索引只有锁住多条记录或者一条不存在的记录的时候，才会产生间隙锁，指定给某条存在的记录加锁的时候，只会加记录锁，不会产生间隙锁；
	2、普通索引不管是锁住单条，还是多条记录，都会产生间隙锁；
	3、间隙锁会封锁该条记录相邻两个键之间的空白区域，防止其它事务在这个区域内插入、修改、删除数据，这是为了防止出现 幻读 现象；


一、你说说一条查询SQL的执行过程？

1、首先客户端发送请求到服务端，建立连接。
2、服务端先看下查询缓存是否命中，命中就直接返回，否则继续往下执行。
3、接着来到解析器，进行语法分析，一些系统关键字校验，校验语法是否合规。
4、然后优化器进行SQL优化，比如怎么选择索引之类，然后生成执行计划。
5、最后执行引擎调用存储引擎API查询数据，返回结果。


二、你说说一条更新SQL的执行过程？

1、首先客户端发送请求到服务端，建立连接。
2、服务端先看下查询缓存，对于更新某张表的SQL，该表的所有查询缓存都失效。
3、接着来到解析器，进行语法分析，一些系统关键字校验，校验语法是否合规。
4、然后优化器进行SQL优化，比如怎么选择索引之类，然后生成执行计划。
5、执行引擎去存储引擎查询需要更新的数据。
6、存储引擎判断当前缓冲池中是否存在需要更新的数据，存在就直接返回，否则去从磁盘加载数据。
7、执行引擎调用存储引擎API去更新数据。
8、存储引擎更新数据，同时写入undo_log、redo_log信息。
执行引擎写binlog，提交事务，流程结束。

1、limit 为什么会影响性能。

	1、MySQL的分页查询通常通过limit来实现。对于小的偏移量，直接使用limit来查询没有问题，
	但是随着数据量的增大，越往后分页，limit的数据的偏移量就越大，速度也会越来越明显

	 问题sql ：
	 		select * from product limit 40000,20.

	2、优化
		1、优化的思想 避免数据量大的时候，扫描过多的数据记录。

			1、利用 id >= 的形式
				select * from product where id >= (select id from product limit 4090000,1) limit 20
			2、利用join

				select * from product a join (select id from product limit 400000,20) b on a.id = b.id



		可以优化的原因：
			1、通过索引字段进行定位，然后才取出来相应的内容，减少了回表查询的次数。提升查询优化的效率。

			在实际的项目中，可以利用策略模式的方式去处理分页：
			例如，每页100条数据，判断如果是100页以内，就使用基本的分页方式，如果大于100，则使用子查询的分页方式。

16、分析sql语句的执行顺序
	1、一般，WHERE在前，GROUP BY在后，即先进行筛选，然后进行分组；
	2、HAVING只能跟在GROUP BY之后，对分组后的聚合结果进行筛选；HAVING的前提是分组；WHERE在最前，最先对原始数据进行一遍筛选；
	3、WHERE的条件里只能用已有的列进行条件判断，不允许使用聚合函数。HAVING之后可以允许使用聚合函数


	当一个查询语句同时出现了where,group by,having,order by的时候，执行顺序和编写顺序是：
	1.执行where xx对全表数据做筛选，返回第1个结果集。
	2.针对第1个结果集使用group by分组，返回第2个结果集。
	3.针对第2个结果集中的每1组数据执行select xx，有几组就执行几次，返回第3个结果集。
	4.针对第3个结集执行having xx进行筛选，返回第4个结果集。
	5.针对第4个结果集排序。


17、MySql的连接left join, inner join, full join

    　　1、left join （左连接）：返回包括左表中的所有记录和右表中连接字段相等的记录。
    　　2、right join （右连接）：返回包括右表中的所有记录和左表中连接字段相等的记录。
    　　3、inner join （等值连接或者叫内连接）：只返回两个表中连接字段相等的行。
    　　4、full join （全外连接）：返回左右表中所有的记录和左右表中连接字段相等的记

18、join on and 和 join on where 	区别

        总结：
        在使用left join 时，on和where条件的区别：
        1：on条件是在生成临时表时使用的条件，它不管on中的条件是否为真，都会返回左边表中的记录。
        2：where条件是在临时表生成好后，再对临时表进行过滤的条件。这时已经没有left join的含义（必须返回左边表的记录）了，条件不为真的就全部过滤掉。
        3: inner join是在生成临时表以后再进行过滤的，而且对左表和右表都起作用。


        select * from dept left join emp on dept.deptno = emp.deptno;
        +----+--------+--------+----+------+-----+--------+
        | id | deptno | name   | id | name | sex | deptno |
        +----+--------+--------+----+------+-----+--------+
        |  2 |      2 | 运营部 |  1 | 小张 | 男  |      2 |
        |  1 |      1 | 技术部 |  2 | 小王 | 男  |      1 |
        |  3 |      3 | 市场部 |  3 | 小李 | 女  |      3 |
        |  1 |      1 | 技术部 |  4 | 小杨 | 男  |      1 |
        |  1 |      1 | 技术部 |  5 | 小郑 | 男  |      1 |
        +----+--------+--------+----+------+-----+--------+

        select * from dept left join emp on dept.deptno = emp.deptno and emp.sex ='男';
        +----+--------+--------+------+------+------+--------+
        | id | deptno | name   | id   | name | sex  | deptno |
        +----+--------+--------+------+------+------+--------+
        |  2 |      2 | 运营部 |    1 | 小张 | 男   |      2 |
        |  1 |      1 | 技术部 |    2 | 小王 | 男   |      1 |
        |  1 |      1 | 技术部 |    4 | 小杨 | 男   |      1 |
        |  1 |      1 | 技术部 |    5 | 小郑 | 男   |      1 |
        |  3 |      3 | 市场部 | NULL | NULL | NULL | NULL   |
        +----+--------+--------+------+------+------+--------+

        on条件是在生成临时表时使用的条件，它不管on中的条件是否为真，都会返回左边表中的记录。显然左连接再加上新的条件:emp.sex='男’，筛选第五行记录。

        Where:

         select * from dept left join emp on dept.deptno = emp.deptno where emp.
        sex ='男';
        +----+--------+--------+----+------+-----+--------+
        | id | deptno | name   | id | name | sex | deptno |
        +----+--------+--------+----+------+-----+--------+
        |  1 |      1 | 技术部 |  2 | 小王 | 男  |      1 |
        |  1 |      1 | 技术部 |  4 | 小杨 | 男  |      1 |
        |  1 |      1 | 技术部 |  5 | 小郑 | 男  |      1 |
        |  2 |      2 | 运营部 |  1 | 小张 | 男  |      2 |
        +----+--------+--------+----+------+-----+--------+
        where是生成临时表以后再进行过滤，对左右表都进行筛选。而and后面的语句如果是对left join中的左表进行过滤将不起任何作用，对右表进行过滤的话，那么左表还是返回所有行，只是右表会被过滤掉一部分行。


        inner join
           select * from dept inner join emp on dept.deptno = emp.deptno and emp.sex ='男';
        +----+--------+--------+----+------+-----+--------+
        | id | deptno | name   | id | name | sex | deptno |
        +----+--------+--------+----+------+-----+--------+
        |  1 |      1 | 技术部 |  2 | 小王 | 男  |      1 |
        |  1 |      1 | 技术部 |  4 | 小杨 | 男  |      1 |
        |  1 |      1 | 技术部 |  5 | 小郑 | 男  |      1 |
        |  2 |      2 | 运营部 |  1 | 小张 | 男  |      2 |
        +----+--------+--------+----+------+-----+--------+

        select * from dept inner join emp on dept.deptno = emp.deptno where emp.sex ='男';
        +----+--------+--------+----+------+-----+--------+
        | id | deptno | name   | id | name | sex | deptno |
        +----+--------+--------+----+------+-----+--------+
        |  1 |      1 | 技术部 |  2 | 小王 | 男  |      1 |
        |  1 |      1 | 技术部 |  4 | 小杨 | 男  |      1 |
        |  1 |      1 | 技术部 |  5 | 小郑 | 男  |      1 |
        |  2 |      2 | 运营部 |  1 | 小张 | 男  |      2 |
        +----+--------+--------+----+------+-----+--------+
        内连接inner join on and 或者on where不管是对左表还是右表进行过滤，实际都是在生成临时表以后再进行过滤的，而且对左表和右表都起作用，这与左连接left join有本质的区别！！
