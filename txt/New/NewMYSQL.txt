1、MyIsam 和 Innodb区别
    1. InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；
    2. InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败；
    3. InnoDB 是聚集索引，MyISAM 是非聚集索引。聚簇索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。
        但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。
        而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。
    4. InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描。而MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；
    5. InnoDB 最小的锁粒度是行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。
        这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；

    MyISAM引擎中 也是使用b+tree作为索引数据结构，叶子结点的data域存放的是数据记录的地址。
    myIsam的索引文件，仅仅保存数据的记录
    myIsam 中，主索引和辅助索引在结构上没有区别，都是存放地址，只是主索引要求key是唯一的，而辅助索引的key可以重复。
    myIsam主键索引比较好理解，B+Tree里面的叶子节点的key存储的是索引值，value存储的是相应data数据的指针。

    MyISAM索引原理：
    	1、采用非聚簇索引-MyISAM myi索引文件和myd数据文件分离，索引文件仅保存数据记录的指针地址。叶子节点data域存储指向数据记录的指针地址。
    	2、MyISAM索引按照B+Tree搜索，如果指定的Key存在，则取出其data域的值，然后以data域值-数据指针地址去读取相应数据记录
    	3、辅助索引和主索引在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复


    Innodb索引原理：
    	1、B+Trees 非叶子节点只存储 key，不存储 data，这可以大大提高每个节点存储 key 的个数,降低了高度；
    	2、data 都存储在叶子节点中的；
    	3、B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针。
    		提高区间访问的性能，例如如果要查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，不用从头再查询一次，极大提到了区间查询效率。

    聚簇索引和非聚簇索引
    	1、区别。
    		1、聚簇索引：将数据存储和索引放到了一起，找到索引也就找到了数据。
    		2、非聚簇索引：数据存储和索引分开存放，索引结构的叶子节点指向了数据对应的行。

    	2、
    		1、MyISAM 不管是主键索引，还是二级索引使用的都是非聚簇索引。
    		2、InnoDB 主键使用的是聚簇索引。表数据是和主键一起存储的。二级索引的叶结点存储行的主键值，需要根据
    		   主键的值进行回表查询。

2、索引覆盖
    1、索引覆盖，是指从非主键索引就能查到的记录，而不需要查询主键索引中的记录，避免了回表的产生，减少了数的搜索次数，提升查询的性能

    demo: student 表，现在name上建立有索引，但是年龄和name经常需要一起查询，因此可以删除name索引，建立name_age索引，
    select age,name from student时 就可以直接获取name,和age，而不需要在进行回表。

3、聚簇索引和非聚集索引（辅助索引/二级索引）
   1、聚簇索引（clustered index）不是单独的一种索引类型，而是一种数据存储方式。这种存储方式是依靠B+树来实现的，
   根据表的主键构造一棵B+树且B+树叶子节点存放的都是表的行记录数据时，方可称该主键索引为聚簇索引。
   聚簇索引也可理解为将数据存储与索引放到了一块，找到索引也就找到了数据。

   主键索引里面的存储情况如下图所示，叶子节点里面的key是索引的信息，value是数据表里面该索引对应行的数据信息。


   2、非聚集索引。
   在聚簇索引之外创建的索引（不是根据主键创建的）称之为辅助索引，
   辅助索引访问数据总是需要二次查找。辅助索引叶子节点存储的不再是行数据记录，
   而是主键值。首先通过辅助索引找到主键值，然后到主键索引树中通过主键值找到数据行。：
   数据和索引是分开的，B+树叶子节点存放的不是数据表的行记录。

    这种索引在进行存储的时候，虽然说节点依然是key-value的结构，key对应的是相应的索引，但是value对应的却是主键索引的值

4、联合索引和最左匹配
    1、在MySQL建立联合索引时会遵守最左前缀匹配原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。
    2、最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，
    比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，
        如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。
    3、 =和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式


5、MYSQL 索引 （B+索引）
    总结：为什么使用B++ 树作为索引的数据结构
        1、先介绍，二叉树，二叉搜索树(avl)，红黑树，b树，b++存放数据优点。

        1、平衡二叉树
            平衡二叉树又被称为AVL树，本质还是二叉查找树
            平衡二叉树是一颗空树或者它的左右两个子树的高度差的绝对值不超过1，并且左右子树也是平衡树
            非叶子节点值大于左子节点值而小于右子节点值
            非叶子节点最多拥有两个子节点
        2、红黑树
            每个节点要么是红色要么是黑色
            根节点是黑色
            每个叶子节点(NIL)是黑色
            每个红色节点的两个子节点一定为黑色
            任意一个节点到每个叶子节点的路径都包含数量相同的黑色节点
            如果一个节点存在黑子节点，那么该节点肯定有两个子节点

        4、B树又叫平衡多路查找树，
            每个节点中，都包含数据(key和data域)和指针，相互间隔
            叶节点具有相同的深度，叶节点的指针为空
            节点中的数据索引从左到右递增排列
            所有索引元素不重复
            所有叶子节点均在同一层、叶子节点除了包含了关键字和关键字记录的指针外也有指向其子节点的指针只不过其指针地址都为null对应下图最后一层节点的空格子;

        5、B+树
            非叶子节点中不存储data，只存储索引，可以放更多的索引
            叶子节点包含所有索引字段
            叶子节点包含数据(key和data域)和指针
            叶子节点用指针连接，提高区间访问的性能

      1、B树和B+树特点和区别：
      	1、B树和B+树都是多路平衡查找树，每个节点有多个子节点。
      	2、B树每个节点既存放key又存放data，B+树非叶子结点不存放数据，叶子结点存放key和数据。
      		因此B+树更适合外部存储（磁盘存储），一页中可以存放更多的索引结点，降低树的高度，减少磁盘IO。
      	3、B+树在叶子结点通过链表方式链接，因此只需要扫描叶子结点就可以完成范围和顺序查找。而b树，需要进行中序遍历。因此B+树效率更高
      	4、B+树查询数据时必须查找到叶子结点，时间复杂度位logn ，更加稳定。b树由于每个节点存储元素位置，只要找到即可，不管元素的位置，时间复杂度最好位O（1），最坏位logn
      	因此，B+树查找更加稳定。

      2、索引为什么不用 AVL树和红黑树。
        AVL树和红黑树基本都是存储在内存中才会使用的数据结构。在大规模数据存储的时候，每个节点最多有两个子节点。
        红黑树往往出现由于树的深度过大而造成磁盘 IO 读写过于频繁，进而导致效率低下的情况。

       3、Mysql单表最多多大数据会出现性能问题。一般io操作都1-3次。
         1、数据存储方式：
         	非叶子节点：主键+指针
         	叶子节点：数据
         2、数据量预估。
          	1、假设咱们一行数据大小为1K，那么一页就能存16条数据，也就是一个叶子节点能存16条数据；
           		再看非叶子节点，假设主键ID为bigint类型，那么长度为8B，指针大小在Innodb源码中为6B，一共就是14B，那么一页里就能够存储16K/14=1170个(主键+指针)，
         	2、那么一颗高度为2的B+树能存储的数据为：1170*16=18720条，一颗高度为3的B+树能存储的数据为：1170*1170*16=21902400（千万级条）。
         	因此在InnoDB中B+树高度通常为1-3层，它就能知足千万级的数据存储。在查找数据时一次页的查找表明一次IO，因此	经过主键索引查询一般只须要1-3次IO操做便可查找到数据。
         	并且mysql先把第一页夹在到内存中。因此查询数据最多两次i/o即可。

6、事务的隔离级别和 ACID特性
	在 MySQL 中只有使用了 Innodb 数据库引擎的数据库或表才支持事务，事务处理可以用来维护数据库的完整性。

	1、ACID 特性：
		事务的ACID特性:
       1、 原子性(atomicity):一个事务是一个不可分割的最小工作单位，事务中的所有操作要么都做，要么都不做。

       2、 一致性(consistency):事务前后数据的完整性必须保持一致.事务必须是使数据库从一个一致性状态变到另一个一致性状态,一致性与原子性是密切相关的。

       3、 隔离性(isolation):一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的,并发执行的各个事务之间不能互相干扰。有四种隔离级别

       4、· 持久性(durability):指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。

	2、在数据库中，为了有效的保证并发读取数据的正确性，提出了事务隔离级别

        1、Read UnCommitted  未提交读 。（允许脏读，也就是可能读取到其他会话中未提交事务修改的数据）
        2、Read Committed    已提交读 （只能读取到已经提交的数据。但是存在不可重复读的问题）
        3、Repeated Read 	 可重复读 （在同一个事务中内的查询都是和事务开始时候一致的。可重复读隔离级别，是InnoDb 的默认隔离级别。该级别消除了不可重复读，但是存在幻读现象）
        4、Serializable 串行读（完全串行化的读，每次读都需要获得表级的共享锁，读写都会被组塞）
            这个级别的实现很简单，读加共享锁，写加排它锁，读写互斥。使用的是悲观锁的理论，实现比较简单，数据安全，但是并发能力弱

    3、脏读、不可重复读和幻读的区别，以及如何解决幻读
      	1、脏读（读取未提交的数据）
      	2、不可重复读（前后数据多次读取，结果集内容不一致）
      		不可重复读即当事务 A 按照查询条件得到了一个结果集，这时事务 B 对事务 A查询的结果集数据做了修改操作，之后事务 A 为了数据校验继续按照之前的查询条件得到的结果集与前一次查询不同，导致不可重复读取原始数据。
      		Innodb通过MVCC解决不可重复读。
      	3、幻读（前后数据多次读取，结果集数量不一致）
      		错误的理解：幻读是指当事务 A 按照查询条件得到了一个结果集，这时事务 B 对事务 A 查询的结果集数据做新增操作，之后事务 A 继续按照之前的查询条件得到的结果集平白无故多了几条数据，好像出现了幻觉一样。
      		我的理解：
      			幻读，并不是说两次读取获取的结果集不同，幻读侧重的方面是某一次的 select 操作得到的结果所表征的数据状态无法支撑后续的业务操作。更为具体一些：select 某记录是否存在，不存在，准备插入此记录，但执行 insert 时发现此记录已存在，无法插入，此时就发生了幻读。

      			Innodb通过间隙锁解决幻读。

7、MVCC实现原理。
  	1、MVCC，即多版本并发控制，是一种并发控制的方法。
  	在Innodb引擎中主要通过事务的版本号来实现。每行记录除了我们自定义的字段外，还有数据库隐式定义的DB_TRX_ID,DB_ROLL_PTR,DB_ROW_ID等字段。
  		1、DB_TRX_ID 记录创建这条记录/最后一次修改该记录的事务ID
  		2、DB_ROLL_PTR。回滚指针，指向这条记录的上一个版本。
  		3、DB_ROW_ID。隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引
  		4、实际还有一个删除flag隐藏字段, 既记录被更新或删除并不代表真的删除，而是删除flag变了。实现InnoDB的MVCC机制，更新或者删除操作都只是设置一下老记录的deleted_bit，并不真正将过时的记录删除。

  	2、查询操作时。在查询时要符合以下两个条件的记录才能被事务查询出来
  		1) 删除版本号未指定或者大于当前事务版本号，即查询事务开启后确保读取的行未被删除。
  		2）创建版本号 小于或者等于 当前事务版本号 ，就是说记录创建是在当前事务中（等于的情况）或者在当前事务启动之前的其他事物进行的insert。

  		所以，InnoDB存储引擎通过多版本控制的方式来读取当前执行时间数据库中行的数据，如果读取的行正在执行DELETE或UPDATE操作，这是读取操作不会因此等待行上锁的释放。相反的，InnoDB会去根据回滚指针读取行的一个快照数据（Undo log）

7、	InnoDB锁类型
	1、锁机制划分。乐观锁和悲观锁。
	    首先乐观锁和悲观锁 时两种控制并发的思想方式。
        1、乐观锁。
            1、乐观锁对数据修改持乐观态度，认为即使在并发环境中，外界对数据的操作一般是不会造成冲突，所以并不会去加锁，而是在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。
            如果其他事务有更新的话，则让返回冲突信息，让用户决定如何去做下一步，比如说重试或者回滚。
            2、乐观锁可借助版本号实现。例如MVCC 就是乐观锁的实现。

        2、悲观锁
            1、悲观锁采取的是保守策略，认为在数据修改的过程中，肯定会发生冲突，因此数据处理的过程中都采用加锁的方式来保证对数据资源的独占。
            2、悲观锁是借助数据库的锁机制实现。

     2、锁粒度
        1、表锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。
        2、行锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高
            只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！

     3、兼容性
        1、共享锁S
        2、排他锁X
            例子：
            不同事务可以同时对同一行记录加 S 锁。

            如果一个事务对某一行记录加 X 锁，其他事务就不能加 S 锁或者 X 锁，从而导致锁等待。

            如果事务 T1 持有行 r 的 S 锁，那么另一个事务 T2 请求 r 的锁时，会做如下处理:

            T2 请求 S 锁立即被允许，结果 T1 T2 都持有 r 行的 S 锁

            T2 请求 X 锁不能被立即允许

            如果 T1 持有 r 的 X 锁，那么 T2 请求 r 的 X、S 锁都不能被立即允许，T2 必须等待 T1 释放 X 锁才可以，因为 X 锁与任何的锁都不兼容

            select ... lock in share mode：加 S 锁

            select ... for update：加 X 锁


    4、算法（行锁算法）
            1、记录锁（Record-Lock） 锁定一行记录（记录锁存在于包括主键索引在内的唯一索引并且精准匹配中，锁定单条索引记录。）

            2、gap-lock锁 （间隙锁，锁定一个区间） （间隙锁存在于非唯一索引中，锁定开区间范围内的一段间隔，它是基于临键锁实现的。）
            3、next-key Lock (记录锁+间隙锁 锁定行记录+区间)
                （临键锁存在于非唯一索引中，该类型的每条记录的索引上都存在这种锁，它是一种特殊的间隙锁，锁定一段左开右闭的索引区间）

            InnoDB的默认事务隔离级别是RR，在这种级别下，如果你使用select ... in share mode或者select ... for update语句，
            那么InnoDB会使用临键锁，因而可以防止幻读；但即使你的隔离级别是RR，
            如果你这是使用普通的select语句，那么InnoDB将是快照读，不会使用任何锁，因而还是无法防止。

    4、意向锁

    1、产生原因
    解决表锁与之前可能存在的行锁冲突，避免为了判断表是否存在行锁而去扫描全表的系统消耗。
    2、意向锁加锁规则
    事务在获取行级 S 锁之前，必须获取其对应表的 IS 或 IX 锁
    事务在获取行级 X 锁之前，必须获取其对应表的 IX 锁

    3、作用
    一种快速判断手动加的表锁与之前可能存在的行锁冲突的机制。（数据库在执行事务过程中，更新数据时会帮我们自动加行锁），数据库在加行锁前要先加意向互斥锁。意向互斥锁是一种表锁。

    4、例子分析
    事务 A 锁住了表中的一行，让这一行只能读，不能写。之后，事务 B 申请整个表的写锁。

    如果事务 B 申请成功，那么理论上它就能修改表中的任意一行，这与 A 持有的行锁是冲突的。

    数据库需要避免这种冲突，就是说要让 B 的申请被阻塞，直到 A 释放了行锁。

    数据库要怎么判断这个冲突呢？

    step1：判断表是否已被其他事务用表锁锁表
    step2：判断表中的每一行是否已被行锁锁住。（注意step2，这样的判断方法效率实在不高，因为需要遍历整个表）

    于是就有了意向锁。

    在意向锁存在的情况下，事务 A 必须先申请表的意向互斥锁，成功后再申请一行的行锁。

    在意向锁存在的情况下，上面的判断可以改成

    step1：不变
    step2：发现表上有意向互斥锁，说明表中有些行被行锁锁住了，因此，事务 B 申请表的写锁会被阻塞。


    5、插入意向锁

    插入意向锁是在插入一条记录行前，由 INSERT 操作产生的一种间隙锁。该锁用以表示插入意向，
    当多个事务在同一区间（gap）插入位置不同的多条数据时，事务之间不需要互相等待。假设存在两条值分别为 4 和 7 的记录，
    两个不同的事务分别试图插入值为 5 和 6 的两条记录，每个事务在获取插入行上独占的（排他）锁前，都会获取（4，7）之间的间隙锁，
    但是因为数据行之间并不冲突，所以两个事务之间并不会产生冲突（阻塞等待）。

    插入意向锁特性：
    插入意向锁是一种特殊的间隙锁 —— 间隙锁可以锁定开区间内的部分记录。
    插入意向锁之间互不排斥，所以即使多个事务在同一区间插入多条记录，只要记录本身（主键、唯一索引）不冲突，
    那么事务之间就不会出现冲突等待。

    ！！！  需要强调的是，虽然插入意向锁中含有意向锁三个字，但是它并不属于意向锁而属于间隙锁，因为意向锁是表锁而插入意向锁是行锁。

    说明：
    我甚至可以简单理解为，插入意向锁是为了避免普通间隙锁导致的并发插入问题才引入的，其实就是告诉其它事务，
    我是一把插入意向锁，我的权利比普通间隙锁大，你们可以不用管它，想怎么插入，就怎么插入吧。


8、死锁概念：
    是指两个或两个以上的进程在执行过程中,
    因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去.
    此时称系统处于死锁状态或系统产生了死锁,这些永远在互相等竺的进程称为死锁进程.
    表级锁不会产生死锁.所以解决死锁主要还是针对于最常用的InnoDB.


     案例。
    	 事务 A
    	 update goods  set  count = 1 where goods_id = 1。

    	 update goods set count = 1 were goods_id = 2.


    	 事务B

    	 update goods set count = 1 where goods_id = 2;

    	 update goods set count =1  where goods_id = 1;


    	 出现死锁。

    	 对每一步的说明：

    	1，事务A开始事务。

    	2，事务A修改id=1的数据，持有了该行的锁。

    	3，事务B开始事务。

    	4，事务B修改id=2的数据，持有了该行的锁。

    	5，事务A试图修改id=2的数据，此行的锁被事务B持有，于是事务A等待事务B释放锁。

    	6，事务B试图修改id=1的数据，此行的锁被事务A持有，于是事务B等待事务A释放锁。

    	 当执行到这一步时，MySQL会立即检测到死锁，并且中断并回滚其中一个事务。

    1、死锁分析
            1、可以用show engine innodb status，查看最近一次死锁日志，找出死锁SQL，并分析死锁日志

    2、如何避免死锁
            2、为表添加合理的索引，如果不走索引将会为表的每一行记录加锁，死锁的概率就会大大增大；
            3、避免大事务，尽量将大事务拆成多个小事务来处理；因为大事务占用资源多，耗时长，与其他事务冲突的概率也会变高；
            4、设置锁等待超时参数：innodb_lock_wait_timeout，这个参数并不是只用来解决死锁问题，
                在并发访问比较高的情况下，如果大量事务因无法立即获得所需的锁而挂起，会占用大量计算机资源，
                造成严重性能问题，甚至拖跨数据库。我们通过设置合适的锁等待超时阈值，可以避免这种情况发生
            5、上线前充分压测 和代码review

9、一致性非锁定读

        1、一致性非锁定读 是指InnoDB存储引擎通过行版本控制的方式来读取当前执行时间数据库中的数据。
        如果读取的行正在执行DELETE或UPDATE操作，这时读取操作不会因此去等待行上锁的释放。相反的，
        InnoDB引擎会读取行的一个快照数据。
        流程：
            1、sql query  -》 XLocked  -〉 直接返回 （Snapshot Data） (快照数据)

            之所以称为非锁定度，是因为不需要等待访问数据行上的X锁的释放。快照数据是指该行之前版本的数据，通过undo段来实现（undo用来在事务中回滚数据）。

            说明： 快照数据是指该行的之前版本的数据，通过undo段来实现，而 undo用来在事务中回滚数据，因此读取
            快照数据没有额外的开销。

        2、一致性非锁定读机制，极大的提高了数据库的并发性。在InnoDB引擎默认的设置下，是默认的读取方式。但是快照数据可能不止一个，在不同的事务隔离级别中，快照数据读取的定义不同。
            1、在READ COMMITTED 在 读已提交隔离级别下，非锁定读总是读取被锁定行的最新一份的快照数据。
            2、在REPEATABLE READ 在可重复读隔离级别下，非一致性锁定读总是读取事务开始时的行数据版本。

            demo:
                会话a  											会话B
                 begin(开启事务)
            1、 select * from parent where id = 1
                                                                begin 开启事务
                                                                update paraent set id = 3 where id = 1;

            2、	 select * from parent where id = 1;
                                                                Commit

            3、	 select * from parent where id =1;

                 Commit


            总结 ：
                1、在 读已提交隔离级别中，会话a  步骤3 查询不到数据，因为 当前行被锁定，读取改行版本最新的一个快照数据 id已经变成了3
                2、在 可重复读隔离级别中，总是读取事务开始的行快照数据。因此 会话A的步骤3 还是可以读取出id=1 的数据的。

10、一致性锁定读
	 在InnnoDB 的默认配置下，事务的隔离级别 为可重复读，使用的是一致性非锁定读，但是 在某些情况下，需要对数据的读取操作进行加锁以保证数据逻辑的一致性。
	 InnnoDB 引擎，通过
	 1、select  for  update (添加X锁)
	 2、select lock in share mode  （添加S锁）

	  支持对只读操作的 一致性锁定读。
	 	select for update 会给 当前读取的行加上一个 X锁（排它锁），其他事务不能对已锁定的行加锁 只能阻塞。

11、分布式事务
	分布式事务指的是允许多个独立的事务资源参与到一个全局的事务中。全局事务必须要求在其中的所有参与事务要么都提交，要么都回滚。在使用分布式事务中，InnoDB 存储引擎的事务隔离级别必须设置 Serializable

	1、MySQL 数据库也支持分布式事务
		InnoDB 引擎提供了对XA事务的支持，并且通过XA事务来支持分布式事务的实现。

		XA 事务 由一个或者多个资源管理器，一个事务管理器以及一个应用程序组成。
		分布式事务使用两段水提交的方式。
		1、在第一阶段，所有参与全局事务的节点都开始准备，告诉事务管理器他们准备好了。
		2、在第二阶段，事务管理器告诉资源管理器执行ROLLBACK 还是COMMIT。如果一个节点显示不能提交，则所有的节点都被告知要回滚。

12、Mysql 主从复制
	1、 复制是Mysql 数据库提供的一种高可用高性能的解决方案。mysql 的主从复制 是数据可以从一个Mysql 数据库服务器主节点复制到一个或者多个从节点。MySQL 默认采用异步复制方式。
	2、主从复制形式
		1、一主一从
		2、一主多从 （提高系统读性能）
		3、多主一从
	3、主从复制原理
		主从复制涉及三个线程 ，一个运行在主节点（log dump thread）,两个运行在从线程（I/O 线程，SQL线程）
		步骤：
		1、当从节点连接主节点时，主节点会创建一个log dump 线程，用于发送bin-log的内容。在读取bin-log中的操作时，此线程会对主节点上的bin-log加锁，当读取完成，甚至在发动给从节点之前，锁会被释放。

		2、当从节点上执行`start slave`命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的bin-log。I/O线程接收到主节点binlog dump 进程发来的更新之后，保存在本地relay-log中。
		3、SQL线程负责读取relay log中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。
	4、主从好处
		1、读写分离。让主库负责写，从库负责读，提高系统系能
		2、高可用和架构扩展。（如果是单机部署数据库，就会导致I/O访问频率过高。有了主从复制，增加多个数据存储节点，将负载分布在多个从节点上，降低单机磁盘I/O访问的频率，提高单个机器的I/O性能）

14、分库分表
    导语：
    随着业务的增长，mysql中保存的数据会越来越多。此时，数据库很容易成为系统性能的一个瓶颈，单机存储容量、IO、CPU处理能力都有限，
    当单表的数据量达到1000W或100G以后，库表的增删改查操作面临着性能大幅下降的问题。分库分表是一种解决办法。

   1、 分库分表实际上就是对数据进行切分。我们一般可以将数据切分分为两种方式：垂直（纵向）切分和水平（横向）切分。

   2、垂直切分 （垂直切分常见有垂直分库和垂直分表两种。）

       1. 垂直分库
            垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库。思想与”微服务治理“类似，将系统拆分为多个业务，每个业务使用自己单独的数据库。
            （我们现在的微服务就是采用该模式，用户库，活动库，酬勤库）
       2、垂直分表
            垂直分表是基于数据库中的表字段来进行的。业务中可能存在一些字段比较多的表，表中某些字段长度较大。这些长字段我们又只是偶尔需要用到。
            这时候我们就可以考虑将表进行垂直拆分了。将某些不常用的，但是长度又很大的字段拎出来放到另外一张表。

            （例如用户的登录信息，和 用户基础信息表分离）
            原因：MySQL底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外的性能开销。另外数据库以行为单位将数据加载到内存中，
                这样表中字段长度较短且访问频率较高，内存能加载更多的数据，命中率更高，减少了磁盘IO，从而提升了数据库性能。
        3. 垂直切分优缺点
        优点：

        1. 不同系统可以使用不同的库表，解决业务系统层面的耦合，业务清晰

        2. 高并发场景下，垂直切分一定程度地提升IO、数据库连接数，缓解单机硬件资源的瓶颈

   3、水平切分
        单表数据依然过大，存在单库读写、存储性能瓶颈时候，这时候就可以考虑水平切分了。
        水平切分又可以分为库内分表和分库分表。是根据表内数据的内在逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，
        每个表中只包含一部分数据，从而使得单个表的数据量变小，达到分布式的效果。

        1、库内分表
            库内分表就是在同一个db上，将表按照某种条件拆分为多张表。（例如 post 根据帖子id ，把评论分为不同的表）

        2、分库分表
            分库分表就是将表不仅拆分，而且拆分到不同机器上。 （使用比较少）


    3 分库分表带来的问题
        1、事务一致性问题 （分布式事务）
        2、跨节点关联查询 join 问题
            切分之前，系统中很多列表和详情页所需的数据可以通过sql join来完成。
            而切分之后，数据可能分布在不同的节点上，此时join带来的问题就比较麻烦了，考虑到性能，尽量避免使用join查询。

            解决这个问题的一些方法：
                1、a. 全局表：
                2、b. 字段冗余：
                3、c. 数据组装：
                    在系统层面，分两次查询，第一次查询的结果集中找出关联数据id，然后根据id发起第二次请求得到关联数据。最后将获得到的数据进行字段拼装

        (3) 全局主键避重问题
            在分库分表环境中，由于表中数据同时存在不同数据库中，主键平时使用的自增长将无用武之地，
            某个分区数据库自生成的ID无法保证全局唯一。因此需要单独设计全局主键，以避免跨库主键重复问题。

            例如雪花算法
15、mysql日志
	MySQL的日志主要有：二进制日志、通用查询日志、慢查询日志、错误日志、事务日志等。
    1、binlog日志
        binlog是Mysql sever层维护的一种二进制日志，用来记录操作MySQL数据库中的写入性操作（包括增删改，但不包括查询），

        1、二进制的主要作用有两个：
            1、复制，配置了主从复制的时候，主服务器会将其产生的二进制日志发送到slave端，slave端会利用这个二进制日志的信息在本地重做，实现主从同步。
            2、恢复，因为二进制日志包含了备份以后的所有更新，因此可以用于最大限度地恢复数据库。因此，建议二进制日志单独保存到一个磁盘上，以便磁盘损坏以后进行数据恢复。
      	2、binlog的格式有三种：STATEMENT、ROW、MIXED 。下面我们来了解下这三种格式的区别：
            1、STATMENT：基于SQL语句的复制(statement-based replication, SBR)，记录的是SQL语句本身，不记录SQL语句对应每行的数据变化，即你写的什么SQL语句就记录什么。
            优点：产生的日志较少

            2、ROW：基于行的复制(row-based replication, RBR)，记录的是每行实际数据的变更

                特点：因此它会产生大量的日志，可读性差，但是它准确性强，能精准记录数据的变更。

                例如：例如 “update stu set age=16” 这条语句意思是将stu表中所有行的age列的值修改为16，对应就有很多行数据的变更。如果是ROW格式，那么binlog记录的就不是这条SQL语句本身（DDL和DCL语句记录的是本身），而是对应到每行的实际数据变更操作，假如stu表有100行，那么就会记录100条操作
        3、MIXED：混合模式复制(mixed-based replication, MBR)，以上两种模式的混合使用，由MySQL根据执行的SQL语句选择日志的记录格式。

    2、错误日志 error 日志
        MySQL的错误日志记录了 mysqld 启动和停止时，以及服务器在运行过程中出现的任何严重错误。

        一般在my.ini中配置
    3、redo.log
        可以结合实现事务的原子性，和持久性来介绍。

        例如事务的实现原理，就可以介绍原子性和持久性，介绍redo.log 和undo.log

        1、redo.log
            1、Redo log包括两部分，重做日志缓冲（redo log buffer）和重做日志文件（redo log file），前者是易失的缓存，后者是持久化的文件。
                举一个事务的例子：

                步骤1:begin;
                步骤2:insert into t1 …r
                步骤3:insert into t2 …
                步骤4:commit;
                这个事务的写入过程实际拆解如下：

                begin ->insert =>  更新数据到缓冲池 -》 写入redo log buffer =>  insert =>  更新数据到缓冲池 -》 写入redo log buffer  并将redo log buffer 写入redo log file 中 redo log处于prepare阶段。
                =》 写入binlog =〉 提交事务，事务处于commit状态

            重点关注在这个事务提交前，将 redo log 的写入拆成了两个步骤，prepare 和 commit，这就是"两阶段提交”。

            实际上，两阶段提交是分布式系统常用的机制。MySQL使用了两阶段提交后，也是为了保证事务的持久性。Redo log 和bingo 有一个共同的数据字段，叫 XID,崩溃恢复的时候，会按顺序扫描 redo log。
            1、假设在写入binlog前系统崩溃，那么数据库恢复后顺序扫描 redo log，碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务，而且binlog也没写入，所以事务就直接回滚了。
            2、假设在写入binlog之后，事务提交前数据库崩溃，那么数据库恢复后顺序扫描 redo log，碰到既有 prepare、又有 commit 的 redo log，就直接提交，保证数据不丢失。

         注意！！ mysql 就是通过以上 redo log 来实现持久性的。

            2、redo log和binlog的不同。
                1、产生位置不同。
                    redo log是innodb的存储引擎产生的，而binlog是数据库的server层实现的。换句话说，如果你使用MySQL，换其他存储引擎，那么可能没有redo log，但是还是会有binlog。
                2、日志记录的内容形式不同。
                    binlog是一种逻辑日志，记录对应的SQL语句，而redo log记录了物理日志，是针对每个数据页的修改。
                3、日志写入磁盘时间不同。
                    binlog只有在事务提交后完成一次写入，对于一个事物而言，在binlog中只有一条记录。而redo log在事务进行中不断被写入，而且是并发写入的，不是顺序写入的。
                4、保存方式不同。
                    redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

        4、undo log
            Undo log保证了事务的原子性。undo log有两个作用：提供回滚和多个行版本控制(MVCC)。
            1、在对数据库进行修改时，innoDB引擎除了会产生redo log，还会产生undo log。InnoDB实现回滚，靠的是undo log：当事务对数据库进行修改时，InnoDB会生成对应的undo log；如果事务执行失败导致事务需要回滚，就利用undo log中的信息将数据回滚到修改之前的样子。
                    比如一条 ` INSERT语句，对应一条 DELETE 的 undo log ，对于每个 UPDATE 语句，对应一条相反的 UPDATE 的undo log 。
            2、undo log还要另外一个重要作用，就是用于mvcc中，进行多版本控制，也就是实现事务隔离性的基础，当用户读取一行记录时，如果这个记录已接被其他事务占用，那么当前事务就可以通过undo读取之前的行版本信息，用来实现非锁定读取，就是“快照读”。
            所以redo log是一种物理日志（数据页的修改），而undo log是一种逻辑日志（数据记录）。

            补充：一致性的实现 （我们可以认为原子性、持久性和隔离性都是为了实现事务的一致性。）

16、你说说一条查询SQL的执行过程？
    1、首先客户端发送请求到服务端，建立连接。
    2、服务端先看下查询缓存是否命中，命中就直接返回，否则继续往下执行。
    3、接着来到解析器，进行语法分析，一些系统关键字校验，校验语法是否合规。
    4、然后优化器进行SQL优化，比如怎么选择索引之类，然后生成执行计划。
    5、最后执行引擎调用存储引擎API查询数据，返回结果。

    特殊说明3：
        解析器 和 预处理器 的工作主要包含：
        1、对 原始SQL 进行语法解析，验证语法规则，如：
        	1、关键字是否正确
        	2、语句是否有语法错误，如：缺少逗号等
        	3、得到 `语法解析树`
        2、进一步验证 语法解析树，如：
        	1、库、表是否存在
        	2、字段、类型是否正确
        	3、是否使用了禁止的关键字等
        	4、调用函数、识别别名等

17、你说说一条更新SQL的执行过程？
    1、首先客户端发送请求到服务端，建立连接。
    2、服务端先看下查询缓存，对于更新某张表的SQL，该表的所有查询缓存都失效。
    3、接着来到解析器，进行语法分析，一些系统关键字校验，校验语法是否合规。
    4、然后优化器进行SQL优化，比如怎么选择索引之类，然后生成执行计划。
    5、执行引擎去存储引擎查询需要更新的数据。
    6、存储引擎判断当前缓冲池中是否存在需要更新的数据，存在就直接返回，否则去从磁盘加载数据。
    7、执行引擎调用存储引擎API去更新数据。
    8、存储引擎更新数据，同时写入undo_log、redo_log信息。
    执行引擎写binlog，提交事务，流程结束。

18、limit 为什么会影响性能。

	1、MySQL的分页查询通常通过limit来实现。对于小的偏移量，直接使用limit来查询没有问题，
	但是随着数据量的增大，越往后分页，limit的数据的偏移量就越大，速度也会越来越明显

	 问题sql ：
	 		select * from test where val = t  limit 40000,20.

	 		为什么会慢：
	 		    1、上述sql查询到索引叶子节点数据。根据叶子节点上的主键值去聚簇索引上查询需要的全部字段值。
	 		    需要查询300005次索引节点，查询300005次聚簇索引的数据，最后再将结果过滤掉前300000条，取出最后5条。
	 		    MySQL耗费了大量随机I/O在查询聚簇索引的数据上，而有300000次随机I/O查询到的数据是不会出现在结果集当中的。

	 		    2、InnoDB中有buffer pool。里面存有最近访问过的数据页，包括数据页和索引页。读取大量的无用数据行（300000）
	 		      这会造成一个问题：加载了很多热点不是很高的数据页到buffer pool，会造成buffer pool的污染，
	 		      占用buffer pool的空间

	2、优化
		1、优化的思想 避免数据量大的时候，扫描过多的数据记录。

			1、利用 id >= 的形式
				1、select * from test where id >= (select id from test where val = 5  limit 30000,1) limit 5
		        例如：
		            1、select *  from ident_person_log  limit 100000,10;
		            2、select * from ident_person_log a where a.logid >= (select b.logid from ident_person_log b  order by b.logid limit 99999,1) limit 10;
			2、利用join
				select * from test a inner join (select id from test where val limit 30000,5) b on a.id = b.id.



		可以优化的原因：
			1、通过索引字段进行定位，然后才取出来相应的内容，减少了回表查询的次数。提升查询优化的效率。

			在实际的项目中，可以利用策略模式的方式去处理分页：
			例如，每页100条数据，判断如果是100页以内，就使用基本的分页方式，如果大于100，则使用子查询的分页方式。

19、分析sql语句的执行顺序
	1、一般，WHERE在前，GROUP BY在后，即先进行筛选，然后进行分组；
	2、HAVING只能跟在GROUP BY之后，对分组后的聚合结果进行筛选；HAVING的前提是分组；WHERE在最前，最先对原始数据进行一遍筛选；
	3、WHERE的条件里只能用已有的列进行条件判断，不允许使用聚合函数。HAVING之后可以允许使用聚合函数


	当一个查询语句同时出现了where,group by,having,order by的时候，执行顺序和编写顺序是：
	1.执行where xx对全表数据做筛选，返回第1个结果集。
	2.针对第1个结果集使用group by分组，返回第2个结果集。
	3.针对第2个结果集中的每1组数据执行select xx，有几组就执行几次，返回第3个结果集。
	4.针对第3个结集执行having xx进行筛选，返回第4个结果集。
	5.针对第4个结果集排序。


20、MySql的连接left join, inner join, full join

    　　1、left join （左连接）：返回包括左表中的所有记录和右表中连接字段相等的记录。
    　　2、right join （右连接）：返回包括右表中的所有记录和左表中连接字段相等的记录。
    　　3、inner join （等值连接或者叫内连接）：只返回两个表中连接字段相等的行。
    　　4、full join （全外连接）：返回左右表中所有的记录和左右表中连接字段相等的记

    21、join on and 和 join on where 	区别

        总结：
        在使用left join 时，on和where条件的区别：
        1：on条件是在生成临时表时使用的条件，它不管on中的条件是否为真，都会返回左边表中的记录。
        2：where条件是在临时表生成好后，再对临时表进行过滤的条件。这时已经没有left join的含义（必须返回左边表的记录）了，条件不为真的就全部过滤掉。
        3: inner join是在生成临时表以后再进行过滤的，而且对左表和右表都起作用。


        select * from dept left join emp on dept.deptno = emp.deptno;
        +----+--------+--------+----+------+-----+--------+
        | id | deptno | name   | id | name | sex | deptno |
        +----+--------+--------+----+------+-----+--------+
        |  2 |      2 | 运营部 |  1 | 小张 | 男  |      2 |
        |  1 |      1 | 技术部 |  2 | 小王 | 男  |      1 |
        |  3 |      3 | 市场部 |  3 | 小李 | 女  |      3 |
        |  1 |      1 | 技术部 |  4 | 小杨 | 男  |      1 |
        |  1 |      1 | 技术部 |  5 | 小郑 | 男  |      1 |
        +----+--------+--------+----+------+-----+--------+

        select * from dept left join emp on dept.deptno = emp.deptno and emp.sex ='男';
        +----+--------+--------+------+------+------+--------+
        | id | deptno | name   | id   | name | sex  | deptno |
        +----+--------+--------+------+------+------+--------+
        |  2 |      2 | 运营部 |    1 | 小张 | 男   |      2 |
        |  1 |      1 | 技术部 |    2 | 小王 | 男   |      1 |
        |  1 |      1 | 技术部 |    4 | 小杨 | 男   |      1 |
        |  1 |      1 | 技术部 |    5 | 小郑 | 男   |      1 |
        |  3 |      3 | 市场部 | NULL | NULL | NULL | NULL   |
        +----+--------+--------+------+------+------+--------+

        on条件是在生成临时表时使用的条件，它不管on中的条件是否为真，都会返回左边表中的记录。显然左连接再加上新的条件:emp.sex='男’，筛选第五行记录。

        Where:

         select * from dept left join emp on dept.deptno = emp.deptno where emp.
        sex ='男';
        +----+--------+--------+----+------+-----+--------+
        | id | deptno | name   | id | name | sex | deptno |
        +----+--------+--------+----+------+-----+--------+
        |  1 |      1 | 技术部 |  2 | 小王 | 男  |      1 |
        |  1 |      1 | 技术部 |  4 | 小杨 | 男  |      1 |
        |  1 |      1 | 技术部 |  5 | 小郑 | 男  |      1 |
        |  2 |      2 | 运营部 |  1 | 小张 | 男  |      2 |
        +----+--------+--------+----+------+-----+--------+
        where是生成临时表以后再进行过滤，对左右表都进行筛选。而and后面的语句如果是对left join中的左表进行过滤将不起任何作用，对右表进行过滤的话，那么左表还是返回所有行，只是右表会被过滤掉一部分行。


        inner join
           select * from dept inner join emp on dept.deptno = emp.deptno and emp.sex ='男';
        +----+--------+--------+----+------+-----+--------+
        | id | deptno | name   | id | name | sex | deptno |
        +----+--------+--------+----+------+-----+--------+
        |  1 |      1 | 技术部 |  2 | 小王 | 男  |      1 |
        |  1 |      1 | 技术部 |  4 | 小杨 | 男  |      1 |
        |  1 |      1 | 技术部 |  5 | 小郑 | 男  |      1 |
        |  2 |      2 | 运营部 |  1 | 小张 | 男  |      2 |
        +----+--------+--------+----+------+-----+--------+

        select * from dept inner join emp on dept.deptno = emp.deptno where emp.sex ='男';
        +----+--------+--------+----+------+-----+--------+
        | id | deptno | name   | id | name | sex | deptno |
        +----+--------+--------+----+------+-----+--------+
        |  1 |      1 | 技术部 |  2 | 小王 | 男  |      1 |
        |  1 |      1 | 技术部 |  4 | 小杨 | 男  |      1 |
        |  1 |      1 | 技术部 |  5 | 小郑 | 男  |      1 |
        |  2 |      2 | 运营部 |  1 | 小张 | 男  |      2 |
        +----+--------+--------+----+------+-----+--------+
        内连接inner join on and 或者on where不管是对左表还是右表进行过滤，实际都是在生成临时表以后再进行过滤的，而且对左表和右表都起作用，这与左连接left join有本质的区别！！


21、索引失效的场景：
	1、使用了or的情况。使用or连接的两个字段，如果两个字段都是索引字段索引才会生效，否则索引无效。
	2、组合索引失效。判断是否满足最左前缀原则
	3、使用like %XXXX。做模糊匹配的时候把%加在最前边的时候，索引无效，加在后面可以。
        1、 like %xttblog，因为 % 表示全匹配，所以 MySQL 就放弃索引了，进行全表扫描。
        2、like xtttt% 走索引
        3、like %xttt% 不走索引
          最左匹配原则， 其实是和 B+Tree 有些关系，索引树从左到右都是有顺序的。对于索引中的关键字进行对比的时候，一定是从左往右以此对比，且不可跳过。

	4、隐示类型转换，导致索引失效。
	    1、例如：  `c1` varchar(255) NOT NULL DEFAULT '', 操作时使用  整数
              explain select * from t1 where c1=12345678901234567;
              因进行隐示类型转化 ，导致全表扫描，不走索引。
              c1 字段类型是 varchar，等号右边常量是数字，MySQL 会把 c1 字段的值和数字常量转换成浮点数比较。
              当字段是字符串跟数字比较时，MySQL 不能使用索引来加快查询。
               正如示例的执行计划显示的那样，进行了全表扫描。
               原因在于字符串转浮点型的时候所使用的算法，在 MySQL 里以下’1’, ‘ 1’, ‘1a’字符串转换成数字后都是 1。
         2、c1字段是int,等号右边是 字符串。
              int 优先级比较高，查询条件中如果有int，另一方会被转换成int。此时会走索引的。

	5、使用<>、NOT、in、not exists。的时候索引可能会失效，进而使用全表查询。
		当查询条件为非时，索引定位就困难了，执行计划此时可能更倾向于全表扫描
	6、条件上包括函数
		select * from test where upper(name)='SUNYANG';
	具体是否走索引，我们可以根据explain进行分析。从而优化SQL。

索引设计的原则：
	1、为经常需要排序、分组操作的字段建立索引
	2、为常作为查询条件的字段建立索引
	3、尽量选择区分度高的列作为索引
	4、限制索引的数目。
		索引的数目不是越多越好。每个索引都需要占用磁盘空间，索引越多，需要的磁盘空间就越大。修改表时，对索引的重构和更新很麻烦。越多的索引，会使更新表变得很浪费时间。
	5、联合索引，遵循索引最左匹配原则。
	6、尽量使用数据量少的索引
		如果索引的值很长，那么查询的速度会受到影响。例如，对一个CHAR(100)类型的字段进行全文检索需要的时间要比对CHAR(10)类型的字段需要的时间要多。

22、Mysql优化
  1、架构方向。提供高可用性。使用主从进行读写分离。降低单数据库的压力。
  2、数据库和表设计方向。
    1、根据服务场景，进行分库 和分表设计。（垂直分库/分表，水平分库/分表）
    2、表中索引设计
      1、建立索引时，索引不能太多，区分度高的字段建立索引。 使用时充分考虑有没有命中索引。
      2、建立字段时，根据业务考虑字段合适的类型。
      3、根据数据量预估，对表，选择合适的分区方案。
  3、应用优化。根据业务场景，采用合适的nosql做一层缓存，降低mysql的压力。例如redis,memcache.


23、MySql分区：
    分区的意思是指将同一表中不同行的记录分配到不同的物理文件中，几个分区就有几个.idb文件

    1、分区。
        1、要么没有主键/唯一键，要么分区表主键/唯一键必须包涵分区键。

    2、分区类型。
      1、Range 分区。（基于属于一个给定连续区间的列值，把多行分配给分区）
          一般都是根据日期来分区。目前交易流水表使用的是根据dateline来分区。每隔四月，由运维进行分区。优化空间：未来使用存储过程进行自动分区。
      2、HASH 分区。（基于给定的分区个数，把数据分配到不同的分区）
        一般根据uid进行分区。目前线上user_info表，通过uid进行hash分区。user_info表数据量大概2000万。

    3、分区的优点。
      1、可以让单表存储更多的数据。在SQL查询中，条件存在分区的列，使查询定位到具体的分区上，不用扫码全部的分区，加速查询的性能。
      2、如果分区字段中有主键或者唯一索引的列，那么所有主键列和唯一索引列都必须包含进来

24、如何分析Mysql慢SQL

	1、开启慢查问日志捕捉慢SQL
		① 查问mysql是否开启慢日志捕捉：
			SHOW VARIABLES LIKE '%slow_query_log%';

		②  查看慢查问的时间阙值：
			SHOW GLOBAL VARIABLES LIKE '%long_query_time%';

	2、应用explain剖析慢SQL
		explain执行计划。
		Mysql通过在语句前面添加EXPLAIN关键字来查看执行计划。包括以下列。
		1、id  在一个大的查询语句中每个select关键字都对应一个唯一的id
		2、select_type : select关键字对应的查询类型。
				SIMPLE : 查询语句中不包含UNION和子查询的都是SIMPLE类型
				PRIMARY : 对于包涵UNION，UNION ALl 或者子查询的大的查询来说，它是由几个小查询组成的，其中最左边
						  的那个查询select_type 值就是PRIMAERY。 其余的类型都是UNION。
				UNION：
				SUBQUERY： 子查询语句。

		3、table 表名
		4、type:  每个表中数据的扫描方式,单表的访问方法。
				system:系统表，少量数据，往往不需要进行磁盘IO
				const: 根据主键或者唯一索引进行等值匹配时，就是const。例如：explain select * from s1 where id = 5。
				ref: 通过普通索引与常量进行
				range: 使用索引获取某些范围内记录时，就可能使用range方法
				index: 扫描全部的索引记录
				ALL :全表扫描
		5、possible_keys：可能用到的索引
		6、key：实际用到的索引
		7、key_len，使用到的索引长度
		8、rows：扫描的行数
		9、extra:一些额外的信息。

	3、应用show profile查问SQL执行细节
		Show Profile是MySQL提供可以用来分析当前会话中语句执行的资源消耗情况，可以用于SQL的调优测量。
		ALL：显示所有开销信息
	      BLOCK IO：显示IO相关开销
	      CONTEXT SWITCHES：显示上下文切换相关开销
	      CPU：显示CPU相关开销
	      IPC：显示发送接收相关开销
	      MEMORY：显示内存相关开销
	      PAGE FAULTS：显示页面错误相关开销
	     SOURCE：显示和Source_function，Source_file，Source_line相关开销
	     SWAPS：显示交换次数相关开销


    4\慢sql
      	1、一直很慢
      		1、一般都是索引有关。要么sql 语句没有走索引，要么没有建立索引，或者建立的索引不正确。
      	2、大多数情况是正常的，只是偶尔会出现很慢的情况。
      		1、可能因为网络抖动。（应用和数据库部署在不同的服务器，且属于不同的机房）
      		2、数据库 存在刷脏页。
      			mysql 在更新数据的时候，先把记录写到redo log buffer中，然后在空闲的时候，刷新到redo log file 中
      			如果mysql 的负载很大，更新又很频繁， redo log 很快就会被写满，这个只能暂停其他操作，等待数据同步完成。
      			可以通过配置修改redo log file 的大小。
      		3、存在锁等待。
      			执行的这条语句，刚好这条语句涉及到的表或者使用到的某个一行被加锁了，只能慢慢等待别人释放锁了。
      			如果要判断是否真的在等待锁，我们可以用 show processlist这个命令来查看当前的状态。
25、MySQL 主从延迟原因和解决方案
	1、从库的压力大。（读并发）
		原因：按照正常的策略，读写分离，主库提供写能力，从库提供读能力。将进行大量查询放在从库上，结果导致从库上耗费了大量的CPU资源，进而影响了同步速度，造成主从延迟。

		解决方案：对于这种情况，1、可以通过一主多从，分担读压力；2、也可以采取binlog 通过kafak 输出到外部系统，比如Hadoop 和ES，让外部系统提供查询能力。3，也可以在应用程引入缓存，写完主库，在写入缓存中。

	2、主库的压力大。（写并发）
		分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍

	3、网络延迟导致 的主从延迟。 （这个建议把 主从服务部署在一个机房内，扩大带宽）
	4、实时性要求的业务读强制走主库，从库只做灾备，备份。

26、Redis 主从延迟。
	1、单机环境 和集群。
		1、网络延迟。 从节点和主节点部署在一个网络内，扩大带宽。
		2、从库压力过大。（读并发）
			1、增加从库，通过一主多从，分担从库压力。
		3、忽略这个数据不一致，在数据一致性要求不高的业务下，未必需要时时一致性。

		4、强制读主库，使用一个高可用的主库，数据库读写都在主库，添加一个缓存，提升数据读取的性能

		5、选择性读主库，添加一个缓存，用来记录必须读主库的数据，将哪个库，哪个表，哪个主键，作为缓存的key,设置缓存失效的时间为主从库同步的时间，
		如果缓存当中有这个数据，直接读取主库，如果缓存当中没有这个主键，就到对应的从库中读取

		1、根本上解决
			监控主从节点延迟（通过offset）判断，如果slave延迟过大，暂时屏蔽程序对该slave的数据访问


27、数据库和缓存不一致。
    1、先删缓存，再更新数据库（系统实时性要求不高）
        1、延时双删
           1、线程1删除缓存，然后去更新数据库
           2、线程2来读缓存，发现缓存已经被删除，所以直接从数据库中读取，这时候由于线程1还没有更新完成，所以读到的是旧值，然后把旧值写入缓存
           3、线程1，根据估算的时间，sleep，由于sleep的时间大于线程2读数据+写缓存的时间，所以缓存被再次删除
           4、如果还有其他线程来读取缓存的话，就会再次从数据库中读取到最新值
        2、采用补偿机制。。启动一个定时任务，定时把数据库的数据，更新到缓存中

	2、系统实时性要求高。并且高并发读取的情况下。
	    1、更新与读取操作进行异步串行化
	      1、系统内部维护n个内存队列. 一个数据变更的操作，先执行删除缓存，然后根据数据的唯一标识Id，把更新数据库操作放入队列中，
	      2、如果此时一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，
	        此时会在队列中积压，排在刚才更新库的操作之后，然后同步等待缓存更新完成.

28、数据库字段的区别
     1、char、varchar、和text的区别
    	1、char(n),varchar(n) n代表字符数。
    	2、char: 它是定长格式的，但是长度范围是0~255字节. 当你想要储存一个长度不足255的字符时，mysql会用空格来填充剩下的字节。
    		举个例子。 “abc” char(10)，会占用10个字节，7个字节用空格占位。
    	3、varchar： 变长格式，最大 0 ~ 65535 字节。
    		例如 “abc” char(10)，只占用3个字节，按实际字节长度存储
    	4、text 最大长度也是65535个字节，没有默认值。

     2、bigint,int,smallint,tinyint的区别
     	1、bigint
     		   从 -2^63 (-9223372036854775808) 到 2^63-1 (9223372036854775807) 的整型数据（所有数字）。存储大小为 8 个字节。
    	2、int
    		    从 -2^31 (-2,147,483,648) 到 2^31 – 1 (2,147,483,647) 的整型数据（所有数字）。存储大小为 4 个字节。、
    	3、smallint
    			从 -2^15 (-32,768) 到 2^15 – 1 (32,767) 的整型数据。存储大小为 2 个字节。
    	4、tinyint
    		    从 0 到 255 的整型数据。存储大小为 1 字节。






