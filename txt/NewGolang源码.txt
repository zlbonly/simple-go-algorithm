1、golang 如何实现多态？
	1、interface
		Go接口是一组方法的集合，可以理解为抽象的类型，他提供了一种非侵入式的接口。然和类型，只要实现了该接口中的方法集，那么就属于这个类型。

		例如：
			type Duck interface{
				Quack()
				DuckGo()
			}

			type Chickken struct{

			}

			func(c Chicken) IsChicken() bool{
				fmt.println("a chicken")
			}

			func (c Chicken) Quack() {
    				fmt.Println("嘎嘎")
			}

			func (c Chicken) DuckGo() {
   				 fmt.Println("大摇大摆的走")
			}

			注意，这里只是实现了 Duck 接口方法，并没有将鸡类型和鸭子接口显式绑定。这是一种非侵入式的设计。

			func DoDuck(d Duck) {
  			 	 d.Quack()
    			 d.DuckGo()
			}

			func main() {
   				 c := Chicken{}
    			 DoDuck(c)
			}

			执行正常。如此是不是很类似于其他语言的多态，其实这就是 Go 多态的实现方法。

			核心思想： 我理解为“依赖于接口而不是实现接口，优先使用组合而不是继承”

			其他语言，例如 php ,生命一个接口，每个实现都需要 继承该接口，如果接口改动实现也需要跟着改动，是一种侵入式的。



	2 空接口和nil 区别
		1、如果 一个interface 没有定义任何方法，即为空 表示为interface{},如此一来，任何类型都能满它，当参数类型为interface{}时，可以给他传递任意类型的参数。
			Go的interface{} 常常会被用作为函数的参数传递，用以帮助我们实现其他语言中的范型效果。

	3、golang interface底层源码分析
		1、interface 底层接口
			iface 和 eface 都是 Go 中描述接口的底层结构体，区别在于 iface 描述的接口包含方法，而 eface 则是不包含任何方法的空接口：interface{}。

			1、
			type iface struct {
    			tab  *itab  // 指针类型，指向 itab 类型
    			data unsafe.  // 描述了具体的值
			}

			type itab struct {
			    inter *interfacetype
			    _type *_type // // 通用的类型信息
			    hash  uint32 // copy of _type.hash. Used for type switches.
			    _     [4]byte
			    fun   [1]uintptr // variable sized. fun[0]==0 means _type does not implement inter.
			    	//  // 存储了接口方法对应的具体数据类型的方法地址
			}


			2、	空的 inferface{} 是没有方法集的接口。所以不需要 itab 数据结构。它只需要存类型和类型对应的值即可。对应的数据结构如下：

			type eface struct { // 16 字节
			    _type *_type
			    data  unsafe.Pointer
			}

				从这个数据结构可以看出，只有当 2 个字段都为 nil，空接口才为 nil。空接口的主要目的有 2 个，一是实现“泛型”，二是使用反射。

	4、类型断言
		一个interface被多种类型实现时，有时候我们需要区分interface的变量究竟存储哪种类型的值，go可以使用comma,ok的形式做区分 value, ok := em.(T)：em 是 interface 类型的变量，T代表要断言的类型，value 是 interface 变量存储的值，ok 是 bool 类型表示是否为该断言的类型 T。总结出来语法如下：
			<目标类型的值>，<布尔参数> := <表达式>.( 目标类型 ) // 安全类型断言
			<目标类型的值> := <表达式>.( 目标类型 )　　//非安全类型断言

			 d1,ok := d.(Dog)
			    if !ok{
			        return
			    }



2、channel 实现
	Go并发的哲学，基于channel实现。“不是通过共享内存实现通信，而是通过通信来共享内存”

	runtime/chan.go
	1、hchan数据结构
		type hchan struct {
		    qcount   uint           // 队列中剩余元素
		    dataqsiz uint           // 队列长度，eg make(chan int64, 5), dataqsiz为5
		    buf      unsafe.Pointer // 数据存储环形数组
		    elemsize uint16         // 每个元素的大小
		    closed   uint32         // 是否关闭 0 未关闭
		    elemtype *_type         // 元素类型
		    sendx    uint           // 发送者写入位置
		    recvx    uint           // 接受者读数据位置
		    recvq    waitq          // 接收者队列，保存正在读取channel的goroutine
		    sendq    waitq          // 发送者队列，保存正在发送channel的goroutine
		    lock     mutex          // 锁
		}

		waitq 是双向链表，sudog 为 goroutine 的封装
		type waitq struct {
		    first *sudog
		    last  *sudog
		}




        2、channel发送和接收的流程
            向channel发送和从channel接收数据主要涉及hchan里的四个成员变量（buf,sendx,recvx,lock），借用Kavya ppt里的图示，来分析发送和接收的过程
            如图：https://pic1.zhimg.com/v2-c2549285cd3bbfd1fcb9a131d8a6c40c_b.webp

        还是以前面的任务队列为例:

        G1
        func main(){
            ...

            for _, task := range hellaTasks {
                ch <- task    //sender
            }

            ...
        }

        //G2
        func worker(ch chan Task){
            for {
               //接受任务
               task := <- ch  //recevier
               process(task)
            }
        }
        其中G1是发送者，G2是接收，因为ch是长度为3的带缓冲channel，初始的时候hchan结构体的buf为空，sendx和recvx都为0，当G1向ch里发送数据的时候，会首先对buf加锁，然后将要发送的数据copy到buf里，并增加sendx的值，最后释放buf的锁。然后G2消费的时候首先对buf加锁，然后将buf里的数据copy到task变量对应的内存里，增加recvx，最后释放锁。整个过程，G1和G2没有共享的内存，底层通过hchan结构体的buf，使用copy内存的方式进行通信，最后达到了共享内存的目的.

        3、一般情况下，G2的消费速度应该是慢于G1的，所以buf的数据会越来越多，这个时候G1再向ch里发送数据，这个时候G1就会阻塞，那么阻塞到底是发生了什么呢？

            goroutine是Golang实现的用户空间的轻量级的线程，有runtime调度器调度，与操作系统的thread有多对一的关系
            其中M是操作系统的线程，G是用户启动的goroutine，P是与调度相关的context，每个M都拥有一个P，P维护了一个能够运行的goutine队列，用于该线程执行。

            1、当G1向buf已经满了的ch发送数据的时候，当runtine检测到对应的hchan的buf已经满了，会通知调度器，调度器会将G1的状态设置为waiting, 移除与线程M的联系，然后从P的runqueue中选择一个goroutine在线程M中执行，此时G1就是阻塞状态，但是不是操作系统的线程阻塞，所以这个时候只用消耗少量的资源。

            2、当G1变为waiting状态后，会创建一个代表自己的sudog的结构，然后放到sendq这个list中，sudog结构中保存了channel相关的变量的指针(如果该Goroutine是sender，那么保存的是待发送数据的变量的地址，如果是receiver则为接收数据的变量的地址，之所以是地址，前面我们提到在传输数据的时候使用的是copy的方式)
            3、当G2从ch中接收一个数据时，会通知调度器，设置G1的状态为runnable，然后将加入P的runqueue里，等待线程执行



        4、wait empty channel

            前面我们是假设G1先运行，如果G2先运行会怎么样呢？如果G2先运行，那么G2会从一个empty的channel里取数据，这个时候G2就会阻塞，和前面介绍的G1阻塞一样，G2也会创建一个sudog结构体，保存接收数据的变量的地址，但是该sudog结构体是放到了recvq列表里，当G1向ch发送数据的时候，runtime并没有对hchan结构体题的buf进行加锁，而是直接将G1里的发送到ch的数据copy到了G2 sudog里对应的elem指向的内存地址！


            参考如图：https://zhuanlan.zhihu.com/p/27917262



        5、channel应用场景
            1、数据交流：当作并发的 buffer 或者 queue，解决生产者 - 消费者问题。多个 goroutine 可以并发当作生产者（Producer）和消费者（Consumer）。
            2、数据传递：一个goroutine将数据交给另一个goroutine，相当于把数据的拥有权托付出去。
            3、信号通知：一个goroutine可以将信号(closing，closed，data ready等)传递给另一个或者另一组goroutine。
            4、任务编排：可以让一组goroutine按照一定的顺序并发或者串行的执行，这就是编排功能。
            5、锁机制：利用channel实现互斥机制。


        6、无缓冲通道和 缓存为1的通道的区别
            golang channel 有缓冲 与 无缓冲 是有重要区别的 。我之前天真的认为 有缓冲与无缓冲的区别 只是 无缓冲的 是 默认 缓冲 为1 的缓冲式。其实是彻底错误的，无缓冲的与有缓冲channel有着重大差别
            1、那就是一个是同步的 一个是非同步的

                c1:=make(chan int)        无缓冲
                c2:=make(chan int,1)      有缓冲
                c1<-1

            解释：无缓冲的 不仅仅是 向 c1 通道放 1 而是 一直要有别的携程 <-c1 接手了 这个参数，那么c1<-1才会继续下去，要不然就一直阻塞着
            而 c2<-1 则不会阻塞，因为缓冲大小是1 只有当 放第二个值的时候 第一个还没被人拿走，这时候才会阻塞。

            无缓冲的channel的读写者必须同时完成发送和接收，而不能串行，显然单协程无法满足。所以这里造成了循环等待，会死锁。
        7、优雅的关闭channel
          原则：  不要从一个 receiver 侧关闭 channel，也不要在有多个 sender 时，关闭 channel。
            根据 sender 和 receiver 的个数，分下面几种情况：
            1、一个 sender，一个 receiver
            2、 一个 sender， M 个 receiver
            3、N 个 sender，一个 reciver
            4、N 个 sender， M 个 receiver
            对于 1，2，只有一个 sender 的情况就不用说了，直接从 sender 端关闭就好了，没有问题。重点关注第 3，4 种情况。
            对于 3解决方案就是增加一个传递关闭信号的 channel，receiver 通过信号 channel 下达关闭数据 channel 指令。senders 监听到关闭信号后，停止发送数据
            对于4 通过一个中间人来关闭channel
        8、channel导致死锁
            1、同一个goroutine中，使用同一个 channel 读写。
                    func main(){
                        ch:=make(chan int)  //这就是在main程里面发生的死锁情况
                        ch<-6   //  这里会发生一直阻塞的情况，执行不到下面一句
                        <-ch
                    }
             2、第二种：2个 以上的go程中， 使用同一个 channel 通信。 读写channel 先于 go程创建。
                func main(){
                    ch:=make(chan int)
                    ch<-666    //这里一直阻塞，运行不到下面
                    go func (){
                        <-ch  //这里虽然创建了子go程用来读出数据，但是上面会一直阻塞运行不到下面
                    }()
                }
3、Context
	1、背景
		Go 1.7 标准库引入 context，中文译作“上下文”，准确说它是 goroutine 的上下文，context 主要用来在 goroutine 之间传递上下文信息，包括：取消信号、超时时间、截止时间、k-v 等。

		举个例子：在Go 里，我们不能直接杀死协程，协程的关闭一般会用 channel+select 方式来控制。但是在某些场景下，例如处理一个请求衍生了很多协程，这些协程之间是相互关联的：需要共享一些全局变量、有共同的 deadline 等，而且可以同时被关闭。再用 channel+select 就会比较麻烦，这时就可以通过 context 来实现。

	2、context 底层实现原理
		1、Context 是一个接口，定义了 4 个方法，它们都是幂等的。也就是说连续多次调用同一个方法，得到的结果都是相同的
			1、Done() <-chan struct{}	当 context 被取消或者到了 deadline，返回一个被关闭的 只读channel
				注意：当这个 channel 被关闭时，说明 context 被取消了，读一个关闭的 channel 会读出相应类型的零值。并且源码里没有地方会向这个 channel 里面塞入值。换句话说，这是一个 receive-only 的 channel。因此在子协程里读这个 channel，除非被关闭，否则读不出来任何东西。也正是利用了这一点，子协程从 channel 里读出了值（零值）后，就可以做一些收尾工作，尽快退出。
			2、    Err() error 在 channel Done 关闭后，返回 context 取消原因
			3、 Deadline() (deadline time.Time, ok bool)		返回 context 是否会被取消以及自动取消时间（即 deadline）
			4、Value() 获取之前设置的 key 对应的 value。


	3、源码中定义了 Context 接口后，并且给出了一个实现：emptyCtx
		这实际上是一个空的 context，永远不会被 cancel，没有存储值，也没有 deadline。
		var (
		    background = new(emptyCtx)
		    todo       = new(emptyCtx)
		)

		func Background() Context {
    		return background
		}

		func TODO() Context {
		    return todo
		}

		1、context.Background()：这个函数返回一个空context。这只能用于高等级（在 main 或顶级请求处理中）。
		2、context.TODO()：这个函数也是创建一个空context。也只能用于高等级或当您不确定使用什么 context


	4、有了根节点 context，又提供了四个函数创建子节点 context：
			func WithCancel(parent Context) (ctx Context, cancel CancelFunc)
			func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc)
			func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)
			func WithValue(parent Context, key, val interface{}) Context


4、golang锁

 1、互斥锁 Mutex 和 读写锁 RWMutex
 	1、互斥锁 Mutex
 		1.互斥锁有两种操作，获取锁和释放锁
		2.当有一个goroutine获取了互斥锁后，任何goroutine都不可以获取互斥锁，只能等待这个goroutine将互斥锁释放
		3.互斥锁适用于读写操作数量差不多的情况
		4.读写都可以放入互斥锁中

	Go 标准库中提供了 sync.Mutex 互斥锁类型及其两个方法：
		Lock 加锁
		Unlock 释放锁


	2、互斥锁的实现原理
		type Mutex struct {
			state int32		// 表示当前互斥锁的状态
			sema uint32	// sema 是用于控制锁状态的信号量。
		}

		1、Mutex的状态机比较复杂，使用一个int32来表示


		32								3								2							1
		waiterCount						mutexServing					mutexWoken				mutexLocked

		在默认情况下，互斥锁的所有状态位都是 0，int32 中的不同位分别表示了不同的状态：
		1、mutexLocked — 表示互斥锁的锁定状态；
		2、mutexWoken — 表示从正常模式被从唤醒；
		3、mutexStarving — 当前的互斥锁进入饥饿状态；
		4、waitersCount — 当前互斥锁上等待的 goroutine 个数；


		2、为了保证锁的公平性，设计上互斥锁有两种状态：正常状态和饥饿状态

			1、正常状态
			 正常模式下，所有等待锁的goroutine按照FIFO顺序等待。唤醒的goroutine不会直接拥有锁，而是会和新请求锁的goroutine竞争锁的拥有。新请求锁的goroutine具有优势：它正在CPU上执行，而且可能有好几个，所以刚刚唤醒的goroutine有很大可能在锁竞争中失败。在这种情况下，这个被唤醒的goroutine会加入到等待队列的前面。 如果一个等待的goroutine超过1ms没有获取锁，那么它将会把锁转变为饥饿模式。
			2、饥饿状态
				饥饿模式下，锁的所有权将从unlock的gorutine直接交给交给等待队列中的第一个。新来的goroutine将不会尝试去获得锁，即使锁看起来是unlock状态, 也不会去尝试自旋操作，而是放在等待队列的尾部。

			如果一个等待的goroutine获取了锁，并且满足一以下其中的任何一个条件：(1)它是队列中的最后一个；(2)它等待的时候小于1ms。它会将锁的状态转换为正常状态。
			饥饿模式是在 Go 1.9版本引入的，它防止了队列尾部waiter一直无法获取锁的问题


    注意**
    3、当 Go struct 遇上 Mutex。不能复制原因。
          我们使用 Mutex 是为了不同 goroutine 之间共享某个变量, 所以需要让这个变量做到能够互斥, 不然该变量就会被互相被覆盖.
          Mutex 底层是由 state sema 控制的, 当 Mutex 变量被复制时, Mutex 的 state, sema 当时的状态也被复制走了, 但是由于不同 goroutine 之间的 Mutex 已经不是同一个变量了, 这样就会造成要么某个 goroutine 死锁或者不同 goroutine 共享的变量达不到互斥

    4、struct 如何与 不可复制 的类型一块使用 ?
    type URL struct {
        Ip       string
        mux   	 *sync.RWMutex
    }

    将嵌套的不可复制变量改成指针类型变量，就可避免，但是要注意空指针问题。

 	2、读写锁RWMutex
 		1.读写锁有四种操作 读上锁 读解锁 写上锁 写解锁
 		2.写锁最多有一个，读锁可以有多个(最大个数据说和CPU个数有关)
		3.写锁的优先级高于读锁，这是因为为了防止读锁过多，写锁一直堵塞的情况发生
 		4.当有一个goroutine获得写锁时，其他goroutine不可以获得读锁或者写锁，直到这个写锁释放
 		由此也可得知，如果当一个goroutine希望获取写锁时，不断地有其他goroutine在获得读锁和释放读锁会导致这个写锁一直处于堵塞状态，所以让写锁的优先级高于读锁可以避免这种情况，

 		注意：6.读写锁适用于读多写少的情景。

 		Go 标准库中提供了 sync.RWMutex 互斥锁类型及其四个方法：
 			1、Lock 加写锁
			2、Unlock 释放写锁
			3、RLock 加读锁
			4、RUnlock 释放读锁


5、Map 源码
	1、Go语言中，一个map就是一个hash表的引用，它是一个无序的key/value 对的集合，其中所有的key都是不同的，然后通过key
	可以在常数时间复杂度内检索，更新，删除对应的value .
	2、Map实现的原理
	    1、在 go 中，map 同样也是数组存储的的，每个数组下标处存储的是一个 bucket,
	        每个 bucket 中可以存储 8 个 kv 键值对，当每个 bucket 存储的 kv 对到达 8 个之后，
	     会通过 overflow 指针指向一个新的 bucket，从而形成一个链表
        key 的 Hash 值低位用于在该数组中定位到桶，而高 8 位则用于在桶中区分 key/value 对。

		2、核心结构
			map 主要有两个核心结构，基础结构和桶结构：
			1、 hmap：map 的基础结构。
			2、 bmap：存放 key-value 的桶结构。
				严格来说 hmap.buckets 指向桶组成的数组，每个桶的头部是 bmap，之后是 8 个key，再是 8个 value，最后是 1 个溢出桶指针，指向额外的桶链表，用于存储溢出的元素。

			3、数据结构图
				1、创建 map 时，会初始化一个 hmap 结构体，同时分配一个足够大的内存空间 A。其中 A 的前段用于 hash 数组，A 的后段预留给溢出的桶

					其中 A 的前段用于 hash 数组，A 的后段预留给溢出的桶。于是 hmap.buckets 指向 hash 数组，即 A 的首地址；hmap.extra.nextOverflow 初始时指向内存 A 中的后段，即 hash 数组结尾的下一个桶，也即第 1 个预留的溢出桶。所以当 hash 冲突需要使用到新的溢出桶时，会优先使用上述预留的溢出桶。hmap.extra.nextOverflow 依次往后偏移直到用完所有的溢出桶，才有可能会申请新的溢出桶空间。
				2、参考结构图片：
				https://ask.qcloudimg.com/http-save/yehe-2609282/rafej6fyu0.png?imageView2/2/w/1620

				上图中，当需要分配一个溢出桶时，会优先从预留的溢出桶数组里取一个出来链接到链表后面，这时不需要再次申请内存。但当预留的溢出桶被用完了，则需要申请新的溢出桶

		3. 哈希冲突

		当有两个或以上数量的键被哈希到了同一个bucket时，我们称这些键发生了冲突。Go使用链地址法来解决键冲突。
		由于每个bucket可以存放8个键值对，所以同一个bucket存放超过8个键值对时就会再创建一个键值对，用类似链表的方式将bucket连接起来。
		参考图：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/bmp_bucket.jpeg

		4、扩容
			1、装载因子
			  loadFactor := count / (2^B) （count 就是 map 的元素个数，2^B 表示 bucket 数量。）

				装载因子是表示哈希表中元素的填满程度。它的计算公式：装载因子=填入哈希表中的元素个数/哈希表的长度。装载因子越大，填入的元素越多，空间利用率就越高，但发生哈希冲突的几率就变大。反之，装载因子越小，填入的元素越少，冲突发生的几率减小，但空间浪费也会变得更多，而且还会提高扩容操作的次数
			2、扩容流程
				1、确定扩容机制
					1、翻倍扩容
						触发 load factor 的最大值，负载因子已达到当前界限。这时候说明大部分的桶可能都快满了（即平均每个桶存储的键值对达到6.5个），表明很多 bucket 都快要装满了，查找效率和插入效率都变低了。在这个时候进行扩容是有必要的。
						将 B 加 1，bucket 最大数量（2^B）直接变成原来 bucket 数量的 2 倍。于是，就有新老 bucket 了。注意，这时候元素都在老 bucket 里，还没迁移到新的 bucket 来。而且，新 bucket 只是最大数量变为原来最大数量（2^B）的 2 倍（2^B * 2）。
					2、等量扩容
						判断溢出桶是否太多。
						1、当桶总数 < 2 ^ 15 时，如果溢出桶总数 >= 桶总数，则认为溢出桶过多。
						2、当桶总数 >= 2 ^ 15 时，直接与 2 ^ 15 比较，当溢出桶总数 >= 2 ^ 15 时，即认为溢出桶太多了。
					因为如果溢出桶的数量过多，也会导致map的查找效率下降。所以触发等量扩容但可以减少溢出桶的使用且使bmap的排列更加紧密。


				2、第二阶段：初始化、交换新旧 桶/溢出桶
					新申请的扩容空间（newbuckets/newoverflow）都是预分配，等真正使用的时候才会初始化。不管是增量扩容还是等量扩容，都需要创建新的桶数组，并不是原地操作的。
				3、扩容
					扩容完毕后（预分配），不会马上就进行迁移。而是采取增量扩容的方式，当有访问到具体 bukcet 时，才会逐渐的进行迁移（将 oldbucket 迁移到 bucket）
					即每次访问map时都会触发一次搬迁，每次搬迁2个键值对。当oldbuckets中的键值对全部搬迁完毕后，删除oldbuckets。

					1、为什么是增量扩容？
					如果是全量扩容的话，那问题就来了。假设当前 hmap 的容量比较大，直接全量扩容的话，就会导致扩容要花费大量的时间和内存，导致系统卡顿，最直观的表现就是慢。显然，不能这么做

					2、既然迁移是逐步进行的。那如果在途中又要扩容了，怎么办？
						结合源码上下文可得若正在进行扩容，就会不断地进行迁移。待迁移完毕后才会开始进行下一次的扩容动作。
        5、查找过程
            1、根据key计算出hash值。
            2、如果存在old table, 首先在old table中查找，如果找到的bucket已经evacuated，转到步骤3。 反之，返回其对应的value。
            3、在new table中查找对应的value。

		5、插入过程：
		    在扩容过程中，oldbucket是被冻结的，查找时会在oldbucket中查找，但不会在oldbucket中插入数据。如果在oldbucket是找到了相应的key，做法是将它迁移到新bucket后加入evalucated标记

        5、map的遍历
            1、本来 map 的遍历过程比较简单：遍历所有的 bucket 以及它后面挂的 overflow bucket，然后挨个遍历 bucket 中的所有 cell。每个 bucket 中包含 8 个 cell，从有 key 的 cell 中取出 key 和 value，这个过程就完成了。
            2、遍历如果发生在扩容的过程中，就会涉及到遍历新老 bucket 的过程
            3、map 遍历的核心在于理解 2 倍扩容时，老 bucket 会分裂到 2 个新 bucket 中去。而遍历操作，会按照新 bucket 的序号顺序进行，碰到老 bucket 未搬迁的情况时，要在老 bucket 中找到将来要搬迁到新 bucket 来的 key。

        6、使用建议
            1、从map设计可以知道，它并不是一个并发安全的数据结构。同时对map进行读写时，程序很容易出错。
                因此，要想在并发情况下使用map，请加上锁（sync.Mutex或者sync.RwMutex）。其实，Go标准库中已经为我们实现了并发安全的map——sync.Map

            2、遍历map的结果是无序的，在使用中，应该注意到该点。
                原因：Go 做得更绝，当我们在遍历 map 时，并不是固定地从 0 号 bucket 开始遍历，每次都是从一个随机值序号的 bucket 开始遍历，并且是从这个 bucket 的一个随机序号的 cell 开始遍历
            3、通过map的结构体可以知道，它其实是通过指针指向底层buckets数组。所以和slice一样，尽管go函数都是值传递，
               但是，当map作为参数被函数调用时，在函数内部对map的操作同样会影响到外部的map

            4、1.无论什么情况下len操作总是正常的
              2.同时read不会引发异常，同时read和write会异常，同时write会异常。
              3.read或write的同时，json.Marshall或json.Unmarshall此类解析方法也应避免使用，否则也会引发异常。
           5、map无序，若实现有序，可以参考map结合链表的方式。

6、Sync.Map
	sync.Map是协程安全的，并通过读写分离的机制，降低锁的粒度，提高并发性能。
		1、	type Map struct {
						mu Mutex 	// 互斥锁，当涉及到dirty数据的操作的时候，需要使用这个锁

						read atomic.Value // readOnly 。 是一个只读的数据结构，因为只读，并不会有读写冲突，从这个数据中读取总是安全的。

						dirty map[interface{}]*entry	// dirty数据 包含当前的map数据中的entries , 对于dirty的操作需要加锁，因为对它的操作可能会有读写竞争

						misses int // 当从Map中读取到entry的时候，如果read中不包含这个entry，会尝试从dirty中读取，这个时候会将misses加一，只有当misses累积到dirty的长度的时候，就会将dirty提升为read，避免从dirty中miss太多次，因为dirty需要加锁。
				}

		2、需要介绍下read的数据结构

			read的数据结构是：
				type readOnly struct {
					m       map[interface{}]*entry
					amended bool // 如果Map.dirty有些数据不在中read的时候，这个值为true
				}

			amended指明Map.dirty中有readOnly.m未包含的数据，所以如果从Map.read找不到数据的话，还要进一步到Map.dirty中查找


		3、介绍下entry数据结构
			type entry struct {
				p unsafe.Pointer // *interface{}
			}
			readOnly.m和Map.dirty存储的值类型是*entry,它包含一个指针p, 指向用户存储的value值。
			read和dirty有冗余数据，但这些数据是通过指针指向同一个数据，所以尽管Map的value会很大，但是冗余的空间占用还是有限的


		4、分别介绍load和store，delet，range

			4.1 Load
				加载方法，也就是提供一个键key,查找对应的值value。

				流程：
				1、首先从m.read中得到只读readOnly,从它的map中查找，不需要加锁。如果找到直接返回。如果没找到，并且m.dirty中有新数据，需要从m.dirty查找，这个时候需要加锁，并且 不管m.dirty中存不存在，都将misses计数加一。并且当misses值 和dirty中数据个数一样的时候。把dirty提升为read。接下来还是从read中直接读取。

				有两个需要关注的地方：
					1、一个是首先从m.read中加载，不存在的情况下，并且m.dirty中有新数据，加锁，然后从m.dirty中加载。
					2、二是这里使用了双检查的处理。
						if !ok && read.amended {
							m.mu.Lock()

						因为在加锁之前，m.dirty可能被提升为m.read,所以加锁后还得再检查m.read，后续的方法中都使用了这个方法。


			4.2 Store (更新或者新增一个entry)
				流程：
				1、如果m.read存在这个键，并且这个entry【没有被标记删除】，尝试直接存储。（因为m.dirty也指向这个entry,所以m.dirty也保持最新的entry）
				2、如果 m.read不存在这个值， 并且m.dirty中存在，则直接更新m.dirty的值
				3、如果m.read和 m.dirty中都不存在，那么是是一个新键值，插入到m.dirty中。（存在一个判断m.dirty是否有新更新数据操作。并且复制m.read数据到m.dirty中）

			4.3 delete （删除一个键值。）
				流程
				1、删除操作还是从m.read中开始， 如果这个entry不存在于m.read中，并且m.dirty中有新数据，则加锁尝试从m.dirty中删除。
				2、如果存在于m.read中。则从m.read中删除（注意：不是直接删除而是，打上已删除标记）

			4.4 Range(遍历操作)
				1、流程：（会根据read.amend值，先判断 m.dirty中是否有新数据，则提升m.dirty,然后在遍历）

7、切片（slice） 和 数组
	1、数组是一种有固定长度的基本数据结构，一旦创建长度就不允许修改，数组的空余位置用0填补，不允许越界，越界panic
	2、slice 是一个特殊的引用类型，本身也是个结构体
		type slice struct {
		    array unsafe.Pointer
		    len   int
		    cap   int
		}
	   1、属性len表示可用元素数量,读写操作不能超过这个限制,不然就会panic

       2、属性cap表示最大扩张容量,当然这个扩张容量也不是无限的扩张,它是受到了底层数组array的长度限制,超出了底层array的长度就会panic

		1、切片的创建
			1、通过数组创建
			2、通过 slice := make([]int ,3,5)
			切片是个引用类型,所以它作为参数传递给函数,函数操作的实质是底层数组
		2、	切片的扩容
			1、5、切片扩容后是新数组or 旧数组？
				1、如果原数组还有容量可以扩容，则在执行append（）操作后，会在原数组上直接操作，所以这时候，切片扩容后的数组还是指向的原来数组，并且原来数组会跟随改变。
				2、如果原来的数组的容量已经将达到了最大值，则在扩容时会根据扩容策略，开辟一片新的内存区域，把原来数组的值拷贝过来，然后执行append操作，这个时候不会影响原数组。
				1、扩容策略
					1、首先先判，如果新申请容量（cap）大于2倍的旧容量（old.cap）,最终容量（newCap）就是新申请的容量（cap）
					2、否则判断，如果旧切片的长度小于1024，则最终容量（newcap），就是旧容量（old.cap）的两倍。即newcap = 			doublecap
					3、否者判断，如果旧切片的长度大于等于1024，则最终容量（newcap）从旧容量	old.cap）的两倍。即newcap开始循环增加原来的1/4 即 （参考slice源码）newcap = old.cap for {newcap += newcap/4},直到最终容量（newcap) 大于等于新申请的容量cao .即 newcap 》= cap .
		3、切片作为函数参数是传值还是传引用
			理清三个重要的 概念。
	 	1、值传递
	 		值传递是指在调用函数时将实际参数拷贝一份传递到函数中，这样在函数中对参数进行修改不会影响到实际参数。

	 	2、传指针
	 		传指针是指 形参是指向实际参数的指针，当对形参的指向进行操作时，相当于对实参本身进行操作。
	 	3、引用传递是指调用函数时将实际参数的地址传递到函数中，在函数中对参数进行修改，影响实际参数。
	 		c++中才有引用传递。
	 	官方文档已经明确说明：Go里边函数传参只有值传递一种方式。但是，slice，channel，map 本身就是引用类型，因此可以修改外部的数据。

8、Sync.Once
	1、Once 可以用来执行且仅仅执行一次动作，常常用于用来初始化单例资源，或者并发访问只需初始化一次的共享资源，或者在测试的时候初始化一次测试资源。

	sync.Once 只暴露了一个方法 Do，你可以多次调用 Do 方法，但是只有第一次调用 Do 方法时 f 参数才会执行，这里的 f 是一个无参数无返回值的函数
		type Once struct {
		   done uint32 // 初始值为0表示还未执行过，1表示已经执行过
		   m    Mutex
	}

	2、Do函数
		1、调用 Do 函数时，首先判断done值是否为0，若为1，表示传入的匿名函数 f() 已执行过，无需再次执行；若为0，表示传入的匿名函数 f() 还未执行过，则调用 doSlow() 函数进行初始化。
		2、在 doSlow() 函数中，若并发的goroutine进入该函数中，为了保证仅有一个goroutine执行 f() 匿名函数。为此，需要加互斥锁保证只有一个goroutine进行初始化，同时采用了双检查的机制(double-checking)，再次判断 o.done 是否为 0，如果为 0，则是第一次执行，执行完毕后，就将 o.done 设置为 1，然后释放锁。


9、golang GC
	垃圾回收是编程语言中提供的自动的内存管理机制，目的是自动释放不需要的对象，让出存储器资源，这一过程无需由开发人员手动执行。

	1、golang GC 算法演变过程
		版本	GC 算法
			v1.1	Mark 、Sweep、STW （STW(stop the word)）
			v1.3	Mark STW,Sweep (标记清除)
			v1.5	三色标记
			v1.8	hybrid write barrier (三色标记基础上加入写屏障)

	2、Go V1.3之前的标记-清除(mark and sweep)算法
		此算法主要由两个步骤
			1、标记(Mark phase)
			2、清除(Sweep phase)

		1、第一步 暂停程序业务逻辑，程序找出它所有可达的对象，然后做上标记。
			操作非常简单，但是有一点需要额外注意：mark and sweep算法在执行的时候，需要程序暂停！即 STW(stop the world)。也就是说，这段时间程序会卡在哪儿
			参考图片：https://img.kancloud.cn/01/60/0160c38ec63623f3108550ff648f0959_1494x1248.png
		2、	标记完了之后，然后开始清除未标记的对象
			参考图：https://img.kancloud.cn/3e/a9/3ea9ec35364a573c669f5f32c03c8b50_1344x1326.png

		3、第四步, 停止暂停，让程序继续跑。然后循环重复这个过程，直到process程序生命周期结束。

		分析、标记-清扫(mark and sweep)的缺点
			1、STW，stop the world；让程序暂停，程序出现卡顿 (重要问题)。
			2、标记需要扫描整个heap，会产生heap碎片

	3、Go V1.3之前 和 v1.3版本的标记-清除(mark and sweep)算法	对比
		1、Go V1.3版本之前就是以上来实施的, 流程是：
			启动STW  => Mark标记 =》 Sweep清除 =〉 停止STW
			参考：https://img.kancloud.cn/c7/da/c7da67305d321015d28af3f505ccc748_2426x578.png
		2、Go V1.3 做了简单的优化,将STW提前, 减少STW暂停的时间范围.
			启动STW  => Mark标记 =》 停止STW =〉 Sweep清除
			参考 https://img.kancloud.cn/7f/c9/7fc93a9ae9387d34e9843eb1edec31fe_2410x520.png

		Go V1.3 及之前版本的 mark and Sweep 算法 最大的问题是 STW会造成程序卡顿。go V1.5提出了三色标记法，来优化这个问题。

	4、Go v1.5 三色标记法
		为了解决原始标记清除算法带来的长时间 STW。垃圾收集器都会实现三色标记算法的变种以缩短 STW 的时间。三色标记算法将程序中的对象分成白色、黑色和灰色三类：

		白色对象 — 潜在的垃圾，其内存可能会被垃圾收集器回收；
        黑色对象 — 活跃的对象，包括不存在任何引用外部指针的对象以及从根对象可达的对象；
        灰色对象 — 活跃的对象，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象；


        在垃圾收集器开始工作时，程序中不存在任何的黑色对象，垃圾收集的根对象会被标记成灰色，
        垃圾收集器只会从灰色对象集合中取出对象开始扫描，当灰色集合中不存在任何对象时，标记阶段就会结束。
            1、将根节点标记为灰色，其他节点标记为白色
            2、在灰色对象中选择一个标记为黑色
            3、将黑色对象指向的所有对象都标记为灰色
            4、重复前两个步骤直到所有对象中没有灰色对象
            5、清除所有白色对象

            如图：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/三色标记01.png

        1、标记阶段完成时，应用程序的堆中不存在任何灰色对象，只有黑色的活跃对象和白色的垃圾对象，垃圾收集器就会回收这些白色对象，下图中的白色对象 2 就是即将被回收的垃圾：
       如图： https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/三色标记02.png


    4、为什么要有屏障保护
    如果在三色标记法中 一个白色对象被黑色对象引用，是注定无法通过这个黑色对象来保证自身存活的。
    为了防止这种现象发生，最简单的方式就是STW，直接禁止掉其他用户程序对对象饮用关系的干扰。但是STW过程明显的浪费资源。
    因此需要屏障技术来保证对象不丢失的情况下尽可能的提高GC效率，减少STW时间。

  5、三色变式
      1、 想要在并发或者增量的标记算法中保证正确性，我们需要达成以下两种三色不变性（Tri-color invariant）中的一种：
            1、强三色不变性 — 黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象；
            2、弱三色不变性 — 黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径

            屏障技术就是在并发或增量标记过程中保证三色不变式的重要技术

              1、插入写屏障
                1、插入写屏弹是一种相对保守的屏障技术，它会将有存活可能的对象都标记为灰色以满足强三色不变式。

                2、在Golang中，对栈上指针的写入添加写屏障的成本很高，所以Go选择仅对堆上的指针插入增加写屏障，
                这样就会出现在扫描结束后，栈上仍存在引用白色对象的情况，这时的栈是灰色的，不满足三色不变式，
                所以需要对栈进行重新扫描使其变黑，完成剩余对象的标记，这个过程需要STW。
                这期间会将所有goroutine挂起，当有大量应用程序时，时间可能会达到10～100ms。

                在对象 𝐴 引用对象 𝐶 的时候，如果对象 𝐶 是白色，就将对象 𝐶 标记为灰色，其他情况则保持不变

                如图：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/插入写屏障.png


                在上图所示的垃圾回收过程中，实际上不再存活的的对象 𝐵 也保留到了最后，没有被回收。
                如果在第二步时再指 𝐴 到 𝐶 的指针指向 𝐵 ，虽然 𝐶 没有被任何对象引用，但其依然是灰色，
                不会被回收，只有在下次 GC 时才会被回收。

             2、删除写屏障
                1、删除写屏障也叫基于快照的写屏障方案，必须在起始时，STW 扫描整个栈（注意了，是所有的 goroutine 栈），
                    保证所有堆上在用的对象都处于灰色保护下，保证的是弱三色不变式；

                2、由于起始快照的原因，起始也是执行 STW，删除写屏障不适用于栈特别大的场景，栈越大，STW 扫描时间越长，
                    对于现代服务器上的程序来说，栈地址空间都很大，所以删除写屏障都不适用，
                    一般适用于很小的栈内存，比如嵌入式，物联网的一些程序；
                3、删除写屏障 存在精度问题，一个对象即使被删除后依旧可以活过这一轮 。

              当白色或灰色的对象的引用被删除时，将白色对象变为灰色。
                  如图：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/删除写屏障.png

             删除写屏障通过对对象 𝐶 的着色，保证了对象 𝐶 和下游的对象 𝐷 能够在这一次垃圾收集的循环中存活，避免发生野指针以保证用户程序的正确性。

            这样删除写屏障就可以保证弱三色不变式，能够保证白色对象的上游链路中一定存在灰色对象


            3、混合写屏障
               1、 插入写屏障和删除写屏障的短板：
                    1、插入写屏障：结束时需要STW来重新扫描栈，标记栈上引用的白色对象的存活；
                    2、删除写屏障：回收精度低，GC开始时STW扫描堆栈来记录初始快照，这个过程会保护开始时刻的所有存活对象。
                 Go V1.8版本引入了混合写屏障机制（hybrid write barrier），避免了对栈re-scan的过程，极大的减少了STW的时间。结合了两者的优点。

               2、在 v1.8 版本中，由插入写屏障和删除写屏障构成了如下所示的混合写屏障，其流程如下：
                     1、GC 开始，将栈上的全部可达对象标记为黑色，之后便不再需要进行重新扫描
                     2、GC 期间，任何在栈上新创建的对象都标记为黑色
                     3、写屏障将被删除的对象标记为灰色（堆）
                     4、写屏障将新添加的对象标记为灰色（堆）

                注意：     混合写屏障扫描栈虽然没有 STW，但是扫描某一个具体的栈的时候，还是要停止这个 goroutine
                           赋值器的工作的哈（针对一个 goroutine 栈来说，是暂停扫的，要么全灰，要么全黑哈，原子状态切换）；

                场景一 对象被一个堆对象删除引用，被一个栈对象引用。
                  1、第一步，将栈上可达对象全部标记为黑色：
                        如图：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/混合屏障01.png

                  2、第二步，对象 6 被对象 1 引用：
                     如图：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/混合屏障02.png

                  3、 第三步，断开与对象 5 的引用关系：
                     如图：https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/混合屏障03.png

                  对象 5 删除与对象 6 的引用关系，触发写屏障，将对象 6 标记为灰色


9、进程、线程、协程的区别
	1、进程
		1、进程是资源分配的基本单位，每个进程在创建的时候，都分配一个独立的进程地址空间，该进程地址空间称为虚拟内存空间，虚拟内存空间 对于进程而言 看到的是一整块连续的内存空间，但是落实到操作上则是 一块块内存碎片的的东西。主要为了节约内核空间，房间管理内存。
		2、每个进程独立的内存空间，又分为用户空间和内核空间。
			1、用户空间
			用户空间因CPU的“保护模式”只能访问受限的资源，也就是说用户空间是无法直接操作像内存、网卡和磁盘等硬件，只用于用户程序的运行
			2、内核空间
				内核空间可支持访问CPU所有的指令集（ring0 - ring3）以及所有的内存空间、IO及硬件设备；
				所有进程的内核空间，都映射到同一块物理内存区域，因此所有的进程，都共享内核空间。
			3、系统调用
				用户空间通过系统调用的方式访问内核空间。
				进程运行在用户空间时 处于用户态，通过系统调用运行在内核空间时处于内核态。也就是我们常说的是上下文切换。
		3、进程间通信（IPC）
			 由于每个进程的用户空间都是独立的，不能相互访问，这时就需要借助内核空间来实现进程间通信，原因很简单，每个进程都是共享一个内核空间。
		4、IPC的方式通常有
		    1、管道:通信的数据是无格式的流并且大小受限，通信的方式是单向的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道
		    2、消息队列:消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。
		    3、共享内存:mmp
		    4、信号量
		    5、信号:信号是进程间通信机制中唯一的异步通信机制，
		    6、Socket：
		    	要与不同主机的进程间通信，那么就需要 Socket 通信了。Socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 Socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。
		5、进程有三个状态:
	        1、等待态：等待某个事件的完成；
	        2、就绪态：等待系统分配处理器以便运行；
	        3、运行态：占有处理器正在运行。

    2、线程
    	1、线程是进程的一个执行单元，一个进程可以包涵多个线程，只有拥有了线程的进程才会被cpu执行，所以一个进程至少拥有一个线程。
    	2、共享进程资源。
    		在同一进程中的各个线程，都可以共享该进程所拥有的资源，这首先表现在：所有线程都具有相同的地址空间（进程的地址空间）
    	3、	因为进程资源共享，所以会产生资源竞争，需要通过锁机制来协同


    3、协程
    	1、协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。

10、Golang的GMP 调度
		goroutine是Go语言提供的一种用户态线程,我们也称之为协程。1个 goroutine 只占几 KB，并且这几 KB 就足够 goroutine 运行完，这就能在有限的内存空间内支持大量 goroutine，支持了更多的并发。
		Goroutine 特点：
			1、占用内存更小（几 kb）
			2、调度更灵活 (runtime 调度)

		1、名次解释
			1、

		1、早期的调度模型G-M
			1、早期的调度模型只有，G、M和 全局G队列。M 想要执行、放回 G 都必须访问全局 G 队列，并且 M 有多个，即多线程访问同一资源需要加锁进行保证互斥 / 同步，所以全局 G 队列是有互斥锁进行保护的。
			2、老调度器的缺点。
				1、创建、销毁、调度 G 都需要每个 M 获取锁，这就形成了激烈的锁竞争
				2、M 转移 G 会造成延迟和额外的系统负载。比如当 G 中包含创建新协程的时候，M 创建了 G’，为了继续执行 G，需要把 G’交给 M’执行，也造成了很差的局部性，因为 G’和 G 是相关的，最好放在 M 上执行，而不是其他 M’。
				3、系统调用 (CPU 在 M 之间的切换) 导致频繁的线程阻塞和取消阻塞操作增加了系统开销

		2、GMP调度模型
			在新调度器中，除了 M (thread) 和 G (goroutine)，又引进了 P (Processor)。
			Processor，调度器，它包含了运行 goroutine 的资源，如果线程想运行 goroutine，必须先获取 P，P 中还包含了可运行的 G 队列。
			(1) GMP 模型
				在 Go 中，线程是运行 goroutine 的实体，调度器的功能是把可运行的 goroutine 分配到工作线程上。

				1、全局队列（Global Queue）：
					存放等待运行的 G。在新的调度器中依然有全局 G 队列，但功能已经被弱化了，当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G。
				2、P 的本地队列
					同全局队列类似，存放的也是等待运行的 G，存的数量有限，不超过 256 个。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。
				3、P 列表：所有的 P 都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个。
				4、M：线程想运行任务就得获取 P，从 P 的本地队列获取 G，P 队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，或从其他 P 的本地队列偷一半放到自己 P 的本地队列。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。

				Goroutine 调度器和 OS 调度器是通过 M 结合起来的，每个 M 都代表了 1 个内核线程，OS 调度器负责把内核线程分配到 CPU 的核上执行

			参考：链接https://cdn.learnku.com/uploads/images/202003/11/58489/Ugu3C2WSpM.jpeg!large


			2、有关 P 和 M 的个数问题 ，P 和 M 何时会被创建

				1、P 的数量：由启动时环境变量 $GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。程序执行的任意时刻都只有 $GOMAXPROCS 个 goroutine 在同时运行。
				2、M 的数量。go 语言本身的限制：go 程序启动时，会设置 M 的最大数量，默认 10000.

				M 与 P 的数量没有绝对关系，一个 M 阻塞，P 就会去创建或者切换另一个 M，所以，即使 P 的默认数量是 1，也有可能会创建很多个 M 出来。

				3、P 何时创建：在确定了 P 的最大数量 n 后，运行时系统会根据这个数量创建 n 个 P。
				4、M 何时创建：没有足够的 M 来关联 P 并运行其中的可运行的 G。比如所有的 M 此时都阻塞住了，而 P 中还有很多就绪任务，就会去寻找空闲的 M，而没有空闲的，就会去创建新的 M。

			3、调度器的设计策略
				1、复用线程：避免频繁的创建、销毁线程，而是对线程的复用。
					1、work stealing 机制
						​ 当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。


					2、hand off 机制
						​ 当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。
				2、利用并行
					GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。GOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS = 核数/2，则最多利用了一半的 CPU 核进行并行。

				3、协作式调度：
					在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程，在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死，这就是 goroutine 不同于 coroutine 的一个地方。

				4、全局 G 队列：
					在新的调度器中依然有全局 G 队列，但功能已经被弱化了，当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G。

			4、Go 调度器调度场景过程全解析
				1、 场景 1
					假设 P 拥有 G1，M1 获取 P 后开始运行 G1，G1 使用 go func() 创建了 G2，为了局部性 G2 优先加入到 P1 的本地队列。
				2、场景 2
					G1 运行完成后 (函数：goexit)，M 上运行的 goroutine 切换为 G0，G0 负责调度时协程的切换（函数：schedule）。从 P 的本地队列取 G2，从 G0 切换到 G2，并开始运行 G2 (函数：execute)。实现了线程 M1 的复用。

				3、 场景 3
					假设每个 P 的本地队列只能存 4 个 G。G2 要创建了 6 个 G，前 4 个 G（G3, G4, G5，G6）已经加入 p1 的本地队列，p1 本地队列满了。
					看场景4
				4、	场景 4
					G2 在创建 G7 的时候，发现 P1 的本地队列已满，需要执行负载均衡 (把 P1 中本地队列中前一半的 G，还有新创建 G 转移到全局队列)，这些 G 被转移到全局队列时，会被打乱顺序。所以 G3,G4,G7 被转移到全局队列。


				5、场景 5
					G2 创建 G8 时，P1 的本地队列未满，所以 G8 会被加入到 P1 的本地队列。G8 加入到 P1 点本地队列的原因还是因为 P1 此时在与 M1 绑定，而 G2 此时是 M1 在执行。所以 G2 创建的新的 G 会优先放置到自己的 M 绑定的 P 上。
				6、场景 6
					在创建 G 时，运行的 G 会尝试唤醒其他空闲的 P 和 M 组合去执行。
					假定 G2 唤醒了 M2，M2 绑定了 P2，并运行 G0，但 P2 本地队列没有 G，M2 此时为自旋线程（没有 G 但为运行状态的线程，不断寻找 G）。
				7、场景7
					M2 尝试从全局队列 (简称 “GQ”) 取一批 G 放到 P2 的本地队列（函数：findrunnable()），至少从全局队列取 1 个 g，但每次不要从全局队列移动太多的 g 到 p 本地队列，给其他 p 留点。这是从全局队列到 P 本地队列的负载均衡。
				8、场景 8
					假设 G2 一直在 M1 上运行，经过 2 轮后，M2 已经把 G7、G4 从全局队列获取到了 P2 的本地队列并完成运行，全局队列和 P2 的本地队列都空了，如场景 8 图的左半部分。

					全局队列已经没有 G，那 m 就要执行 work stealing (偷取)：从其他有 G 的 P 哪里偷取一半 G 过来，放到自己的 P 本地队列。P2 从 P1 的本地队列尾部取一半的 G，本例中一半则只有 1 个 G8，放到 P2 的本地队列并执行。

				9、场景 9
					假设M3,M4 分别投去P1的G5，G6
					G1 本地队列 G5、G6 已经被其他 M 偷走并运行完成，当前 M1 和 M2 分别在运行 G2 和 G8，M3 和 M4 没有 goroutine 可以运行，M3 和 M4 处于自旋状态，它们不断寻找 goroutine。

					为什么要让 m3 和 m4 自旋，自旋本质是在运行，线程在运行却没有执行 G，就变成了浪费 CPU. 为什么不销毁现场，来节约 CPU 资源。因为创建和销毁 CPU 也会浪费时间，我们希望当有新
					goroutine 创建时，立刻能有 M 运行它，如果销毁再新建就增加了时延，降低了效率。当然也考虑了过多的自旋线程是浪费 CPU，所以系统中最多有 GOMAXPROCS 个自旋的线程
					(当前例子中的 GOMAXPROCS=4，所以一共 4 个 P)，多余的没事做线程会让他们休眠。

				10、场景 10
					假设G8 进行了阻塞系统调用，那么M2和P2就会立即解绑，P2会进行判断，如果P2本地队列有G，全局队列有G，或者有空闲的M，那么P2会唤醒一个M和他绑定，否则P2则会加入到空闲的P列表，等待M来获取可用的p


		总结，Go 调度器很轻量也很简单，足以撑起 goroutine 的调度工作，并且让 Go 具有了原生（强大）并发的能力。Go 调度本质是把大量的 goroutine 分配到少量线程上去执行，并利用多核并行，实现更强大的并发。
        	参考链接；https://learnku.com/articles/41728
11、逃逸分析
    1、说白了就是：逃逸分析是编译器用于决定变量分配到栈还是堆上的一种行为。
       go在一定程度上消除了堆和栈的区别，因为go在编译的时候进行了逃逸分析，来决定一个对象放到栈上还是堆上，
       不逃逸的对象放栈上，可能逃逸的放到堆上
    2、逃逸分析场景
        1、 情景1：典型的逃逸case，函数返回局部变量的指针。
                 func test1()*int{
                        var a =10
                        return &a
                    }
        2、 栈空间不足
               func test {
                            t := make([]int ,1000,1000)
                            s :=make([]itn,10000,10000)
                            for i:=0;i<len(s);i++{
                                s[i[]= i
                        }
                }

        3、动态类型逃逸
            很多函数参数为interface类型
            func main() {

            	fmt.Println("hello 程序猿编码")
            	fmt.Print("hello minger")
            }
            func Printf(format string, a ...interface{}) (n int, err error)
        4、被指针类型的slice，map 和 chan 引用的指针一定发生逃逸。
             备注：在stack overflow有人提问为什么使用指针的chan比使用值的chan慢30%，就是因为使用指针的chan发生了逃逸，gc拖慢了速度。
                   a := make([]*int,1)
                   b := 12
                   a[0] = &b

         5、逃逸分析的好处
                    终端运行命令查看逃逸分析日志：
                    go build -gcflags=-m        -m 会打印出逃逸分析的优化策略。

                1、减少gc压力，不逃逸的对象分配到栈上，当函数返回时就回收了资源，不需要gc标记清除
                2、逃逸分析后可以确定那变量可以分配到栈上，栈的分配比堆快，因此性能更好。

12、goroutine 内存泄漏
    1、什么是内存泄漏？
    内存泄露 memory leak，是指程序在申请内存后，无法释放已申请的内存空间，一次内存泄露危害可以忽略，但内存泄露堆积后果很严重，无论多少内存,迟早会被占光
    memory leak会最终会导致out of memory！
    2、golang 内存泄漏分析工具和场景。
        1、golang 提供的 pprof 工具可以很方便的分析性能上的问题比如cpu的使用情况，堆内存分配，goroutine 死锁情况等
            1、浏览器方式
                如果你的应用程序是一直运行的，比如 web 应用，那么可以使用net/http/pprof库，它能够在提供 HTTP 服务进行分析。
                1、 //引用pprof
                 import "net/http"
                 import_ "net/http/pprof"
                2、你的 HTTP 服务都会多出/debug/pprof，在浏览器中访问即可 ，会显示goroutine堆栈和内存分配信息。
            2、命令行方式
               使用命令 go tool pprof url可以获取指定的profile文件，比如：profile类型alloc已分配的内存，inuse代表使用中的内存。
               最常用的：top、list、traces，分别介绍一下。
               1、top 按指标大小列出前10个函数，比如内存是按内存占用多少，CPU是按执行时间多少。
               2、list 查看某个函数的代码，以及该函数每行代码的指标信息，如果函数名不明确，会进行模糊匹配，比如list main会列出main.main和runtime.main。
               3、traces 打印所有调用栈，以及调用栈的指标信息。

            3、内存泄漏场景
                1、resp.Body.Close() 没有关闭 导致的内存泄漏
                   http 源码包发现 一次建立连接，就会启动一个读goroutine和写goroutine。这就是为什么一次http.Get()会泄漏两个goroutine的来源，
                  resp.Body.Close() 没有调用 会导致 readLoop和 writeLoop 两个goroutine在 写入请求并获取response返回后，并没有跳出for循环，而继续阻塞在 下一次for循环的select 语句里面。
                  两个函数所在的goroutine并没有运行结束。
                   goroutine持续增加导致内存持续增加

                2、当在for循环里使用select + time.After的组合时会产生内存泄露
                    demo
                          for {
                                select {
                                    case x:=<-ch:
                                    println(x)
                                    case <-time.After(3.time.Minute)
                                        println(time.Now.Unix())
                                }
                            }

                            在for循环每次select的时候，都会实例化一个一个新的定时器。该定时器在3分钟后，才会被激活，但是激活后已经跟select无引用关系，被gc给清理掉。
                            换句话说，被遗弃的time.After定时任务还是在时间堆里面，定时任务未到期之前，是不会被gc清理的。
                            也就是说每次循环实例化的新定时器对象需要3分钟才会可能被GC清理掉

                            在go代码中，在for循环里不要使用select + time.After的组合，可以使用time.NewTimer替代

                            idleDuration := 3 * time.Minute
                                idleDelay := time.NewTimer(idleDuration)
                                defer idleDelay.Stop()

                                for {
                                    idleDelay.Reset(idleDuration)

                                    select {
                                        case x := <- ch:
                                            println(x)
                                        case <-idleDelay.C:
                                            return
                                        }
                                }

                3、channel
                     ch := make(chan int)
                    	for i := 0; i < 3; i++ {
                    		go func() { ch <- query() }()
                    	} //开启了三个协程，有两个协程堵塞
                    	return <-ch
                    	原因在于 无缓冲channel 均已经发送了（每次发送 3 个），但是在接收端并没有完全接收（只接收 1 次 ch），所诱发的 Goroutine 泄露。并且main函数本身也算是一个goroutine

                4、Mutex
                    var mutex sync.Mutex
                    	for i := 0; i < 10; i++ {
                    		go func() {
                    			mutex.Lock()
                    			total += 1
                    		}()
                    	}


                    	第一个互斥锁 sync.Mutex 加锁了，由于他可能在处理业务逻辑，或者是忘记 Unlock 解锁了。因此导致后面的所有 sync.Mutex 想加锁，却因锁未释放又都阻塞住了。 建议在加锁后来一句defer mutex.Unlock()

            4、编码goroutine泄露的建议
                为避免goroutine泄露造成内存泄露，启动goroutine前要思考清楚：

                1、goroutine如何退出？

                2、是否会有阻塞造成无法退出？如果有，那么这个路径是否会创建大量的goroutine？


    另外可以结合 go trace 用来跟踪 goroutines运行情况,跟pprof配合使用，可以起到事半功倍的效果。
13、反射
    1、golang的反射实现原理
        通过反射机制可以动态获取对象的类型、值、方法甚至动态改变对象的成员。
    2、反射的规则
        1、从接口值到反射对象的反射。
            1、从relfect.Value中获取接口interface的信息

        2、从反射对象到接口值的反射。
            1、已知类型后转换为其对应的类型的做法如下，直接通过Interface方法然后强制转换
                realValue := value.Interface().(已知的类型)
            2、未知原有类型【遍历探测其Filed】

        3、为了修改反射对象，其值必须可设置。
            reflect.Value是通过reflect.ValueOf(X)获得的，只有当X是指针的时候，才可以通过reflec.Value修改实际变量X的值，

    3、Golang reflect慢主要有两个原因
        1、涉及到内存分配以及后续的GC；
        2、reflect实现里面有大量的枚举，也就是for循环，比如类型之类的。

14、WaitGroup
    	WaitGroup是多个goroutine之间协作的一种实现方式，主要功能就是阻塞等待一组goroutine执行完成。
    	常用的使用场景：主goroutine调用Add函数设置需要等待的goroutine的数量,当每个goroutine执行完成后调用Done函数(将counter减1)，Wait函数用于阻塞等待直到该组中的所有goroutine都执行完成

    	1、waitGroup方法及数据结构概念。

      	type WaitGroup struct {
    		noCopy noCopy  / 该WaitGroup对象不允许拷贝使用,只能用指针传递
    		state1 [12]byte // 用户存储计数器(counter)和waiter的值。只需要64位，其中高32位是counter值，低32位值是waiter值，不直接使用unit64位，是因为uint64的原子操作需要64位操作系统，而32位系统下，可能会出现崩溃。所以使用btye数组来实现。32位系统下4字节对齐，64位系统下8字节对齐，所以申请12个字节。其中必定有8个字节是符合8字节对齐的。在state（）函数中有进行判断。
    	}

        state[0],   state[1],   state[2]
       64位   waiter,     counter,    sema
       32位    sema ,      waiter,   counter,
        从结构体中我们看到 waitgroup结构体中state1的格式很重要。共占12个字节,用于存储counter和waiter的值 sema就是传说中的信号量。

            1、waiter 是等待者计数，
            2、counter 是任务计数，
            3、sema 是信号量


    	2、state函数
    		state是一个内部函数，用于获取counter和 waiter的值

    	//获取counter  、 waiter的值  (counter是uint64的高32位，waiter是uint64的低32位)
    	func (wg *WaitGroup) state() *uint64 {
    		// 根据state1的起始地址分析,若是8字节对齐的,则直接用前8个字节作为*uint64类型
    		// 若不是,说明是4字节对齐,则后移4个字节后,这样必为8字节对齐,然后取后面8个字节作为*uint64类型
    		if uintptr(unsafe.Pointer(&wg.state1))%8 == 0 {
    			return (*uint64)(unsafe.Pointer(&wg.state1))
    		} else {
    			return (*uint64)(unsafe.Pointer(&wg.state1[4]))
    		}
    	}

    	3、Add 函数
    		用于增加或减少计数器(counter)的，如果计数器为0，则释放调用Wait方法时的阻塞，如果计数器为负，则panic
    		参考流程图：
    			https://mmbiz.qpic.cn/mmbiz_png/picLDrXZzlobmEsicxu1Bic6jmxjTu44hiaLlgNGupxmib49p514r4aqtyciaDWibcPOfdEzaY44S6rqYsNln0icVFk75w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1

    			关键判断：
    			//1.counter > 0,说明还不需要释放信号量，可以直接返回
    		//2. waiter  = 0 ,说明没有等待的goroutine，也不需要释放信号量，可以直接返回
    		if v > 0 || w == 0 {
    			return
    		}

    	4、done 函数
    		//将计数器(counter)的值减1
    		相当于Add(-1)

    	5、wait 函数
    		调用Wait方法会阻塞当前调用的goroutine直到 counter的值为0。会一直阻塞，一直等待，直到无需等待或信号量触发，才返回
    		参考流程图：
    		https://mmbiz.qpic.cn/mmbiz_png/picLDrXZzlobmEsicxu1Bic6jmxjTu44hiaLyuze241iaqn1nGjTcHf360keZkQxwPFXic23dW6SHiaPkvNia0ZYHiaqZtA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1

    	6、注意点
    	1.Add()必须在Wait()前调用

    	2.Add()设置的值必须与实际等待的goroutine个数一致，如果设置的值大于实际的goroutine数量，可能会一直阻塞。如果小于会触发panic

    	3. WaitGroup不可拷贝，可以通过指针传递，否则很容易造成BUG



15、内存对齐
	不是所有的硬件平台都能访问任意地址上的任意数据的；某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。
	1、为什么要内存对齐
		简单来说，操作系统的cpu不是一个字节一个字节访问内存的，是按2,4,8这样的字长来访问的。
		如32位系统访问粒度是4字节（bytes），64位系统的是8字节。当被访问的数据长度为 n 字节且该数据地址为n字节对齐，那么操作系统就可以一次定位到数据，这样会更加高效。无需多次读取、处理对齐运算等额外操作。
		demo：
			1、这么设计的目的，是减少 CPU 访问内存的次数，加大 CPU 访问内存的吞吐量。比如同样读取 8 个字节的数据，一次读取 4 个字节那么只需要读取 2 次。
			2、内存对齐对实现变量的原子性操作也是有好处的，每次内存访问是原子的，如果变量的大小不超过字长，那么内存对齐后，对该变量的访问就是原子的，
				demo: 变量 a、b 各占据 3 字节的空间，内存对齐后，a、b 占据 4 字节空间，CPU 读取 b 变量的值只需要进行一次内存访问。如果不进行内存对齐，CPU 读取 b 变量的值需要进行 2 次内存访问。第一次访问得到 b 变量的第 1 个字节，第二次访问得到 b 变量的后两个字节。
		简言之：合理的内存对齐可以提高内存读写的性能，并且便于实现变量操作的原子性。方便不同平台 移植平台原因(移植原因)
		不是所有的硬件平台都能访问任意地址上的任意数据的；某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。

	2、go语言通过unsafe.Alignof 描述对齐规则
		1、对任意类型的变量X，unsafe.AlignOf（x）至少为1
		2、对于struct结构体类型变量X，计算每一个字段f 的 unsafe.Alignof(x),unsafe.AlignOf(x)等于其中最大值
		3、对于array数组类型的变量x，unsafe.Align(x) 等于构成数组的元素类型的对齐倍数。

	3、struct内存对齐的技巧
		1、合理布局可以减少内存占用
			假设一个 struct 包含三个字段，a int8、b int16、c int64
			顺序会对 struct 的大小产生影响顺序会对 struct 的大小产生影响
			type demo1 struct {
				a int8
				b int16
				c int32
			}

			type demo2 struct {
				a int8
				c int32
				b int16
			}
			每个字段按照自身的对齐倍数来确定在内存中的偏移量，字段排列顺序不同，上一个字段因偏移而浪费的大小也不同。

			1、接下来逐个分析，首先是 demo1：
			1、a 是第一个字段，默认是已经对齐的，从第 0 个位置开始占据 1 字节。
			2、b 是第二个字段，对齐倍数为 2，因此，必须空出 1 个字节，偏移量才是 2 的倍数，从第 2 个位置开始占据 2 字节。
			3、c 是第三个字段，对齐倍数为 4，此时，内存已经是对齐的，从第 4 个位置开始占据 4 字节即可。
			因此 demo1 的内存占用为 8 字节

			其实是 demo2：

		    1、是第一个字段，默认是已经对齐的，从第 0 个位置开始占据 1 字节。
			2、c 是第二个字段，对齐倍数为 4，因此，必须空出 3 个字节，偏移量才是 4 的倍数，从第 4 个位置开始占据 4 字节。
			3、b 是第三个字段，对齐倍数为 2，从第 8 个位置开始占据 2 字节。
			demo2 的对齐倍数由 c 的对齐倍数决定，也是 4，因此，demo2 的内存占用为 12 字节。

			因此，在对内存特别敏感的结构体的设计上，我们可以通过调整字段的顺序，减少内存的占用。

	4、 空 struct{} 的对齐
			空 struct{} 大小为 0，作为其他 struct 的字段时，一般不需要内存对齐。但是有一种情况除外：即当 struct{} 作为结构体最后一个字段时，需要内存对齐。因为如果有指针指向该字段, 返回的地址将在结构体之外，如果此指针一直存活不释放对应的内存，就会有内存泄露的问题（该内存不因结构体释放而释放）。

			type demo3 struct {
				c int32
				a struct{}
			}

			type demo4 struct {
				a struct{}
				c int32
			}

			func main() {
				fmt.Println(unsafe.Sizeof(demo3{})) // 8
				fmt.Println(unsafe.Sizeof(demo4{})) // 4
			}

			可以看到，demo4{} 的大小为 4 字节，与字段 c 占据空间一致，而 demo3{} 的大小为 8 字节，即额外填充了 4 字节的空间。

        参考链接：https://geektutu.com/post/hpg-struct-alignment.html


