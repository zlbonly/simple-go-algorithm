五、RPC
    RPC 基本概念
    	1、RPC(Remote Procdure Call)

    	RPC(Remote Procedure Call)，远程过程调用，大部分的RPC框架都遵循如下三个开发步骤：
    	1. 定义一个接口说明文件：描述了对象(结构体)、对象成员、接口方法等一系列信息；
    	2. 通过RPC框架所提供的编译器，将接口说明文件编译成具体的语言文件；
    	3. 在客户端和服务器端分别引入RPC编译器所生成的文件，即可像调用本地方法一样调用服务端代码；

    	rpc 通信流程如图：
    		https://img-blog.csdn.net/20170207141803075?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbGloYW8yMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast

    	通信过程包括以下几个步骤：
    		1、客户过程以正常方式调用客户桩（client stub，一段代码）；
    		2、客户桩生成一个消息，然后调用本地操作系统；
    		3、客户端操作系统将消息发送给远程操作系统；
    		4、远程操作系统将消息交给服务器桩（server stub，一段代码）；
    		5、服务器桩将参数提取出来，然后调用服务器过程；
    		6、服务器执行要求的操作，操作完成后将结果返回给服务器桩；
    		7、服务器桩将结果打包成一个消息，然后调用本地操作系统；
    		8、服务器操作系统将含有结果的消息发送回客户端操作系统；
    		9、客户端操作系统将消息交给客户桩；
    		10、客户桩将结果从从消息中提取出来，返回给调用它的客户过程；

    	1、Thrift
    		thrift主要用于各个服务之间的RPC通信，支持跨语言。thrift是一个典型的CS结构，客户端和服务端可以使用不同的语言开发，thrift通过IDL(Interface Description Language)来关联客户端和服务端

    		thrift通信流程：
    			Thrift实际上是实现了C/S模式，通过代码生成工具将thrift文生成服务器端和客户端代码（可以为不同语言），从而实现服务端和客户端跨语言的支持。用户在Thirft文件中声明自己的服务，这些服务经过编译后会生成相应语言的代码文件，然后客户端调用服务，服务器端提服务便可以了。


    	 1.1 thrift 网络通信

    	 	thrift的网路通信是自己开发实现的，架构图如下：
    	 	如图：https://images2018.cnblogs.com/blog/645085/201803/645085-20180304155305568-1935823842.png

    	 	协议栈的其他模块都是Thrift的运行时模块：

    			底层IO模块，负责实际的数据传输，包括Socket，文件，或者压缩数据流等。

    			TTransport负责以字节流方式发送和接收Message，是底层IO模块在Thrift框架中的实现，每一个底层IO模块都会有一个对应TTransport来负责Thrift的字节流(Byte Stream)数据在该IO模块上的传输。例如TSocket对应Socket传输，TFileTransport对应文件传输。

    			TProtocol主要负责结构化数据组装成Message，或者从Message结构中读出结构化数据。TProtocol将一个有类型的数据转化为字节流以交给TTransport进行传输，或者从TTransport中读取一定长度的字节数据转化为特定类型的数据。如int32会被TBinaryProtocol Encode为一个四字节的字节数据，或者TBinaryProtocol从TTransport中取出四个字节的数据Decode为int32。

    			TServer负责接收Client的请求，并将请求转发到Processor进行处理。TServer主要任务就是高效的接受Client的请求，特别是在高并发请求的情况下快速完成请求。

    			Processor(或者TProcessor)负责对Client的请求做出相应，包括RPC请求转发，调用参数解析和用户逻辑调用，返回值写回等处理步骤。Processor是服务器端从Thrift框架转入用户逻辑的关键流程。Processor同时也负责向Message结构中写入数据或者读出数据。

    	 	1、TProtocol（协议层），定义数据传输格式，例如：
    		TBinaryProtocol：二进制格式；
    		TCompactProtocol：压缩格式；
    		TJSONProtocol：JSON格式；
    		TSimpleJSONProtocol：提供JSON只写协议, 生成的文件很容易通过脚本语言解析；
    		TDebugProtocol：使用易懂的可读的文本格式，以便于debug

    		2、TTransport（传输层），定义数据传输方式，可以为TCP/IP传输，内存共享或者文件共享等）被用作运行时库。
    		TSocket：阻塞式socker；
    		TFramedTransport：以frame为单位进行传输，非阻塞式服务中使用；
    		TFileTransport：以文件形式进行传输；
    		TMemoryTransport：将内存用于I/O，java实现时内部实际使用了简单的ByteArrayOutputStream；
    		TZlibTransport：使用zlib进行压缩， 与其他传输方式联合使用，当前无java实现；

    		3、Thrift支持的服务模型

    		TSimpleServer
    			简单的单线程服务模型，常用于测试。只在一个单独的线程中以阻塞I/O的方式来提供服务。所以它只能服务一个客户端连接，其他所有客户端在被服务器端接受之前都只能等待。
    		TNonblockingServer
    			它使用了非阻塞式I/O，使用了java.nio.channels.Selector，通过调用select()，它使得程序阻塞在多个连接上，而不是单一的一个连接上。TNonblockingServer处理这些连接的时候，要么接受它，要么从它那读数据，要么把数据写到它那里，然后再次调用select()来等待下一个准备好的可用的连接。通用这种方式，server可同时服务多个客户端，而不会出现一个客户端把其他客户端全部“饿死”的情况。缺点是所有消息是被调用select()方法的同一个线程处理的，服务端同一时间只会处理一个	消息，并没有实现并行处理。
    		THsHaServer（半同步半异步server）
    			针对TNonblockingServer存在的问题，THsHaServer应运而生。它使用一个单独的线程专门负责I/O，同样使用java.nio.channels.Selector，通过调用select()。然后再利用一个独立的worker线程池来处理消息。只要有空闲的worker线程，消息就会被立即处理，因此多条消息能被并行处理。效率进一步得到了提高。
    		TThreadedSelectorServer
    			它与THsHaServer的主要区别在于，TThreadedSelectorServer允许你用多个线程来处理网络I/O。它维护了两个线程池，一个用来处理网络I/O，另一个用来进行请求的处理。
    		TThreadPoolServer
    			它使用的是一种多线程服务模型，使用标准的阻塞式I/O。它会使用一个单独的线程来接收连接。一旦接受了一个连接，它就会被放入ThreadPoolExecutor中的一个worker线程里处理。worker线程被绑定到特定的客户端连接上，直到它关闭。一旦连接关闭，该worker线程就又回到了线程池中。
    			这意味着，如果有1万个并发的客户端连接，你就需要运行1万个线程。所以它对系统资源的消耗不像其他类型的server一样那么“友好”。此外，如果客户端数量超过了线程池中的最大线程数，在有一个worker线程可用之前，请求将被一直阻塞在那里。
    			如果提前知道了将要连接到服务器上的客户端数量，并且不介意运行大量线程的话，TThreadPoolServer可能是个很好的选择。

    	 4、thrift 如何实现多语言通信
    	 	1、数据传输使用socket(多种语言均支持)，数据在以特定的格式(String等)发送，接收方语言进行解析
    	 	2、定义thrift的文件，由thrift文件(IDL)生成双方语言的接口、model，在生成的model以及接口中会有解码编码的代码

     2、grpc
            grpc 是一个高性能，开源和通用的rpc框架，面向移动和HTTP/2设计。

            		调用模型

            		1、客户端（gRPC Stub）调用 A 方法，发起 RPC 调用。

            		2、对请求信息使用 Protobuf 进行对象序列化压缩（IDL）。

            		3、服务端（gRPC Server）接收到请求后，解码请求体，进行业务逻辑处理并返回。

            		4、对响应结果使用 Protobuf 进行对象序列化压缩（IDL）。

            		5、客户端接受到服务端响应，解码请求体。回调被调用的 A 方法，唤醒正在等待响应（阻塞）的客户端调用并返回响应结果。


            		Protocol Buffer 3 :是一种类似XML但更灵活和高效的结构化数据存储格式。
            		protobuf会对proto协议文件进行序列化，最终转换成二进制数据
            		优点： 快：编解码基本都是位运算，也没有复杂的嵌套关系，速度快。


            		Http2协议详解：（HTTP/2（超文本传输协议第2版，最初命名为HTTP2.0），是HTTP协议的第二个主要版本）

            		HTTP1.x的缺点：
            		1、HTTP/1.0一次只允许在一个TCP连接上发起一个请求，HTTP/1.1使用的流水线技术也只能部分处理请求并发，仍然会存在队列头阻塞问题，因此客户端在需要发起多次请求时，通常会采用建立多连接来减少延迟。
            		即（在 HTTP/1.1 协议中 「浏览器客户端在同一时间，针对同一域名下的请求有一定数量限制。超过限制数目的请求会被阻塞」）
            		2、单向请求，只能由客户端发起。
            		3、请求报文与响应报文首部信息冗余量大。
            		4、数据未压缩，导致数据的传输量大。

            		HTTP2.0特点：

            		1、多路复用
            			多路复用允许同时通过单一的 HTTP/2 连接发起多重的请求-响应消息。

            		2、二进制分帧传
            			在HTTP1.x中，我们是通过文本的方式传输数据，而HTTP2.中 在 应用层(HTTP/2)和传输层(TCP or UDP)之间增加一个二进制分帧层，采用二进制传输。其中HTTP1.x的首部信息会被封装到Headers帧，而Request Body则封装到Data帧。

            		3、服务器Push
            			在HTTP2.0中，服务端可以在客户端某个请求后，主动推送其他资源。


            源码阅读参考https://www.bookstack.cn/read/grpc-read/12-grpc%20%E6%95%B0%E6%8D%AE%E6%B5%81%E8%BD%AC.md

     3、自己动手实现geerpc(github)









Http2.0协议

1、HTTP1.X 存在的问题
	1、HTTP/1.0一次只允许在一个TCP连接上发起一个请求，HTTP/1.1使用的流水线技术也只能部分处理请求并发，仍然会存在队列头阻塞问题，因此客户端在需要发起多次请求时，通常会采用建立多连接来减少延迟。
	2、单向请求，只能由客户端发起。
	3、请求报文与响应报文首部信息冗余量大。
	4、数据未压缩，导致数据的传输量大

2、HTTP2.0

	1、二进制分帧
	在不改变HTTP1.x的语义、方法、状态码、URL以及首部字段的情况下.
	HTTP2.0是在应用层（HTTP）和传输层（TCP）之间增加一个二进制分帧层。
	在二进制分帧层上，HTTP2.0会将所有传输的信息分为更小的消息和帧，并采用二进制格式编码，其中HTTP1.x的首部信息会被封装到Headers帧，而Request Body则封装到Data帧。

	HTTP2.0 -> BinaryFraming -> TSL -> TCP -> IP

	2、首部压缩
		1、HTTP1.1并不支持HTTP首部压缩 在HTTP1.0中，我们使用文本的形式传输header，在header中携带cookie的话，每次都需要重复传输几百到几千的字节，这着实是一笔不小的开销。

		2、在HTTP2.0中，我们使用了HPACK（HTTP2头部压缩算法）压缩格式对传输的header进行编码，减少了header的大小。并在两端维护了索引表，用于记录出现过的header，后面在传输过程中就可以传输已经记录过的header的键名，对端收到数据后就可以通过键名找到对应的值
	3、多路复用
		在HTTP1.x中，我们经常会使用到雪碧图、使用多个域名等方式来进行优化，都是因为浏览器限制了同一个域名下的请求数量，当页面需要请求很多资源的时候，队头阻塞（Head of line blocking）会导致在达到最大请求时，资源需要等待其他资源请求完成后才能继续发送。

		HTTP2.0中,基于二进制分帧层，HTTP2.0可以在共享TCP连接的基础上同时发送请求和响应。HTTP消息被分解为独立的帧，而不破坏消息本身的语义，交错发出去，在另一端根据流标识符和首部将他们重新组装起来。 通过该技术，可以避免HTTP旧版本的队头阻塞问题，极大提高传输性能。

	4、 服务器推送
		HTTP2.0新增的一个强大的新功能，就是服务器可以对一个客户端请求发送多个响应。服务器向客户端推送资源无需客户端明确的请求。

		在HTTP2.0中，服务器可以对一个客户端的请求发送多个响应。如果一个请求是由你的主页发送的，服务器可能会响应主页内容、logo以及样式表，因为他知道客户端会用到这些东西。这样不但减轻了数据传送冗余步骤，也加快了页面响应的速度，提高了用户体验。
		推送的缺点：所有推送的资源都必须遵守同源策略。换句话说，服务器不能随便将第三方资源推送给客户端，而必须是经过双方的确认才行。





rpc： 流程


gRPC
1、简介
	 gRPC 里客户端应用可以像调用本地对象一样直接调用另一台不同的机器上服务端应用的方法，使得您能够更容易地创建分布式应用和服务。与许多 RPC 系统类似，gRPC 也是基于以下理念：定义一个服务，指定其能够被远程调用的方法（包含参数和返回类型）。在服务端实现这个接口，并运行一个 gRPC 服务器来处理客户端调用。在客户端拥有一个存根能够像服务端一样的方法。


2、gRPC的特性
		基于HTTP/2
	HTTP/2 提供了连接多路复用、双向流、服务器推送、请求优先级、首部压缩等机制。可以节省带宽、降低TCP链接次数、节省CPU，帮助移动设备延长电池寿命等。gRPC 的协议设计上使用了HTTP2 现有的语义，请求和响应的数据使用HTTP Body 发送，其他的控制信息则用Header 表示。

	IDL使用ProtoBuf
	gRPC使用ProtoBuf来定义服务，ProtoBuf是由Google开发的一种数据序列化协议（类似于XML、JSON、hessian）。ProtoBuf能够将数据进行序列化，并广泛应用在数据存储、通信协议等方面。压缩和传输效率高，语法简单，表达力强。


3、grpc原理：
	1、GRPC服务端创建流程
	1、NettyServer的创建，gRpc服务端的创建，初始化nettyServer，nettyServer负责监听socket地址，实习基于HTTP2协议的写入
	2、绑定IDL定义服务接口实现类，grpc和一些RPC框架的不同是，服务的接口实现类并不是同过反射实现的，而是通过proto工具生成的代码，服务启动后，将服务的接口实现类注册到gRpc内部的服务注册中心上，请求消息来后，便可以通过服务名和方法名调用 ，直接调用启动的时候注册的服务实例，不需要反射进行调用，性能更优
	3、ServerImpl 负责整个 gRPC 服务端消息的调度和处理，创建 ServerImpl 实例过程中，会对服务端依赖的对象进行初始化，例如 Netty 的线程池资源,gRPC 的线程池、内部的服务注册类（InternalHandlerRegistry)。



4、gRPC 有那四种服务类型。
服务类型	 特点
1、简单 RPC	一般的rpc调用，传入一个请求对象，返回一个返回对象
2、服务端流式 RPC	传入一个请求对象，服务端可以返回多个结果对象
3、客户端流式 RPC	客户端传入多个请求对象，服务端返回一个结果对象
4、双向流式 RPC	结合客户端流式RPC和服务端流式RPC，可以传入多个请求对象，返回多个结果对象

5、protobuf3协议
    1、ProtoBuf是什么
        全称为Protocol Buffers，Google推出的序列化框架，用于将自定义数据结构序列化成字节流，和将字节流反序列化为数据结构，该框架不依赖开发语言，也不依赖运行平台，扩展性好，目前支持的语言比较多，包括Java，C++，Python，Ruby等。
    2、ProtoBuf支持字段类型
        int32：可变长编码，也就是不是固定占用4个字节，一般用于保存正整数。

        uint32：可变长编码。

        sin32：可变长编码，存储负数时建议用这个。

        fixed32：固定占用4个字节。

        bool：布尔类型

        string：字符串

    3、Protobuf原理
        protobuf会对proto协议文件进行序列化，最终转换成二进制数据，在这个转换过程中，protobuf做了一些优化，使得转换出来的二进制数据尽可能的小，同时也具有安全，编解码快等特点。

        https://juejin.cn/post/6844904007811465229




6、自实现rpc 需要的流程： 我觉得最重要的分为3步

		1、需要定义  服务端和客户端 通信消息的编码。
			1、encoding/gob，json
			2、序列化 和 反序列化
			3、例如 grpc 使用的protobuf
		2、网络通信
			1、需要定义网络通信协议（http,http2.0,tcp,udp）
			2、rpc 长使用netty 网络通信框架（同步非阻塞NIO，例如grpc底层就是使用 netty 封装的http2.0）


		3、服务发现和注册中心

			1、服务端启动后，向注册中心发送注册消息，注册中心得知该服务已经启动，处于可用状态。一般来说，服务端还需要定期向注册中心发送心跳，证明自己还活着。
			2、客户端向注册中心询问，当前哪天服务是可用的，注册中心将可用的服务列表返回客户端。
			3、客户端根据注册中心得到的服务列表，选择其中一个发起调用。



			框架etcd consul，以及实现相应的负载均衡策略 例如：1、轮训 2、随机 3、一致性hash算法）


7、可以介绍下网上看到的GeeRPC
	GeeRPC 选择从零实现 Go 语言官方的标准库 net/rpc，并在此基础上，新增了协议交换(protocol exchange)、注册中心(registry)、服务发现(service discovery)、负载均衡(load balance)、超时处理(timeout processing)等特性

	大致分为：
		1、服务端与消息编码
			1、定义消息编码采用：encoding/gob, application/json
			2、实现了服务端的雏形，建立连接，读取、处理并回复客户端的请求。
				服务端主要，主要包含三个阶段

				1、读取请求 readRequest （ for 无限制地等待请求的到来，直到发生错误（例如连接被关闭，接收到的报文有问题等）
				2、处理请求 handleRequest （使用了协程并发执行请求）
				3、回复请求 sendResponse （处理请求是并发的，但是回复请求的报文必须是逐个发送的，并发容易导致多个回复报文交织在一起，客户端无法解析。在这里使用锁(sending)保证。）
		2、	实现客户端
			1、客户端 主要 发送请求 和 接收响应。（使用子协程接收）

		3、服务注册：
			1、通过反射实现服务注册功能。
				RPC 框架的一个基础能力是：像调用本地程序一样调用远程服务。因此需要将结构体的方法映射为服务

		4、增加连接超时的处理机制
			超时处理是 RPC 框架一个比较基本的能力，如果缺少超时处理机制，无论是服务端还是客户端都容易因为网络或其他错误导致挂死，资源耗尽，这些问题的出现大大地降低了服务的可用性。因此，我们需要在 RPC 框架中加入超时处理的能力

			GeeRPC 在 3 个地方添加了超时处理机制。分别是：

			1）客户端创建连接时
			2）客户端 Client.Call() 整个过程导致的超时（包含发送报文，等待处理，接收报文所有阶段）
			3）服务端处理报文，即 Server.handleRequest 超时。

		5、客户端实现负载均衡
			1、负载均衡策略用的是 轮询&随机，也可以使用（一致性hash）

		6、 服务发现与注册中心
			1、实现一个简单的注册中心，支持服务注册、接收心跳等功能
				map	维护一个服务列表，并且使用定时器 定时监测服务是否可用

			2、客户端实现基于注册中心的服务发现机制，

			1、服务端启动后，向注册中心发送注册消息，注册中心得知该服务已经启动，处于可用状态。一般来说，服务端还需要定期向注册中心发送心跳，证明自己还活着。
			2、客户端向注册中心询问，当前哪天服务是可用的，注册中心将可用的服务列表返回客户端。
			3、客户端根据注册中心得到的服务列表，选择其中一个发起调用。

			2、客户端实现基于注册中心的服务发现机制




http 和 rpc 的区别

1、两则都是应用调用另一个应用的解决方案
    1、暴露接口  使用http调用，并给接口定义一些 restful规范
        基于Restful的远程过程调用有着明显的缺点，主要是效率低、封装调用复杂。当存在大量的服务间调用时，这些缺点变得更为突出。

    2、远程过程调用rpc
        RPC要求在调用方中放置被调用的方法的接口。调用方只要调用了这些接口，就相当于调用了被调用方的实际方法，十分易用。


2、不同点：

1、传输协议

    RPC，可以基于TCP协议，也可以基于HTTP协议
    HTTP，基于HTTP协议（在TCP协议之上进行封装）

2、传输效率
RPC，使用自定义的TCP协议，可以让请求报文体积更小，或者使用HTTP2协议，也可以很好的减少报文的体积，提高传输效率
HTTP，如果是基于HTTP1.1的协议，请求中会包含很多无用的内容，如果是基于HTTP2.0，那么简单的封装以下是可以作为一个RPC来使用的，这时标准RPC框架更多的是服务治理

3、性能消耗，主要在于序列化和反序列化的耗时

    RPC，可以基于thrift实现高效的二进制传输

    HTTP，大部分是通过json来实现的，字节大小和序列化耗时都比thrift要更消耗性能

4、负载均衡

    RPC，基本都自带了负载均衡策略

    HTTP，需要配置Nginx，HAProxy来实现

服务治理（下游服务新增，重启，下线时如何不影响上游调用者）

    RPC，能做到自动通知，不影响上游

    HTTP，需要事先通知，修改Nginx/HAProxy配置


介绍实现rpc 需要的流程：
    1、服务端与消息编码
			1、定义消息编码采用：encoding/gob, application/json
			2、实现了服务端的雏形，建立连接，读取、处理并回复客户端的请求。
				服务端主要，主要包含三个阶段

				1、读取请求 readRequest （ for 无限制地等待请求的到来，直到发生错误（例如连接被关闭，接收到的报文有问题等）
				2、处理请求 handleRequest （使用了协程并发执行请求）
				3、回复请求 sendResponse （处理请求是并发的，但是回复请求的报文必须是逐个发送的，并发容易导致多个回复报文交织在一起，客户端无法解析。在这里使用锁(sending)保证。）
		2、	实现客户端
			1、客户端 主要 发送请求 和 接收响应。（使用子协程接收）

		3、服务注册：
			1、通过反射实现服务注册功能。
				RPC 框架的一个基础能力是：像调用本地程序一样调用远程服务。因此需要将结构体的方法映射为服务

		4、增加连接超时的处理机制
			超时处理是 RPC 框架一个比较基本的能力，如果缺少超时处理机制，无论是服务端还是客户端都容易因为网络或其他错误导致挂死，资源耗尽，这些问题的出现大大地降低了服务的可用性。因此，我们需要在 RPC 框架中加入超时处理的能力

			GeeRPC 在 3 个地方添加了超时处理机制。分别是：

			1）客户端创建连接时
			2）客户端 Client.Call() 整个过程导致的超时（包含发送报文，等待处理，接收报文所有阶段）
			3）服务端处理报文，即 Server.handleRequest 超时。

		5、客户端实现负载均衡
			1、负载均衡策略用的是 轮询&随机，也可以使用（一致性hash）

		6、 服务发现与注册中心
			1、实现一个简单的注册中心，支持服务注册、接收心跳等功能
				map	维护一个服务列表，并且使用定时器 定时监测服务是否可用

			2、客户端实现基于注册中心的服务发现机制，

			1、服务端启动后，向注册中心发送注册消息，注册中心得知该服务已经启动，处于可用状态。一般来说，服务端还需要定期向注册中心发送心跳，证明自己还活着。
			2、客户端向注册中心询问，当前哪天服务是可用的，注册中心将可用的服务列表返回客户端。
			3、客户端根据注册中心得到的服务列表，选择其中一个发起调用。

			2、客户端实现基于注册中心的服务发现机制