1、缓存穿透 Cache Penetration
   1、 缓存穿透是指数据库中没有符合条件的数据（或者必然不存在的数据时），缓存服务器中也就没有缓存数据，
    导致业务系统每次都绕过缓存服务器查询下游的数据库，缓存服务器完全失去了其应用的作用

    如果黑客试图发起针对该 key 的大量访问攻击，数据库将不堪重负，最终可能导致崩溃宕机。从上图可以看出直接穿过缓存到达下游数据库，大致业务流程如下:
     https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/redis-cache-Penetration.jpeg
    2、解决方案
        1.存储空值/默认值
        虽然数据库中没有符合条件的数据，可以考虑缓存空值或适合业务的默认值，来缓解这种情况。
        为了降低数据的不一致需要注意两点：1. 缓存的过期时间需要设置的比较短；2. 当数据库数据更新时也需要及时更新缓存中对应的数据。
         （另外还需要 不信任传递的参数，根据业务 过滤响应不符合条件的参数请求。）
        2、布隆过滤器(Bloom Filter)
            布隆过滤器是一种比较巧妙的概率性数据结构，它可以告诉你数据一定不存在或可能存在，相比 Map、Set、List 等传统数据结构它占用内存少、结构更高效。
            比如有一个下面这样的数据结构，每个存储位存储的都是一个 big，即 0 或 1
            如图： https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/boom-filter1.jpeg


            当我们向缓存中插入 key 为 name 的缓存数据时，先使用 N 种不同的 hash 函数做 N 次 hash 得到 N 个哈希值，在上面的数据结构中找到对应哈希值的下标，
            并把存储数据设置为 1。假如 N=3，我们可以使用 hash1、hash2、hash3 分别计算出了哈希值为 8，15 和 13，则将其对应下标的数据设置为 1，如下图
             如图： https://github.com/zlbonly/simple-go-algorithm/blob/master/pics/boom-filter2.jpeg

            此时你如果想判断一个缓存 key 是否存在，就采用同样的 l 流程：3 次 hash、根据哈希值寻找下标、取出存储的数据。如果存储的数据不全都是 1，也就意味着缓存中不存在此 key，
            但都是 1 也只表示可能存在。不过没关系，我们只需要否定的意图就能达到目标了(O ^ ~ ^ O)。


            2、布隆过滤器介绍

                1、布隆过滤器是一个很长的二进制向量和一系列随机映射函数。主要用于判断一个元素是否在一个集合中，0代表不存在某个数据，1代表存在某个数据。
                2、布隆过滤器用途
                    1、解决Redis缓存穿透（今天重点讲解）
                    3、在爬虫时，对爬虫网址进行过滤，已经存在布隆中的网址，不在爬取。
                    2、垃圾邮件过滤，对每一个发送邮件的地址进行判断是否在布隆的黑名单中，如果在就判断为垃圾邮件。
                3、布隆过滤器原理
                    1、布隆过滤器
                    	1、本质上布隆过滤器是一种数据结构，比较巧妙的概率型数据结构。特点是高效地插入和查询，可以用来告诉你 “某样东西一定不存在或者可能存在”。相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的。
                    	2、实现原理
                    		1、HashMap 的问题
                    			讲述布隆过滤器的原理之前，我们先思考一下，通常你判断某个元素是否存在用的是什么？应该蛮多人回答 HashMap 吧，确实可以将值映射到 HashMap 的 Key，然后可以在 O(1) 的时间复杂度内返回结果，效率奇高。但是 HashMap 的实现也有缺点，例如存储容量占比高，考虑到负载因子的存在，通常空间是不能被用满的，而一旦你的值很多例如上亿的时候，那 HashMap 占据的内存大小就变得很可观了。
                    			还比如说你的数据集存储在远程服务器上，本地服务接受输入，而数据集非常大不可能一次性读进内存构建 HashMap 的时候，也会存在问题。
                    		2、布隆过滤器数据结构
                    		布隆过滤器是一个 bit 向量或者说 bit 数组，长这样：
                    		0	0	0	0	0	0	0	0	0	0	0
                    		1	2	3	4	5	6	7	8	9	10	11




                    		如果我们要映射一个值到布隆过滤器中，我们需要使用多个不同的哈希函数生成多个哈希值，并对每个生成的哈希值指向的 bit 位置 1，例如针对值 “baidu” 和三个不同的哈希函数分别生成了哈希值 1、4、7。
                    		1	0	0	1	0	0	1	0	0	0	0
                    		1	2	3	4	5	6	7	8	9	10	11

                    		而当我们需要查询 “baidu” 这个值是否存在的话，那么哈希函数必然会返回 1、4、7，然后我们检查发现这三个 bit 位上的值均为 1，那么我们可以说 “baidu” 存在了么？答案是不可以，只能是 “baidu” 这个值可能存在。

      总结：  以上两种缓解措施在不同的应用场景可以做些适当的选择：如果访问量大可以使用第一种方案简单粗暴；如果访问量低但涉及的 key 比较多，则可采用第二种方案

2、缓存击穿 Cache Breakdown
    缓存击穿是指当某一 key 的缓存过期时大并发量的请求同时访问此 key，瞬间击穿缓存服务器直接访问数据库，让数据库处于负载的情况。
    2、解决方案
        1.锁更新
            可以使用(分布式)锁，只让一个线程更新 key，其他线程等待，直到缓存更新释放锁
        2.异步更新
        还有个可行的方案就是把缓存设置为永久不过期，异步定时更新缓存。比如后台有个值守线程专门定时更新缓存，但一般还要定时频繁地去检测缓存，
        一旦发现被踢掉(比如被缓存的失效策略 FIFO、LFU、LRU 等)需要立刻更新缓存，但这个“定时”的度是比较难掌握的，实现简单但用户体验一般。

        异步更新机制还比较适合缓存预热，缓存预热是指系统上线后，将相关的缓存数据直接加载到缓存系统，避免在用户请求时才缓存数据，提高了性能。

3、缓存雪崩 Cache Avalanche
    缓存雪崩是指当大量缓存同时过期或缓存服务宕机，所有请求的都直接访问数据库，造成数据库高负载，影响性能，甚至数据库宕机，
    它和缓存击穿的区别在于失效 key 的数量。
    2、解决方案
        1.集群
        高可用方案的本质就是冗余，集群是其实现方式之一，使用集群可以避免服务单点故障，但集群也带来了复杂度，好在很多成熟的中间件都有稳妥的集群方案，比如 Redis 集群。

        2.过期时间
        为了避免大量的缓存在同一时间过期，可以把不同的 key 过期时间随机生成，但随机可能会对业务有影响，但可以根据业务特点进行设置，总之是让过期时间分散。也有是通过定时刷新过期时间.
           (如： 可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。
        3.服务降级或熔断
           1.服务熔断：当缓存服务器宕机或超时响应时，为了防止整个系统出现雪崩，暂时停止业务服务访问缓存系统。

            2.服务降级：当出现大量缓存失效，而且处在高并发高负荷的情况下，在业务系统内部暂时舍弃对一些非核心的接口和数据的请求，而直接返回一个提前准备好的 fallback（退路）错误处理信息
            熔断和降级都可以间接保证了整个系统的稳定性和可用性。


4、【原创】分布式之数据库和缓存双写一致性方案解析
    先做一个说明，从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。这种方案下，我们可以对存入缓存的数据设置过期时间，
    所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，
    则后面的读请求自然会从数据库中读取新值然后回填缓存。因此，接下来讨论的思路不依赖于给缓存设置过期时间这个方案
        在这里，我们讨论三种更新策略：

      1、先更新数据库，再更新缓存
            这套方案，大家是普遍反对的。为什么呢？有如下两点原因。
            原因一（线程安全角度）
            同时有请求A和请求B进行更新操作，那么会出现
            （1）线程A更新了数据库
            （2）线程B更新了数据库
            （3）线程B更新了缓存
            （4）线程A更新了缓存
            这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑。
      2、 先删除缓存，再更新数据库
            该方案会导致不一致的原因是。同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:
            （1）请求A进行写操作，删除缓存
            （2）请求B查询发现缓存不存在
            （3）请求B去数据库查询得到旧值
            （4）请求B将旧值写入缓存
            （5）请求A将新值写入数据库
            上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。
            那么，如何解决呢？采用延时双删策略
                public void write(String key,Object data){
                		redis.delKey(key);
                	    db.updateData(data);
                	    Thread.sleep(1000);
                	    redis.delKey(key);
                	}
             转化为中文描述就是
             （1）先淘汰缓存
             （2）再写数据库（这两步和原来一样）
             （3）休眠1秒，再次淘汰缓存
             这么做，可以将1秒内所造成的缓存脏数据，再次删除。

      3、 先更新数据库，再删除缓存
            这种情况不存在并发问题么？
            不是的。假设这会有两个请求，一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生
            （1）缓存刚好失效
            （2）请求A查询数据库，得一个旧值
            （3）请求B将新值写入数据库
            （4）请求B删除缓存
            （5）请求A将查到的旧值写入缓存
            ok，如果发生上述情况，确实是会发生脏数据。

            发生上述情况有一个先天性条件，就是步骤（3）的写数据库操作比步骤（2）的读数据库操作耗时更短，才有可能使得步骤（4）先于步骤（5）。可是，大家想想，数据库的读操作的速度远快于写操作的（不然做读写分离干嘛，做读写分离的意义就是因为读操作比较快，耗资源少），因此步骤（3）耗时比步骤（2）更短，这一情形很难出现。
            假设，有人非要抬杠，有强迫症，一定要解决怎么办？
            如何解决上述并发问题？
            首先，给缓存设有效时间是一种方案。其次，采用策略（2）里给出的异步延时删除策略，保证读请求完成以后，再进行删除操作。

         这也是缓存更新策略（2）和缓存更新策略（3）都存在的一个问题，如果删缓存失败了怎么办，那不是会有不一致的情况出现么。比如一个写数据请求，然后写入数据库了，删缓存失败了，这会就出现不一致的情况了。这也是缓存更新策略（2）里留下的最后一个疑问。

        解决方案：使用消息队列。
            流程如下所示
            （1）更新数据库数据；
            （2）缓存因为种种问题删除失败
            （3）将需要删除的key发送至消息队列
            （4）自己消费消息，获得需要删除的key
            （5）继续重试删除操作，直到成功
            然而，该方案有一个缺点，对业务线代码造成大量的侵入。


