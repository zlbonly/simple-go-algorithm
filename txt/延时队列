

延时队列 和 定时任务区别


一、延时队列
	
	1、常见的延时队列实现方式
	 	1） redis zset
	 	2) 时间轮（timewheel,参考kafka时间轮）
	 	3） rabbitmq+ttl （通过rabbitmq的死信队列实现）
	 	4） 定时任务cron (最小堆 nsq内部的延时消息 就是使用最小堆（构建了四叉堆）)

	2、redis 有序列表zset 的实现（参考 simple-delay-queue的实现方式）
	
	i)、整体结构
		整个延迟队列由4个部分组成：
		1、Job Pool用来存放所有Job的元信息。
		2、DelayBucket是组以时间为维度的有序队列，用来存放所有需要延迟的／已经被reserve的Job（这里只存放Job Id）。
		3、Timer负责实时扫描各个Bucket，并将delay时间 【小于/等于】当前时间的Job放入到对应的Ready Queue。
		4、Ready Queue存放处于Ready状态的Job（这里只存放Job Id），以供消费程序消费。 	

	ii)、基本概念
		1、Job：需要异步处理的任务，是延迟队列里的基本单元。与具体的Topic关联在一起。
		2、Topic：一组相同类型Job的集合（队列）。供消费者来订阅。

	iii) 消息结构	
		每个Job必须包含一下几个属性：
		Topic：Job类型。可以理解成具体的业务名称。
		Id：Job的唯一标识。用来检索和删除指定的Job信息。
		Delay：Job需要延迟的时间。单位：秒。（服务端会将其转换为绝对时间）
		TTR（time-to-run)：Job执行超时时间。单位：秒。
		Body：Job的内容，供消费者做具体的业务处理，以json格式存储。

	iv) 消息状态转换
		每个Job只会处于某一个状态下：
		ready：可执行状态，等待消费。
		delay：不可执行状态，等待时钟周期。
		reserved：已被消费者读取，但还未得到消费者的响应（delete、finish）。
		deleted：已被消费完成或者已被删除。

	v)	消息存储
		在选择存储介质之前，先来确定下具体的数据结构：
		Job Poll存放的Job元信息，只需要K/V形式的结构即可。key为job id，value为job struct。
		Delay Bucket是一个有序队列。
		Ready Queue是一个普通list或者队列都行。
		能够同时满足以上需求的，非redis莫属了。
		bucket的数据结构就是redis的zset，将其分为多个bucket是为了提高扫描速度，降低消息延迟。

	vi) 通信协议
		为了满足多语言Client的支持，我们选择Http通信方式，通过文本协议（json）来实现与Client端的交互。 目前支持以下协议：
		添加：{‘command’:’add’, ’topic’:’xxx’, ‘id’: ‘xxx’, ‘delay’: 30, ’TTR’: 60, ‘body’:‘xxx'}
		获取：{‘command’:’pop’, ’topic’:’xxx'}
		完成：{‘command’:’finish’, ‘id’:’xxx'}
		删除：{‘command’:’delete’, ‘id’:’xxx'}
		body也是一个json串。
		Response结构：{’success’:true/false, ‘error’:’error reason’, ‘id’:’xxx’, ‘value’:’job body'}
		强调一下：job id是由业务使用方决定的，一定要保证全局唯一性。这里建议采用topic＋业务唯一id的组合。	

	vii) 举例说明一个Job的生命周期

		用户对某个商品下单，系统创建订单成功，同时往延迟队列里put一个job。job结构为：{‘topic':'orderclose’, ‘id':'ordercloseorderNoXXX’, ‘delay’:1800 ,’TTR':60 , ‘body':’XXXXXXX’}
		1、延迟队列收到该job后，先往job pool中存入job信息，然后根据delay计算出绝对执行时间，并以轮询(round-robbin)的方式将job id放入某个bucket。
		2、timer每时每刻都在轮询各个bucket，当1800秒（30分钟）过后，检查到上面的job的执行时间到了，取得job id从job pool中获取元信息。如果这时该job处于deleted状态，则pass，继续做轮询；如果job处于非deleted状态，首先再次确认元信息中delay是否小于等于当前时间，如果满足则根据topic将job id放入对应的ready queue，然后从bucket中移除；如果不满足则重新计算delay时间，再次放入bucket，并将之前的job id从bucket中移除。
		3、消费端轮询对应的topic的ready queue（这里仍然要判断该job的合理性），获取job后做自己的业务逻辑。与此同时，服务端将已经被消费端获取的job按照其设定的TTR，重新计算执行时间，并将其放入bucket。
		4、消费端处理完业务后向服务端响应finish，服务端根据job id删除对应的元信息。


	viii) 设计不足的地方
		1、timer是通过协程的无限循环来实现，在没有ready job的时候会对CPU造成一定的浪费。
		2、消费端在reserve job的时候，采用的是http短轮询的方式，且每次只能取的一个job。如果ready job较多的时候会加大网络I/O的消耗。
		3、数据存储使用的redis，消息在持久化上受限于redis的特性。

	v10) 未来优化
		 1、基于wait／notify方式的Timer实现。
		 2、提供TCP长连的API，实现push或者long-polling的消息reserve方法。
		 3、拥有自己的存储方案（内嵌数据库、自定义数据结构写文件），确保消息的持久化。			

   	2、基于时间轮的 延迟队列实现（主要是kafak的时间轮算法）
   	    1） 自实现时间轮(https://github.com/zlbonly/timewheel)

           https://github.com/zlbonly/timewheel/blob/master/pics/timewheel.jpeg
           #### 1、timewheel  维护 slots[] 槽位（每个槽内存放 延时任务的双向链表），slotNum  时间轮的槽位数量，interva了
           时间轮中指针每隔多久往前移动一格， 然后根据 Task 维护任务的延迟时间 dealy ， 计算 在时间轮中的位置pos，和圈数
           delaySeconds := int(d.Seconds())  // 延时时间
           intervalSeconds := int(tw.interval.Seconds()) // 移动步长
           cycle = int(delaySeconds / intervalSeconds / tw.slotNum)  // 圈数
           pos = int(tw.currentPos+delaySeconds/intervalSeconds) % tw.slotNum  // 时间轮中所在位置

           然后根据 定时器轮询 获取相应槽位，并遍历对应的 任务链表，取出具体任务 执行。


           #### 缺点：
           1、缺点： 时间轮没有分级，会导致单个槽点 任务双向链表过长，时间轮空转，没有分级概念

   	    2） kafak时间轮
   	      参考连接  https://juejin.cn/post/6844904110399946766

